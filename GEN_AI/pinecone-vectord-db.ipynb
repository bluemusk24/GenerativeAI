{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da24e5ee-c7ee-4009-b832-454c9fe25138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b196d4b-b5d1-43ba-aefb-4589b2198d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.pdf.PyPDFDirectoryLoader at 0x7f3d7dd54610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimator object of PyPDF with folder Machine Learning Notes as parameter\n",
    "loader = PyPDFDirectoryLoader('Machine Learning Notes')\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afaabcf8-492d-4c5e-a19a-3137f4d69b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='  Advancements in Generative AI: A \\nComprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and \\nTransformers. \\nStaphord Bengesi1, Hoda El -Sayed1, Md Kamruzzaman Sarker1, Yao  Houkpati1, John \\nIrungu3   and Timothy Oladunni2 \\n1 Dept. of Computer Science, Bowie State University, Bowie, MD 20715 USA  \\n2 Dept. of Computer Science, Morgan State University, Baltimore, MD 21251 USA  \\n3 Dept.  of Computer Science, University of the District of Columbia , Washington, DC 20008  USA  \\nCorresponding author: sbengesi@bowiestate.edu  \\n \\nABSTRACT  The launch of ChatGPT has garnered global attention, marking a significant milestone in the \\nfield of Generative Artificial Intelligence. While Generative AI has been in effect for the past decade, the \\nintroduction of ChatGPT has ignited a new wave of research and innovation in the AI domain. This surge in interest has led to the development and release of numerous cutting -edge tools, such as Bard, Stable Diffusion, \\nDALL -E, Make-A- Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable \\ncapabilities, encompassing tasks ranging from text generation and music composition, image creation, video \\nproduction, code generation, and even scientific work. They are built upon various state -of-the-art models, \\nincluding Stable Diffusion, transformer models like GPT- 3 (recent GPT -4), variational autoencoders, and \\ngenerative adversarial networks. This advancement in Generative AI presents a wealth of exciting opportunities and, simultaneously, unprecedented challenges. Throughout this paper, we have explored these state-of-the-art models, the diverse array of tasks they can accomplish, the challenges they pose, and the \\npromisi ng future of Generative Artificial Intelligence.  \\nINDEX TERMS  Generative AI, GPT , Bard, ChatGPT, Diffusion  Model, Transformer, GAN , Autoencoder, \\nArtificial Intelligence .\\n \\nI. INTRODUCTION   \\nThe release of ChatGPT on November 30, 2022 [30][31], \\ntriggered an exponential surge in the groundbreaking and \\nwidespread popularity of G enerative A rtificial Intelligence \\n(GAI)  to the general public.  This remarkable achievement \\ncould be traced to t he 1956 summer project at Dartmouth \\nCollege spearheaded by McCarthy ; mark ing the inception of  \\nthe Artificial Intelligence  [1]. The endeavor aimed to \\ndevelop machines with the ability to perform tasks typically demanding human intelligence  [2]  [3] [4] [5] [6]. These \\ntasks include  computer vision, natural language processing, \\nrobotics,  and many others .  Since then, significant \\nadvancements have been achieved in imbuing  machines with \\nthe capability of talking, walking, thinking, and acting like humans . Notably, a series of algorithms, including the \\nRegression model, perceptron algorithm  [7], Decision \\ntree[8], K-N earest Neighbor  [9], Naive Bayes Classifier, \\nBack Propagation, support vector machine (SVM)[10] , and Random Forest  [11] have emerged . These  algorithms  in the \\ncontemporary  are commonly referred to  as \\nclassical /traditional machine learning algorithms and  most of \\nthem were developed before  the year 2000.  Furthermore, \\nthere is an  advancement  in deep learning algorithms, \\nincluding the development of Convolutional Neural Networks (CNNs) in the 1980s  [12], Recurrent Neural \\nNetworks (RNNs) in 198 5[13], Long Short -Term Memory \\n(LSTM) in 1997  [14], and Bidirectional Long Short -Term \\nMemory (BiLSTM) [15] in the same year. However, until \\nrecent times , widespread attention has been limited primarily \\nbecause of computing resources and dataset availability limitations  [16]. \\n   To tackle the constraints imposed by limited datasets, researchers from Stanford University, Princeton University, and Columbia University jointly launched the ImageNet Large Scale Visual Recognition Challenge in 2010 [17]. This \\ncompetition played a pivotal role in driving advancements in neural network architectures, with a particular focus on ', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}),\n",
       " Document(page_content='  Convolutional Neural Networks (CNNs). Since then, CNN \\nhas been established as algorithm  for image classification  \\nand computer vision[18] . The breakthrough achievement of \\nAlexNet in 2012 [19] mark ed a significant milestone in the \\npractical application of deep learning in computer vision \\ntasks. The success of the ImageNet Competition ignited a \\nsurge in interest and investment in deep learning research. \\nThis newfound enthusiasm resulted in the continuous \\nevolution of  improved architectural innovations, including \\nmodels such as ResNet [20], DenseNet [21], MobileNet [22], \\nand EfficientNet [23]. These models set the gold standard for \\nvarious cutting- edge technologies, such as transfer learning, \\ncontinual learning, attention mechanisms  [24], self -\\nsupervised learning, and generative AI.   \\nBefore 2014, all existing deep learning models were \\nprimarily descriptive, focusing on summarizing or \\nrepresenting existing data patterns and relationships. These \\nmodels aimed to explain the data patterns and make \\npredictions based on the information prese nt. However, \\nGoodfellow  et al.  [25] in 2014  introduced the Generative \\nAdversarial Network (GAN) ushering in a new era of \\nGenerative Artificial Intelligence (GAI)  realization . Unlike \\ntheir descriptive counterparts, generative models, such as \\nGANs, are designed to learn the underlying probability \\ndistribution of the data  [26] . Their primary goal is to \\ngenerate new data samples that closely resemble the patterns \\nobserved in the training data  [27][28].  \\nThe breakthrough of GAN marked a significant \\ndeparture from traditional deep learning methods, opening  \\nexciting possibilities for Generative artificial intelligence . \\nGAI has since garnered widespread attention due to its \\ntransformative impact across various domains of life. It offers elegant solutions to complex problems  [29]\\n enabling \\nthe creation of synthetic data, artistic content, and realistic \\nsimulations. This paradigm shift in AI technology has \\nprofoundly influenced the  new perception , implementation, \\nand utilization on  artificial intelligence, sparking innovation \\nand new application opportunities across industries.   \\nThe emergence of GAI has sparked numerous questions, \\nprompting a need for a comprehensive exploration. In that \\nvein, this paper aims   at provid ing an in -depth exploration to \\nthe state-of-the-art in GAI , including  models,  task \\ncategorization, applications, areas of influence, challenges, \\nand prospects . To achieve this, our work  is structured as \\nfollows: Section II introduces contemporary generative \\nmodels. Section III elaborates on the various tasks within \\nGenerative AI. Section IV examines the diverse applications \\nof Generative AI. Section V delves into the outlook for \\ngenerative AI. Lastly, Section VI offers a conclusion.  \\n \\n \\nII. GENE RATIVE MODELS  \\nThere has been a shift in the focus of researchers from discriminative learning to generative learning in the \\ncontemporary era. Multiple generative models have emerged \\n \\n1 Source: https://towardsdatascience.com/applied -deep -learning -part-3-\\nautoencoders -1c083af4d798  with the capability of generating new data points like the \\ntraining data inputs based on learning their distribution . This \\nsection will discuss current state -of-the-art theoretical and \\nmathematical foundations of generative models.  \\n \\nA. AUTOENCODER  \\nAutoencoder is  an unsupervised machine learning neural \\nnetwork model that encodes the input data  using an encoder  \\ninto a lower -dimensional representation (encoding) and then  \\nuses a decoder to  decode it back to its original form \\n(decoding) while reducing the reconstruction error  [32]. This \\nmodel was primarily designed for Dimensionality \\nReduction, Feature Extraction, Image Denoising, Image \\nCompression, Image Search, Anomaly Detection and \\nMissing Value Imputation  [32]. \\n  \\n           FIGURE 1. Autoencoder architecture1 \\n \\nBoth encoder and decoder  of the model  are neural networks \\nwritten as a function of input and a generic function of code layer respectively  [33]. Based on figure 1,  autoencoder is \\nmade up of four components namely:  \\n• Encoder:  This component reduces and compresses \\nthe input data into lower dimensions.  As a result of \\nits output, it creates a new layer called code.  \\n• Code/Bottleneck:  a layer that contains a \\ncompressed and the lowest possible dimensions of input data representation.  \\nConsider  equation 1 below.  \\nℎ\\n𝑖𝑖=𝑓𝑓(𝑋𝑋𝑖𝑖)                                   (1) \\nWhereby 𝒉𝒉𝒊𝒊 is code layer after function f  with user \\ndefined parameter s is applied to the input  𝑿𝑿𝒊𝒊  \\n \\n• Decoder: Reconstruc ts the code layer from lower \\ndimension representation to input.  \\n• Reconstruction  Loss: Defines the final output of \\nthe decoder, measuring how closely the output resembles the original input.     \\n   \\n                          𝑋𝑋\\n𝚤𝚤�=𝑔𝑔(ℎ𝑖𝑖)                       (2)       \\n', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content=\"   \\nWhere 𝑿𝑿𝒊𝒊� is the output of encoder after second \\ngeneric function to the code layer.  \\n \\nThe training of the autoencoder involves minimizing the \\ndissimilarity between the input and the output  [33], as shown \\nin Equation 3.  \\n \\n                     𝐴𝐴\\n𝐴𝐴𝑔𝑔𝐴𝐴𝐴𝐴\\n𝐴𝐴𝑓𝑓,𝑔𝑔<∆�𝑿𝑿 𝒊𝒊,𝑿𝑿𝒊𝒊��                  (3)  \\n T\\nhe encoder and the decoder are composed of fully \\nconnected feedforward neural networks where the input, code, and output layer s consist each of a single neural \\nnetwork layer defined by the user. Like other standard neural networks, autoencoders apply activation functions such as sigmoid and Relu.  Various variants of autoencoder exist, \\nsuch as contractive, Denoising, and sparse autoencoder  [34]. \\nGenerally, the plain autoencoders prior mentioned are not generative since they do not generate new data but replicate \\nthe input. However, the variational autoencoder is the variant \\nthat is generative  [32]. \\n \\n1) VARIATIONAL AUTOENCODER  \\nVariational autoencoder (VAE) evolved as a result of the introduction of variational inference  (A statistical technique \\nfor approximating complex distributions) to Autoencoder (AE) by Kingma  et al.  [35]. It's a generative model that \\nutilizes Variational Bayes Inference to describe data generation using a probabilistic distribution  [36]. \\n     Unlike traditional AEs, VAEs have an extra sampling layer in addition to an encoder and decoder layer  as depicted \\nin figure  2.\\n Training the VAEs model involves encoding the \\ninput as a distribution over the latent space and generating the latent vector from the distribution sampling. Afterward, \\nthe latent vector is decoded, the reconstruction error is \\ncomputed, and the reconstruction error is backpropagated through the network.  During the training process, \\nregularization is introduced explicitly to prevent overfitting.  \\n  \\n                                                                               \\n \\n \\nFIGURE 2 . Variational encoder architecture  \\n \\n  \\n \\n \\n    FIGURE 3. Probability Model   \\n \\nProbabilistically,  VAE is composed of a latent \\nrepresentation z as depicted by  Figure 3, drawn from the \\nprior distribution p(z)  and the data x drawn from the \\nconditional likelihood distribution p(x|z) which is  referred to \\nas probabilistic decoder  and can be expressed as:  \\np(x,z)=p(x∣z)p(z)                                              (4) \\n \\nThe inference of the model is examined by computing the \\nposterior of the latent vector using the Bayes theorem shown \\nin equation 5.  \\n          𝑝𝑝(𝑧𝑧 ∣ 𝑥𝑥 ) =𝑝𝑝(𝑥𝑥∣𝑧𝑧)𝑝𝑝(𝑧𝑧)\\n𝑝𝑝(𝑥𝑥)                               (5)  \\n With any distribution variant such as Gaussian, variational \\ninference can approximate th e posterior,  and its reliability in \\napproximation can be assessed through Kullback- Leibler \\ndivergence  which measures the information lost during \\napproximation.  This model has significantly influenced \\ngenerative AI, as demonstrated in Table 1, which highlights \\na few outstanding state -of-the-art examples using VAE \\nacross various domains.  \\n \\n \\nTABLE   1 \\nVAE  STATE -OF-THE-ART \\ncategory  Subcategory \\nDomains  Dataset  Reference  \\nImage Processing  Image \\nClassification  MRI datasets , SAR \\nimages , ImageNet \\ndataset, NWPU -\\nRESISC45  [37] [38] [39] [40] \\nImage Compression  Kodak dataset  [41] \\nImage Resolution  \\n DIV2K and Flickr2K \\nimage dataset  [42] \\nAudio Processing  \\n Noisy voice \\nrecorded datasets  NIL [43] [44] \\n\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 2}),\n",
       " Document(page_content='   \\nVideo Processing  Prediction  MineRL  and \\nMMNIST  [45] \\nVideo  Infrastructure \\nMonitoring  UCSD Ped2 , Fan \\ndeterioration simulated \\ndataset  [46] [47] [48]  \\nAudio  Infrastructure \\nMonitoring  MIMII  [49] \\nSensor  Nonlinear analysis  Simulated Dataset, \\nButane content  [50] [51] \\nModeling  DCS  [52] [53]  [54] \\nActivity monitoring  Finance 284,807 credit card \\ntransactions  [55] [56] \\n \\n \\nB. TRANSFORMER  \\nThe ground- breaking work of Vaswani et al . \"Attention Is All \\nYou Need\" by the Google Brain team introduced a \\ntransformer  model which can analyze large -scale dataset  \\n[24]. Transform was initially developed for natural language  \\nprocessing (NLP) but was subsequently adapted to other \\nareas of machine learning, such as computer vision [57] [58] \\n[59]. This model aimed  to solve RNNs, and CNNs \\nshortcomings such as long- range dependencies, gradient \\nvanishing, gradient explosion, the need for larger training \\nsteps to reach a local/global minima, and the fact that parallel \\ncomputation was not allowed [24]. Thus, t he proposed \\nsolution  presented a novel  way of handling neural network \\ntasks like translation, content generation, and sentiment analysis  [60]  \\n \\n          \\nFIGURE 4. Transformer Architecture  [24] \\n Transformer Architecture \\nVaswani et al , introduced three main concepts in their study  \\nas depicted in figure 4 , including self -attention, which allows \\na model  to evaluate input sequences according to their \\nimportance, thus reducing long- range dependencies, multi -\\nhead  attention which allows the model to learn multiple \\nmeans of the input sequence, and word embedding, which transforms inputs into vectors.   \\n \\nEncoder and Decoder   \\n', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 3}),\n",
       " Document(page_content=\"  It is worth mentioning that the transformer architecture \\n(Figure 4) inherits the encoder -decoder structure[61] that \\nutilizes stacked self -attention and point -wise layers, fully \\nconnected layers for both the encoder and decoder  [62]. The \\nencoder consists of a stack of N = 6 identical layers, each with \\ntwo sublayers, including a multi -head self -attention \\nmechanism and a fully connected feedforward network. A \\ndecoder is like an encoder, but with an additional sublayer \\nwhich masks the mult i-head attention. Encoders and decoders \\nboth apply residual connections to the sublayers, followed by normalization of the layers.  \\n  \\nSelf-Attention  \\nAttention describes the mechanism for a better understanding of the word's context by paying attention to the vital part of the sentence or any input. It involves mapping a vector of \\nquery and a set of key -value pairs to an output vector. \\nAccording to [24], self -attention refers to Scaled Dot -Product \\nAttention  consisting of queries and key dimensions 𝑑𝑑\\n𝑘𝑘, and \\ndimension 𝑑𝑑𝑣𝑣 values computed according to the following \\nformula:  \\n \\n𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴 (𝑄𝑄,𝐾𝐾,𝑉𝑉 ) = 𝑠𝑠𝐴𝐴𝑓𝑓𝐴𝐴𝐴𝐴 𝑠𝑠𝑥𝑥(𝑄𝑄𝐾𝐾𝑇𝑇\\n√𝑑𝑑𝑘𝑘)𝑉𝑉              (6) \\nFigure 5 depicts  the structure attention whereby the SoftMax \\nactivation function is used to compute the weights on values.   \\n \\nFIGURE 5. Self-attention architecture  [24] \\n Mult i-head attention \\nA multi- head attention mechanism proposes that self -\\nattention can be run multiple times in parallel mode combining knowledge of the same a ttention pooling via \\ndifferent representation subspaces of queries, keys, and \\nvalues.  Afterward, the independent attention outputs are \\nconcatenated and linearly transformed into the expected \\ndimension, as portrayed by equation 7 and figure 6.  \\n  \\n \\n      \\nFIGURE 6. Self-attention architecture [24] \\n \\n𝑀𝑀𝑀𝑀𝑀𝑀 𝐴𝐴𝐴𝐴𝑀𝑀𝐴𝐴𝑠𝑠𝑑𝑑 (𝑄𝑄,𝐾𝐾,𝑉𝑉 )=\\n𝐶𝐶𝐴𝐴𝐴𝐴𝐶𝐶𝑠𝑠𝐴𝐴(ℎ𝐴𝐴𝑠𝑠𝑑𝑑 1,...ℎ𝐴𝐴𝑠𝑠𝑑𝑑 ℎ)𝑊𝑊𝑜𝑜                                         (7)      \\n \\nwhere ℎ𝐴𝐴𝑠𝑠𝑑𝑑 𝑖𝑖 = Attention ( 𝑄𝑄𝑊𝑊𝑖𝑖𝑄𝑄,𝐾𝐾𝑊𝑊𝑖𝑖𝑘𝑘,𝑉𝑉𝑊𝑊𝑖𝑖𝑣𝑣) \\n \\nSince the Transformer's  invention, several variants have been \\ndeveloped to solve different machine- learning  tasks in \\ncomputer vision and natural language processing. It's \\nimperative to note that the state -of-the-art models are built on \\nthe foundation transformer architecture  [63]. In the following \\nsubsection, we will discuss the contemporary generative \\nmodels.  \\n \\n \\n1) GENERATIVE PRE-TRAINED TRANSFORMER (GPT) \\nA Generative Pretrained Transformer (GPT) describes the \\ntransformer -based large language model (LLM) that utilizes  \\ndeep learning techniques to generate a human- like text  [64]. \\nThe model  was introduced by OpenAI in 2018 [65], \\nfollowing Google's 2017 invention of a transformer.  It is \\nmade of a stack of transformer decoders.  They proposed a \\nmodel consisting of two stages: learning a high- capacity \\nlanguage model from a large corpus of text and fine -tuning it \\nwith labeled data during the discriminative task, as depicted \\nin figure 7. \\n \\n\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 4}),\n",
       " Document(page_content='   \\n      FIGURE 7. Self-attention architecture [65] \\n \\n GPT or GPT -1 was trained on the BooksCorpus dataset, \\nwhich consists of over 7,000 unique unpublished books in many genres, such as Adventure, Fantasy, and Romance, all with long stretches of contiguous text, allowing the \\ngenerative model to lear n on long- range information  [61][62] \\n[65]. The model training specification included the following:  \\n• 12-layer decoder -only transformer.  \\n• Masked self -attention heads (768- dimensional states \\nand 12 attention heads).  \\n• Position -wise feed -forward networks.  \\n• Adam optimization.  \\n• Learning rate:  2.5e-4. \\n• 3072 -dimensional inner states.   \\nThe assessment tasks for the model were drawn from four \\nprimary categories within Natural Language Processing \\n(NLP): these encompass natural language inference, question \\nanswering and common- sense reasoning, semantic similarity, \\nand classification.  Following the initial release, OpenAI has \\nproduced a series of variant models known as GPT -n series \\nwhere  every successor model is more substantial and efficient \\nthan the predecessor.  GPT -4 is the most recent variant release \\nin March 2023.  \\n \\n2) GPT-2 \\nAfter the great success of GPT -1, , OpenAI released a second \\nversion (GPT -2) in 2019 with 1.5 billion learnable \\nparameters, ten times more in pre- training corpus and \\nparameters than its predecessor trained on WebText, a collection of millions of webpages.  [66]. As a result, this \\nmodel is capable of handling complex problems and \\ngenerating coherent and contextually relevant texts across a \\nwide range of topics and styles.  \\n \\n3) GPT-3 \\nThis version was released in 2020 and had 2048- token \\ncontexts, 175 billion learnable parameters, which is more \\nthan 100 times its predecessor, and required 800GB of \\nstorage [67]. CommonCrawl was used to train the model, \\nwhich was tested on all domains of NLP, and it had promising \\nfew-short and zero -shot performance.  This version was \\nfurther improved to GPT 3.5, which was used to develop \\nChatGPT.  Considerable research work has been conducted, \\nincorporating GPT -1 to GPT -3.5 across various task  such as \\nSpeech Recognition [68] [69] [70], Text Generation  [71] [72] \\n[73] [74] [75] [76] [77] [78], Cryptography [79] [80] [81] [82], Computer Vision [88] [89], and Question Answering  \\n[83] [84] [85] [86] [87]. \\n \\n4) GPT-4 \\nIn March 2023, the most recent GPT model was released  by \\nOpenAI [90]. It’s a multimodal transformer  model , A large -\\nscale language model  which  accept s image and text inputs \\nand produce text outputs. In a number of professional and \\nacademic benchmarks, including passing a bar and medical \\nexam at high rates, GPT -4 exhibits high performance \\ncomparable to that of humans [91] [92]. The model was \\ntrained using publicly available internet data and data licensed from third parties and then fine -tuned using \\nReinforcement Learning from Human Feedback (RLHF).  It \\nwas compared with state- of-the-art models using Measuring \\nMassive Multitask Language Understanding (MMLU)  [93] \\nthat covers 57 tasks in elementary mathematics, US history, \\ncomputer science, law, and more and outperformed them all.  \\n \\nC. GENERATIVE ADVERSARIAL NETWORK (GAN)  \\n1) GAN OVERVIEW  \\nA generative adversarial network (GAN) is an unsupervised generative model that consists of two neural networks: a \\ngenerator and a discriminator . A generator attempts to \\nfabricate new data (fake) that is indistinguishable from real \\ndata, while a discriminator tries to distinguish between real and fabricated data  [94]. Figure 8 illustrate the  schematic \\narchitecture of GAN (Also known as a vanilla GAN ). The \\ngenerator network takes noise as input and generates fake \\ndata. The discriminator network takes both real and fake data \\nas input and classifies them as real or fake using a sigmoid activation function and binary cross -entropy loss  [95]. Since \\nthe generator does not have direct access to authentic images \\n,it only learns through interactions  with the discriminator; the \\ndiscriminator has access to synthetic and authentic images. \\nUpon completion of classification, backpropagation takes \\nplace to optimize the training process  [94]. This process \\nrepeats itself until the difference between real and fake data \\nsamples is negligible.  \\n \\n \\n                FIGURE 8. Schematic G AN architecture        \\nAccording to Goodfellow et al . [25],  the generator (G) and \\ndiscriminator (D) are trained together in a minimax game \\n', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content=\"  (zero -sum game). In this game  as demonstrated by equation \\n8, G is trying to maximize the probability that D misclassifies \\nits output as real data, while D is trying to minimize the \\nprobability that it misclassifies G's output.  \\n \\n𝒎𝒎𝒊𝒊𝒎𝒎𝑮𝑮𝒎𝒎𝒎𝒎𝒎𝒎𝑫𝑫𝑽𝑽(𝑫𝑫,𝑮𝑮)  =𝑬𝑬𝒎𝒎~𝒑𝒑𝒅𝒅𝒎𝒎𝒅𝒅𝒎𝒎(𝒎𝒎)[𝐥𝐥𝐥𝐥𝐥𝐥𝑫𝑫(𝒎𝒎)]        \\n+ 𝑬𝑬𝒛𝒛~𝒑𝒑𝒛𝒛(𝒛𝒛)[𝐥𝐥𝐥𝐥𝐥𝐥 (𝟏𝟏−𝑫𝑫(𝑮𝑮(𝒛𝒛)))]              (8)    \\n \\nWher e E is the Expected Value, 𝒑𝒑𝒅𝒅𝒎𝒎𝒅𝒅𝒎𝒎(𝒎𝒎) is Real  data \\ndistribution  and 𝒑𝒑𝒛𝒛(𝒛𝒛) implies Noise data distribution . \\n \\n2) GAN CHA LLENGES  \\nDespite their robustness, traditional GANs suffer from \\nlimitations such as : \\n      Mode collapse : In this phenomenon, the generator can \\nonly produce a single type of output or a limited number of outputs  [96]. This is because the generator becomes stuck in \\na particular mode or pattern, failing to generate diverse \\noutputs that cover the entire data range  [97]. There are two \\nmain causes of mode collapse in GANs. The first is catastrophic forgetting  [98], which occurs when learning in a \\ncurrent task destroys knowledge learned in a previous task. \\nThe second cause is discriminator overfitting, which results \\nin the generator loss vanishing [99]. \\n      Non -convergence and Instability : The loss function in \\nequation 8 can cause the generator to suffer from gradient \\nvanishing [100] . This can happen when the discriminator \\nlearns too quickly and can easily distinguish between real and \\nfake samples. On the other hand, the generator may have a \\nlower learning rate and be unable to keep up. This can lead to \\nthe training process stalling, as the generator cannot learn \\nfrom the feedback provided by the discriminator. GANs are also known to be sensitive to the choice of hyperparameters, \\nsuch as the learning rate and the batch size. This means that \\nit can be challenging to train GANs consistently, as even \\nsmall changes to the hyperparameters can significantly \\nimpact the results [101] . \\n    Gradient vanishing can be addressed using a different loss function, such as the Wasserstein loss. The Wasserstein loss \\nis less sensitive to the discriminator's learning rate, and it can \\nprevent the generator's gradients from disappearing. Another solution would be to use a generator with a smaller learning \\nrate. This will prevent generator weights from becoming too \\nlarge, whi ch can also contribute to gradient vanishing. In \\naddition, a good initialization technique must be used for the \\ngenerator. In this manner, the generator will start well, and \\nthe training process will likely be successful.  \\n \\n3) \\nGAN VARIANTS  \\nIn response to the aforementioned GAN challenges, various \\nvariants have been developed to address the weaknesses and \\noptimize the model. Here are some of the most famous \\nvariants of GAN since its emergence in 2014:  \\n   Condi tional Generative Adversarial Network ( cGAN)  \\ncGAN was introduced  by Mirza et al.  [102]  in 2014,  this \\nvariant enhances the classical GAN by incorporating extra auxiliary information into the Generator and Discriminator \\nnetworks, such as class labels or style attributes. This \\nintegration is achieved by introducing an additional layer that \\nincludes the conditional information input to the generator, \\ninstructing it on what to produce  [103] . For instance, in an \\nimage generation scenario, this condition might consist of a \\nclass label that precisely defines the type of image to be \\ngenerated.  \\n \\n   The Deep Convolutional GAN (DCGAN)  framework \\nemploys a deep learning model for discriminator and \\ngenerator components, specifically a Convolutional Neural \\nNetwork (CNN). In the architectural design defined by \\nRadford et al. [104] , traditional fully connected layers \\nsituated on top of convolutional features have been omitted. Additionally, including Batch Normalization plays a pivotal \\nrole in enhancing training stability. This technique \\nnormalizes the input to each neural unit, ens uring a mean of \\nzero and unit variance, thus facilitating more consistent and efficient learning. Moreover, DCGAN substitutes \\nconventional pooling layers with strided convolutions in the \\ndiscriminator and fractional -strided convolutions in the \\ngenerator ne twork. The Rectified Linear Unit (ReLU) serves \\nas the activation function for the generator, while the Leaky \\nReLU is employed in the discriminator.  These activation \\nfunctions play a crucial role in enabling the networks to capture intricate patterns and features.   \\n \\n    Wasserstein GAN  (WGAN) is a GAN variant that \\nemploys the Wasserstein distance (also referred to as the \\nEarth Mover's distance) as its loss function, distinguishing \\nitself from traditional GANs that typically use the Jensen -\\nShannon or Kullback- Leibler divergences. The Wasserstein \\ndistance (WD) measures the similarity between the \\ndistributions of real and generated samples [105] . It is \\ngrounded in the solution to a classical optimization problem \\nknown as the transportation problem  [106] . In this context, \\nsuppose there exists several  suppliers, each endowed with a \\ncertain quantity of goods, tasked with delivering to several consumers, each having a specified capacity limit. Each supplier -consumer pair incurs a cost for transporting a single \\nunit of goods. The transportation problem ai ms to identify the \\nmost cost -efficient allocation of goods from suppliers to \\nconsumers.  \\n \\n𝑊𝑊�𝑃𝑃\\n𝑟𝑟,𝑃𝑃𝑔𝑔�= 𝐴𝐴𝐴𝐴𝑓𝑓\\n𝛾𝛾∈𝜋𝜋(𝑃𝑃𝑟𝑟,𝑃𝑃𝑔𝑔)𝐸𝐸(𝑥𝑥.𝑦𝑦)~𝛾𝛾[ || 𝑥𝑥−𝑦𝑦|| ]                     (9)    \\n \\n    WD is expressed  by equation 9, 𝑷𝑷𝒓𝒓 𝑠𝑠𝐴𝐴𝑑𝑑  𝑷𝑷𝒈𝒈 denotes  the \\nprobability distribution of real ad generated sample \\nrespectively.  The Lipschitz constraint was utilized to impose \\nweight clipping on the discriminator [107] . This measure \\nenhances training stability, mitigating challenges like mode \\ncollapse and saturation loss.  \\n \", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content=\"       Cycle GAN is an approach that automates training image -\\nto-image translation models without requiring paired \\nexamples, leveraging GAN architecture [108] . It utilizes \\nunassociated image collections from distinct source and \\ntarget domains (e.g. Domain X and Domain Y). The model structure comprises two generators: Generator -X crafts \\nimages for Domain X, and Generator -Y generates images for \\nDomain Y. Each gen erator associated with a its \\ncorresponding discriminator for binary classification.  \\n      This variant incorporates three loss functions: firstly, the \\ncycle consistency losses ensure that translations between domains maintain a coherent loop, returning to their original \\npoint; secondly, the adversarial loss pits the Generator against \\nits corresponding Discr iminator, with the Generator striving \\nto generate domain -specific images while the Discriminator \\ndistinguishes between translated and real samples; and thirdly, the Identity Loss incentivizes the Generator to \\nfaithfully preserve color co mposition between input and \\noutput, enhancing translation fidelity.  \\n \\n    StarGAN :  a method that harnesses the power of the GAN \\narchitecture for versatile multi- domain image -to-image \\ntranslation. As outlined by Choi  et al [109] , this innovative \\ngenerative adversarial network masterfully learns mappings \\namong numerous domains, employing just a single generator \\nand discriminator, and efficiently trains on images spanning \\nall domains. This model utilizes an Adversarial Loss to make  \\ngenerated images virtually indistinguishable from real ones, \\na Domain Classification Loss to guarantee precise \\nclassification by the discriminator and a Reconstruction Loss \\nthat minimizes adversarial and classification losses.  \\n \\nIn the preceding subsection, we have delved into several \\nvariants of Generative Adversarial Networks (GANs). However, it is worth noting that the landscape of GANs \\nencompasses a myriad of additional variants that have \\nsignificantly advanced beyond the foundational GAN framework. These notable advancements include the \\nProgressive GAN (PGAN) of 2017  [110] , BigGAN of 2018  \\n[111] , StyleGAN  [112]  and StyleGAN 2  [113]  of  2019, along \\nwith earlier innovations such as InfoGAN  [114] , Stacked  \\nGAN [115] , Bidirectional GAN (BiGAN) [116]  from 2016.  \\n \\nD. DIFFUSION MODEL  Diffusion model  is a generative  model  characterized by a \\ntwo-step process. Initially, they introduce Gaussian noise into \\nthe training data, a step referred to as the forward diffusion process. Subsequently, they perform the reverse diffusion \\nprocess, often called denoising, to reconstruct the original data. Over time, the model progressively acquires the ability \\nto eliminate the added noise.  \\n \\nIII. GENERATIVE AI TASK  \\nGenerative AI encompasses a wide array of tasks, including Speech Generation (Text -to-Speech), Image Generation \\n(Text -to-Image), Text Generation (Text -to-Text), Code \\nGeneration (Text -to-Code), Music Generation (Text -to-\\nMusic), Video Generation (Text -to-Video), and Scientific \\nContent Generation (Text -to-Science). These tasks are \\nsupported by various cutting -edge tools, as illustrated in \\nTable 2. Notably, Google boasts the most generative tools, with Meta AI and OpenAI following closely. Most of these \\ntools w ere unveiled in 2023, although a few were introduced \\nearlier.  \\nA. TEXT  GENERATION  \\nThis task  involves taking text as input and generating \\ncorresponding text -based responses. It is often associated \\nwith question -and-answer conversational systems, \\ncommonly called chatbots. Many renowned generative AI \\ntools fall within this category, with ChatGPT be ing a \\ngroundbreaking example in the field of Generative AI. Other notable tools in this category include Google's Bard, \\nOpenAI's ChatGPT Plus, Wordtune Spice, and Cohere's \\nGenerate.  We conducted a comprehensive performance \\nassessment of two promin ent and renowned text -to-text tools, \\nBard and ChatGPT. Both were presented with identical queries: ‘Provide a brief description of what Bard is in one \\nparagraph ’, ‘Provide a brief description of what ChatGPT is \\nin one paragraph’,  and a Swahili question, ‘ Habari za saa \\nhizi’. The results as illustrated by figure  9, unmistakably \\nindicate that ChatGPT outperformed Bard in delivering more \\nprecise answers to the questions.   \\n \\n \\n  \", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content=\"   \\n(a)  \\n(b) \\n(c)  \\n(d) \\n \\n                                                          FIGURE 9. (a) chatGPT chatbot, b -d are bard output.  \\n   \\nB. IMAGE  GENERATION  \\nIt’s a task which encompasses  the process of utilizing textual \\nprompts  or visual to generate corresponding images, \\nspanning various visual domains, including graphics, \\nphotographs, and artwork. As an illustration of text -to-image \\nconcept , we conducted experiments using 'Firefly' from \\nAdobe and 'Stable Diffusion' by Stability as our subjects. By \\nprompting these models with ‘ College Student \\nProgramming’ , we obtained their respective outputs, as \\nshowcased in Figure 10, t he results clearly indicate that while \\n'Firefly' excelled in delivering more precise outputs in alignment with the input, S table Diffusion exhibited superior \\nimage resolution compared to its counterpart.  Another \\nscenario image generation revolves around the \\ntransformation of an image from one form to another, guided \\nby textual descriptions provided as input. Within this domain, numerous tools have demonstrated promising capabilities in \\neffecting such transformations. Notably, we have explored \\nthe performance of RoomGPT and Runaway, as exemplified \\nin Figure 11 and Figure 12, respectively.  \\nC. VIDEO GENERA TION  \\nThis task involves generating new videos based on textual or \\nvisual inputs, whereby visual encompasses a diverse range of \\ncontent that includes both images and videos. In this domain, \\nthere are notable tools designed to accommodate exclusively \\ntext-based descriptions as inputs. A prime example is ‘ Parti ’ \\nby Google,  and DALL  E-2 [117]  by openAI  are proficient \\ntools focused on creating videos solely from textual prompts. \\nNonetheless, the field of video generation is in a state of \\ncontinuous evolution. Tools such as ‘ Gen-2’ by RunwayML, \\n‘Imagen Video ’ by Google [118] , and ‘ Make -A-Video ’ by \\nMeta[119]   have emerged as pioneers. These advanced \\nplatforms possess the remarkable capability unlimited to \\n\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 8}),\n",
       " Document(page_content='  textual descriptions but also seamlessly integrate images and \\nvideos as input, transcending conventional boundaries. Their \\nexcellence lies in their adeptness at transforming these inputs \\ninto entirely novel video compositions, thus unveiling the exciting potential of generative AI in the creative realm of video production.  \\n  \\n \\n \\n(a) \\n \\n(b) \\n \\n                             FIGURE 10. (a) Adobe firefly, (b) stable diffusion image generated using text “ college Student  \\n                                               Programming”.  \\n \\n \\n', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 9}),\n",
       " Document(page_content=\"   \\nD. CODE GENERATION  \\nCode generation tools are specialized software utilities \\ncapable of automatically producing code blocks for various \\nprogramming languages based on textual descriptions \\nprovided as input [120] . These tools leverage sophisticated \\nmodels trained on extensive publicly available code \\nrepositories, boasting billions of parameters. Their primary \\nobjective is to assist human developers by comprehending \\nplain English and translating it into functional code. Notable \\nexamples of such tools include StarCoder  [121] , Codex\\n [122] , CoPilot,  Codey, and Code Interpreter. \\nAdditionally, it's worth noting that several text- to-text tools, \\nincluding ChatGPT  and Bard as depicted by F igure  13 , also \\npossess the capacity to generate code.   \\n E. MUSI C GENERATION  \\nIt's a fascinating generative task involving entirely new music's \\ncomposition. This innovative process takes input in various forms, including textual descriptions, sequences of musical \\nnotes, and even audio samples [123] . The objective is to \\nharness these inputs and transform them into fresh musical \\ncompositions that encapsulate rhythm, melody, harmonious \\nchords, and diverse musical instruments. Prominent tools like \\nMuseNet  [124]  and Jukebox[125]  stand out as prime examples \\nin the music  generation. These innovative platforms harness \\nthe power of generative AI to craft musical compositions spanning various genres and styles. They excel in infusing creativity into the art of music, opening  new avenues for artists \\nand enthusiasts to explore and enjoy.  \\n \\n \\n         \\nFIGURE 11 . (a) Original Living Room [126]  and (b) Generated new living room using roomGPT  \\n \\n \\n           a  \\n                    b  \\nFIGURE 12. (a) Original BSU Natural Science Building [127]  and  (b) Generated new living room  using runway with prompt  \\n \\n  \\n                                       a                                            b \\n\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 10}),\n",
       " Document(page_content=\"   \\na  \\nb \\n \\nFIGURE 1 3. Code generation using ( a) ChatGPT and (b) Bard\\n \\nF. SPEECH GENERATION  \\nThe generation of human- like speech or voice relies on \\ntextual or audio input. Textual input can encompass written \\ntext, such as sentences, paragraphs, or entire documents, and \\nit can span multiple languages, including punctuation, \\nspecial symbols, and for matting instructions. Speech \\ngeneration models, such as SpeechGAN, undertake a \\nsequence of steps that involve speech synthesis, enhancement, and conversion. The enhancement process \\nincludes noise handling, tone modulation, emotion \\nconveyance, and other nua nced features [128] [129] . \\nNumerous tools have been developed in this domain to \\nfacilitate speech generation, some of which include Whisper, \\nSpeechelo, Synthesys, Voice Over, and WaveNet. These tools are proficient in generating voices or speech that closely mimic natural language , effectively blurring the line \\nbetween human and artificial speech synthesis.  \\nG. SCIENTIFIC CONTENT GENERATION  \\nScientific content generation is a multifaceted process \\nencompassing the creation of informative and scholarly content across various domains of science, including \\nmathematics, physics, chemistry, and biology. This endeavor seeks to harness the power of generative AI to produce \\ncontent that is accurate and insightful, aiding in \\ndisseminating scientific knowledge. O ne notable study in \\nthis field, conducted by Rodriguez  et el. [130] , delved into the \\ninnovative way of generating scientific figures based on textual input. This groundbreaking research leveraged \\ndiffusion models to seamlessly translate textual descriptions \\ninto visually informative scientific figures, thereby \\nstreamlinin g the process of scientific communication and \\nvisualization. Furthermore, Google's ongoing research project, Minerva[131] , represents a significant stride in \\nsolving quantitative reasoning problems. This initiative \\nharnesses the capabilities of Large Language Models \\n(LLMs) to tackle complex quantitative challenges, thereby \\nenhancing our understanding of mathematics and its \\npractical applications within the scientific landscape. In \\nparallel, Galactica [132] , a cutting -edge tool developed by \\nMeta AI, plays a pivotal role in scientific writing. This \\nplatform equips scientists and researchers with powerful \\ntools to streamline articulating their scientific discoveries, theories, and insights.  \\n \\n \\nTABLE  2 \\nGENERETIVE  AI TOOLS  \\n  Tool   Developer  Task   Year  Additional Description  \\n1 VoiceBox  Meta AI  Text-to-Speech  2023  Generate voice clips  \\n2 Genny  Lovo  Text-to-Speech , \\nText-to-Image  2020  Can generate voice over and art image  \\n3 Metamate  Meta AI  Text-to-Code  2023  Software debugging  \\n\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 11}),\n",
       " Document(page_content='  4 Scribe AI  Scribe  Computer Vision  2023  Creates Documentation, how -to guides, \\nSOPs and training manuals  \\n5 Read  Read.ai  Speech -to-Text 2021  Virtual meeting Automated summary, \\ntranscripts, playback, and highlights on  \\naction items, key questions, and real -\\ntime engagement  \\n6 appleGPT  Apple  Text-to-Text 2023  chatbot summarize text and answer \\nquestions  \\n7 Einstein \\nGPT  SalesForce  Text-to-Text 2023  Chatbot built in top for chatGPT  which \\ngenerate text, translate languages, write different kinds of creative content, and \\nanswer questions  \\n8 flashGPT  Neuroflash  Text-to-Text 2020  A generative Chatbot which use flash   \\n9 AlphaCode  DeepMind  Text-to-Code  2022  Generate code,creative content, and \\nrespond to questions in an informative \\nway \\n10 Cloude 2  Anthropic  Text-to-Text 2023  Content Generation, AI Assistant  \\n11 Jasper  Jasper  Text-to-Text 2021  Generate Creative Contents  \\n12 PaLM 2  Google  Text-to-Text 2023  Generate code, creative content, \\nTranslation and Q&A  \\n13 Shepherd  Meta AI  Text-to-Text 2023  Improve the accuracy of AI generated \\nresponse  \\n14 Murf  Murf.Ai  Text-to-Speech  2020  Generate voice -over for  Creative \\ncontents and Presentation  \\n15 Codex  OpenAI  Text-to-Code  2021  Code Generator  \\n16 Codey  Google  Text-to-Code  2023  Generate Code based on user input  \\n17 DALL -E 2 OpenAI  Text-to-Image  2023  Generate image from text description  \\n18 DeepDream  Google  Text-to-Image  2015  Generate psychedelic images  \\n19 Midjourney  Midjourney, Inc  Text-to-Image  2022  Generate realistic and creative image \\nfrom text prompt  \\n20 Firefly  Adobe  Text-to-Image  2023  Generative image from text prompt  \\n21 RoomGPT  RoomGPT.io  Text-to-Image  2023  Design home and room  \\n22  StyleGAN  Nvidia  Text-to-Image  2019  Generate realistic and creative image \\nfrom text prompt  \\n23 Stable \\ndiffusion  Stability AI  Text-to-Image  2022  Generate photo -realistic images given \\nany text input  \\n24 NovelAI  Anlatan  Text-to-Image  2021  Generate image from text input and \\nstrorywriting  \\n25 CM3leon  Meta AI  Text-to-Image  2023  generate  text and images  \\n26 Imagen  Google  Text-to-Image  2023  Generate realistic image  \\n27 Photosonic  Writesonic  Text-to-Image  2020  Generate image from text input  \\n28 AI Art  Nightcafe  Text-to-Image  2019  Generate image from text input  \\n29 Canva AI  Canva  Text-to-Image  2023  Generate image from text input  \\n30 Dreamstudi\\no Stability AI  Text-to-Image  2022  Generate photo -realistic images given \\nany text input  \\n31 StarryAI  StarryAI Inc  Text-to-Image  2021  Generate image from text input  \\n32 ChatSonic  Writesonic  Text-to-Image, \\nText-to-Text,  2022  Conversational chatbot which can \\ngenerate human text response and \\nimage  \\n33 Soundful  soundful  Text-to-Music  2021  Create customized music based on \\nindividual needs  ', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 12}),\n",
       " Document(page_content=\"  34 Boomy  Boomy  Text-to-Music  2019  Develop music without prior \\nknowledge.  \\n35 Soundraw  Soundraw Inc  Text-to-Music  2021  Generate Music  \\n36 AudioCraft  Meta AI  Text-to-Music  2023  Music Generator  \\n37 MusicGen  Meta AI  Text-to-Music  2023  Music Generator  \\n38 Galactica  Meta AI  Text-to-Science  2022  tool for scientific writing  \\n39 Minerva  Google  Text-to-Science  2022  Solve Quantitative reasoning problem  \\n40 WaveNet  DeepMind  Text-to-Speech  2016  Generate realistic speech from text or \\nother audio inputs  \\n41 Voice Over  Speechify  Text-to-Speech  N/A Creates natural Voiceovers for any \\nContent  \\n42 TexTalky  Textalky  Text-to-Speech  2021  Creates realistic voice from text  \\n43 speechelo  speechelo  Text-to-Speech    Creates realistic voice from text  \\n44 Overdub  Descript's  Text-to-Speech  2021  Creates realistic voice from text  \\n45 Synthesys  Synthesys  Text-to-Speech  2020  Create voiceover from text  \\n46 Kits kits Text-to-Speech  N/A Voice generator  \\n47 WellSaid  WellSaid Lab  Text-to-Speech   N/A Voice generator  \\n48 Altered \\nStudio  Altered  Text-to-Speech  2023  Voice generator  \\n49 Whisper  OpenAI  Text-to-Speech  2022  Speech  recorgnition and translation  \\n50 Jukebox  OpenAI  Text-to-Speech  2020  Music Generator  \\n51 LaMDA 2  Google  Text-to-Speech  2022  Customer Service Chatbots, Q&A, \\nTranslation, Research  \\n52 PEER  Meta AI  Text-to-Speech  2022  Writing tool  \\n53 chatGPT  OpenAI  Text-to-Text 2022  Conversational chatbot that generates \\nhuman -like text responses  \\n54 Bard  Google  Text-to-Text 2023  Conversational chatbot that generates \\nhuman -like text responses  \\n55 Generate  Cohere  Text-to-Text 2022  Content Generation  \\n56 chatGPT \\nplus (GPT -\\n4) OpenAI  Text-to-Text 2023  Advanced ChatGPT, Conversational \\nchatbot that generates human- like text \\nresponses  \\n57 Wordtune \\nSpice  AI21 Labs  Text-to-Text 2023  Writing Generator  \\n58 Gen-2 RunwayML  Text-to-Video  2023  Design video from text input  \\n59 Synthesia  Synthesia  Text-to-Video  2018  Generate video from text input  \\n60 Make -A-\\nVideo  Meta AI  Text-to-Video  2022  Generate video from text input  \\n61 Imagen \\nVideo  Google  Text-to-Video  2022  1280x768 HD videos at 24 frames per \\nsecond from text  limited  to inanimate \\nobjects  \\n62 Phenaki  Google  Text-to-Video  2023  Generate video from text input of \\nanimate objects  \\n63 Descript  Descript  Text-to-Video  2020  Generate video from text input  \\n64 GitHub \\nCopilot  Microsoft/GitHub/OpenA\\nI Text-to-Code  2021  Code Generator and Suggestion  \\n65 Sensei   Adobe  Text-to-Image  2017  Generate automative workflow and \\npersonalize cunstomer experience  \\n66 parti Google  Text-to-Image  2023    \\n67 StarCoder  Hugginface + \\nServiceNow  Text-to-Code  2023  state-of-the-art large language model \\n(LLM) for code  \", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 13}),\n",
       " Document(page_content=\"  68 Amper  Amper  Text-to-Music  2023  Generate Music of various genres  \\n69 MuseNet  OpenAI  Text-to-Music  2019  Generate Music of various genres  \\n70 MusicLM  Google  Text-to-Music  2023  Generate Music of various genres  \\n71 quillbot  Course Hero  Text-to-Text   Can paraphrase, rewrite  the text  \\n72 Rephrase.ai  Rephrase.ai  Text-to-Video    Can Generate video using avatar by text \\nprompt  \\n73 Studio bot  Google  Text-to-Code  2023  Code Companion for android developer  \\n \\n \\n \\nIV.        INDUSTIRIAL APPLICATION OF \\nGENERATIVE  AI \\nGenerative AI technology's relevance in the present and future is indispensable. Currently, Generative AI is exerting \\nan exponential impact across a broad spectrum of industries, \\nand this section will delve into a detailed exploration of the \\nsectors that are mostly impacted . \\nA. MEDIA AND ENTERTAINMENT  \\nIn the entertainment industry, Generative AI models are \\nbeginning to have a significant impact despite being in their \\nearly stages. Their influence spans various entertainment \\ndomains, encompassing scriptwriting and storyboarding for novels, plays, and fil ms, audio production [133]  involving \\ncomposition, arrangement, and mixing, game design and \\ncharacter creation, the creation of captivating virtual worlds, \\nmarketing campaigns, and the generation of both moving and \\nstatic images. Notably, a wide range of accessible tools, as \\ndemonst rated in Table 3, make it easier to generate content \\nsuch as reels, jokes, and images [134] . Many of these tools \\nare cost -effective or even free, providing an alternative to \\ntraditional content creation methods. As an illustration of their potential, in 2022, RunwayAI  played a role in creating \\nthe Academy Award -winning film “Everything Everywhere \\nAll at Once ” which  received recognition with seven  Oscars  \\naward [135]  [136] . \\nB. EDUCATION AND RESEARCH \\nGenerative AI is rapidly reshaping the educational landscape, offering innovative solutions that elevate the \\nlearning experience for both students and educators. One \\nsignificant impact of Generative AI in education is the \\nemergence of personalized content generation tools. \\nExemplified by technologies like GPT -3, GPT -4 and Bard , \\nthese tools empower educators to craft tailored learning \\nmaterials, including interactive lessons, quizzes, and study \\nguides, precisely catering to the unique needs of individual \\nstudents  and instructors [137] . Furthermore, AI -driven \\nchatbots and virtual tutors provide students with real -time \\nsupport, offering explanations, addressing queries, and \\ndelivering personalized feedback [138] . This transformative \\ntechnology holds the potential to reinvent how students \\naccess and engage with educational content, promoting \\naccessibility and adaptability according to each learner's \\nspecific preferences [139]  [140] .      Generative AI has also opened new avenues of research \\nand academic exploration. The rapid development of \\nGenerative AI tools has piqued the interest of researchers and \\nacademics across the globe, leading to an array of research \\nopportunities  [141] . Tech giants and research institutions are \\ninvesting significant resources to explore and invent new tools and technologies in this field. This is evident in the surge of publications related to Generative AI, both in peer -\\nreviewed databases like IEEE and  non-reviewed platforms \\nlike arXiv, where Generative AI topics have gained prominence. The fusion of education and Generative AI has not only transformed the learning experience but has also \\nsparked a thriving academic domain that promises continued \\ngrowth and innovation [142] . \\nC. HEALTHCARE  \\nGenerative AI is making substantial inroads in healthcare, particularly in medical imaging [143] . It plays a crucial role \\nin overcoming challenges related to limited datasets by \\nenabling the synthesis of new data [144]  [145] , ultimately \\nenhancing the quality and diversity of medical images. This \\ninnovation is set to revolutionize disease detection and \\ndiagnosis, providing healthcare professionals with more \\naccurate and detailed information. In addition, Generative AI \\nis trans forming the administrative aspects of patient care. By \\nstreamlining administrative processes and offering virtual \\nhealth assistants, it simplifies healthcare management and provides personalized health advice, medication reminders, \\nand emotional support [146] .Moreover, Generative AI is \\nrevolutionizing treatment planning. Leveraging patient -\\nspecific data, it can generate customized treatment plans tailored to an individual's genetic makeup, lifestyle, and \\nmedical history. This approach represents a significant leap \\ntoward precision medicine, ensuring patients receive the \\nmost effective and personalized treatment.  \\n      Furthermore, Generative AI is playing a pivotal role in \\nthe realm of drug development and discovery[147]  [148]  \\n[149] . Through the generation of molecular structures [150]  \\nand predictive modeling, it expedites the identification of novel therapeutic compounds. These advancements can \\naddress previously untreatable diseases, instilling hope in \\ncountless patients across the globe. Notably, the \\ncollaboration between NVIDIA and Evozyne in \\nimplementing Generative AI, specifically ProT -VAE, \\nsignifies the remarkable synergy between AI and the healthcare sector. By employing the Protein Transformer \\nVariational AutoEncoder, they have laid the groundwork for \", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content=\"  creating synthetic proteins [151] , opening up new avenues for \\ntherapeutic solutions in the fight against challenging \\nincurable diseases.  Yet another noteworthy example is the \\ncollaborative research venture between Google and Cognizant [152] . Their joint effort aims to construct a Large \\nLanguage Model (LLM) tailored for healthcare applications, \\nspecifically focusing on enhancing Healthcare \\nadministrative tasks. This endeavor harnesses the \\ncapabilities of Google Cloud and its framework to crea te \\ncutting -edge generative AI solutions for the healthcare \\nsector.  \\nD. BUSINESS  \\nGenerative AI has firmly established its presence in the business landscape. Many of the applications listed in Table 3 operate on a subscription -based model, reflecting the \\ngrowing commercial nature of these tools. Bloomberg \\nIntelligence predicts that Gen erative AI (GAI) will generate \\n$137 billion in 2023 and is expected to surge to $1.3 trillion \\nby 2030[153] . This profound impact extends across various \\nindustries, from manufacturing and wholesale to retail businesses, banking, agriculture, and many more. Generative \\nAI's reach spans from creating new products and automating \\nfinancial data analysis to generatin g personalized advertising \\ncampaigns [154] [155]  [156] , offering tailored product \\nrecommendations to customers, and producing product \\ndescriptions and news articles [157] . It is increasingly evident \\nthat Generative AI is reshaping the business landscape and holds immense economic potential in the future.  \\n      For example, Amazon is actively harnessing Generative \\nAI capabilities to empower sellers in crafting engaging, compelling, and effective product listings through brief \\ndescriptions of their products. Amazon leverages Generative \\nAI to generate high- quality content, which sellers can further \\nrefine or directly submit to enrich the Amazon catalog[158] . \\n \\nV. THE FUTURE OF GENERATIVE AI  \\nGenerative AI undoubtedly holds a significant and promising future, offering a plethora of tangible and transformative \\npossibilities across various domains. However, it is equally \\naccompanied by a considerable degree of uncertainty and a \\nrange of concerns that deserve in -depth exploration. This \\nsection aims to explore the multifaceted aspects of Generative AI, addressing its potential as well as the \\nchallenges and uncertainties that lie ahead.  \\n \\nA. PIONEER OF FIR FTH INDUSTRIAL \\nREVOLUTION  (5IR)  \\nGenerative AI represents the promising frontier of the fifth \\nindustrial revolution (5IR), a force poised to revolutionize \\nthe fourth industrial revolution and create transformative \\nchanges across various sectors. This transformation is made possible by the  profound interconnection of internet \\ninfrastructure, extensive datasets, and distributed computing resources that transcend geographical \\nboundaries. Several industries, including Healthcare, \\nSecurity, Cyber Infrastructure, Entertainment, and Education, ar e on the verge of significant disruption due to \\nGenerative AI's capabilities. However, it's crucial to \\nrecognize that this disruptive potential may also bring about \\ninfrastructure reforms across multiple sectors, potentially \\nleading to high levels of autom ation and optimization in \\nvarious career fields.  \\nOn Healthcare Industry , as we have witnessed, \\nGenerative AI is already playing a pivotal role in drug discovery, with a particular emphasis on exploring protein molecules. The potential for this technology in the field of \\ndrug development is vast, and substantial investments from \\nmajor technology companies underscore the anticipated \\nadvancements in the near future. However, the impact of \\nGenerative AI extends far beyond drug development, as it \\nis expected to transform the patient experience within the \\nhealt hcare sector fundamentally. By harnessing patients' \\nmedical history data, it can autonomously diagnose medical \\nconditions by analyzing metadata like age, sex, and \\nunderlying medical conditions. Moreover, it can sift \\nthrough extensive patient data to identi fy patterns, make \\npredictions, and suggest appropriate medications. This \\ntransformation is set to prioritize patient- centered clinical \\nexperiences and drive cost -effectiveness, ultimately leading \\nto significant enhancements in healthcare protocols [159] . \\nEnhance d Entertainment , In the foreseeable future, \\nwe stand at the threshold of a transformative era where generative AI will likely dominate the realm of content \\ncreation in entertainment and media. From crafting intricate \\nscripts and narratives to meticulously arranging scenes and \\nbringing characters to life, the influence of generative AI is \\nset to permeate every facet of content gen eration in these \\nindustries. Furthermore, the potential impact is so profound \\nthat it might even challenge the boundaries of life and art. \\nDeceased artists could potentially continue to release new albums and creative works, effectively transcending the \\nlimitations of mortality. Not only will this innovation usher \\nin a new age of artistic exploration, but it also promises \\nsignificant cost savings, revolutionizing the economics of movie and music production. Automating scene creation \\nand content generation w ill reduce expenses and make the \\ncreation process more efficient.  \\nNew education era, the advent of AI chatbots like \\nChatGPT and Google Bard, along with other innovative \\ntools, serves as compelling evidence of the democratization of Generative AI in the education industry. This remarkable \\nprogress has rendered the current educational system an d \\nresources outdated, particularly in developed countries. It \\nanticipates a comprehensive overhaul of the education \\nsystem, including teaching resources, to adapt to the \\nexponential growth in the generative AI era, aiming to provide highly personalized and adaptive learning \\nexperiences.  \\nAdvanced Manufa cturing Industries,  before the \\nemergence of Generative AI, robotics had already showcased impressive capabilities. However, with the \\nintegration of generative AI, we can look forward to truly remarkable advancements. Just envision the consequences \", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='  of infusing generative AI into military technology, where \\nwe might see the development of generative nuclear \\nweaponry, the formulation of chemical recipes for \\nbeverages, detergents, and various industrial products, and \\nthe widespread adoption of self -drivi ng vehicles. The range \\nof possibilities is extensive, and it undoubtedly signifies the \\nonset of a new era —an industrial revolution that promises \\na thoroughly transformed landscape and innovative \\napproaches across numerous sectors of industries.  \\nB. JOB MARKET SHIFTING  \\nThe influence of Generative AI on the labor market is two -\\nfold:  \\nFirstly, it ushers in new employment opportunitie s in \\nemerging domains such as AI Explainability and Generative AI engineering. McKinsey\\'s analysis  [160]  suggests a \\ngradual rise in job openings within professions exposed to \\nGenerative AI, and this trend is expected to persist until \\nroughly 2030. A noteworthy revelation is that a substantial \\n84% of the U.S. workforce occupies positions with the \\npotential to  leverage Generative AI for automating a \\nsignificant portion of repetitive tasks, leading to a \\nconsiderable surge in overall productivity. Significantly, \\n47% of U.S. executives express confidence that integrating \\nGenerative AI will lead to heightened produ ctivity across \\ndiverse industries [161]  [162] . \\nConversely, Job deterioration ; optimizing and \\nautomating business processes are anticipated to replace many existing careers with creative and generative AI \\nfunctions. Generative AI\\'s impact on the labor market is \\npoised to transform the employment landscape, gradually replacing many traditional roles with advanced technology. \\nAccording to the World Economic Forum\\'s r eport [163] , \\ntasks with the highest potential for automation by Large \\nLanguage Models (LLMs) are routine and repetitive. These \\ntasks include those performed by Credit Authorizers, \\nCheckers, Clerks, Management Analysts, Telemarketers, \\nStatistical Assistants, and Telle rs[164]  [165] . Therefore, \\nindividuals must prioritize reskilling and adaptability to prepare for AI -driven jobs in the future effectively.  \\nC. PRIVACY AND SECURITY CONCERNS  \\nThe cybersecurity infrastructure domain is presently \\nundergoing a profound and rapid transformation, primarily driven by the integration of Generative AI. This substantial \\nshift is giving rise to a host of pressing concerns and \\nchallenges for the future : \\nSophisticated cyberwarfare, currently , we are \\nwitnessing a notable surge in malicious activities, and this trend is expected to continue its upward trajectory while \\nalso becoming more intricate and sophisticated[166] . For \\ninstance  the emergence of cutting -edge cyber threat tools \\nlike WormGPT and FraudGPT [167]  [168] , which have \\nrapidly established themselves as pioneering elements in cyber threats often referred to as “ exclusive bots ” [169]  by \\ntheir perpetrators, are engineered to be highly sophisticated and evasive. Moreover, the emergence of increasingly automated and sophisticated malware and ransomware, \\npowered by Generative A I[170] , presents a menacing \\npotential for subverting existing encryption methods [171] . \\nThis is primarily due to the immense computational prowess inherent in Generative AI. As these malicious \\nentities persist and advance, they represent a formidable \\nchallenge to the cybersecurity landscape, testing the limits \\nof the resilience and robustne ss of contemporary \\ncybersecurity systems and protocols [172] . The \\nconsequences of these developments are far -reaching, with \\nthe prospect of malicious AI proving to be devastating to a nation\\'s critical infrastructure, particularly in scenarios \\ninvolving state -sponsored or malevolent cyber \\nterrorism [173] . \\n \\nIncreased Impersonation  and misinformation , \\nescalation of AI advancements across various domains, \\nvisual, speech, audio, and text -based applications, has \\nsignificantly elevated concerns surrounding personal \\nprivacy breaches and impersonation. A pertinent example is the music industry, where AI -drive n ghostwriters have \\nreleased a fake audio tracks emulating the voices of \\nrenowned artists like Drake and The Weeknd, both of \\nwhom are global music sensations [174] . Tracks like \"Heart \\non My Sleeve\" and \"Cuff It\" featuring AI -rendered versions \\nof Rihanna and Beyoncé\\'s voices [175] , have garnered \\nattention for their remarkably convincing mimicry. \\nConsequently, the creative industry faces substantial threats, particularly sectors reliant on advanced artificial \\nintelligence. As reported, these technologies can potentially \\njeopardize careers within the entertainment industry.  \\n \\n \\nVI. CONCLUSION  \\nIn conclusion, Generative AI opens the door to a world filled \\nwith both unprecedented opportunities and inherent risks. \\nFurther in -depth research is necessary to comprehend its \\nmultifaceted impacts across various sectors better and develop effective mitiga tion strategies. Striking a balance \\nbetween the potential benefits and threats posed by \\nGenerative AI is essential to serve humanity\\'s needs best. \\nThroughout this paper, we have delved into state -of-the-art \\nmodels, explored their mathematical foundations, scrutinized their architectural intricacies, and anticipated their evolution in the future. We have also examined \\nprominent tasks, benchmarked state -of-the-art tools against \\nGenerative AI, and assessed their real -world applications. \\nThe realms of impact, c hallenges, and future prospects of \\nGenerative AI have been thoroughly addressed.  \\n       The journey to harness the full potential of Generative \\nAI is ongoing, requiring swift and thoughtful actions from \\nregulatory authorities to ensure order and alignment with the \\nrapid advancements in AI technology sweeping the world. \\nThe role of Explainabil ity AI, Responsive AI, and Privacy -\\nPreserving AI becomes increasingly crucial in this context. \\nThe future is bright, but as we move forward, maintaining a \\ndelicate equilibrium between the opportunities and risks ', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='  presented by Generative AI is paramount to realizing its full \\nutility and ensuring it serves humanity effectively.  \\n \\n \\nREFERENCES  \\n[1] J. McCarthy, M. L. Minsky, N. Rochester, I. B. M. \\nCorporation, and C. E. Shannon, “A PROPOSAL FOR THE DARTMOUTH SUMMER RESEARCH \\nPROJECT ON ARTIFICIAL INTELLIGENCE”.  \\n[2] C. Zhang and Y. Lu, “Study on artificial intelligence: \\nThe state of the art and future prospects,” J. Ind. Inf. \\nIntegr. , vol. 23, p. 100224, Sep. 2021, doi: \\n10.1016/j.jii.2021.100224.  \\n[3] N. J. Nilsson, The Quest for Artificial Intelligence . \\nCambridge University Press, 2009.  \\n[4] P. Hamet and J. Tremblay, “Artificial intelligence in medicine,” Metabolism , vol. 69, pp. S36– S40, Apr. \\n2017, doi: 10.1016/j.metabol.2017.01.011.  \\n[5] R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, Machine Learning: An Artificial Intelligence Approach. \\nSpringer Science & Business Media, 2013.  \\n[6] D. L. Du Yi, Artificial Intelligence with Uncertainty , \\n2nd ed. Boca Raton: CRC Press, 2016. doi: 10.1201/9781315366951.  \\n[7] F. Rosenblatt, “The perceptron: A probabilistic model \\nfor information storage and organization in the brain,” \\nPsychol. Rev. , vol. 65, no. 6, pp. 386– 408, 1958, doi: \\n10.1037/h0042519.  \\n[8] J. N. Morgan and J. A. Sonquist, “Problems in the Analysis of Survey Data, and a Proposal,” J. Am. Stat. \\nAssoc. , vol. 58, no. 302, pp. 415– 434, Jun. 1963, doi: \\n10.1080/01621459.1963.10500855.  \\n[9] E. Fix and J. L. Hodges, “Discriminatory Analysis. \\nNonparametric Discrimination: Consistency \\nProperties,” Int. Stat. Rev. Rev. Int. Stat. , vol. 57, no. 3, \\npp. 238– 247, 1989, doi: 10.2307/1403797.  \\n[10] J. Platt, “Sequential Minimal Optimization: A Fast \\nAlgorithm for Training Support Vector Machines,” Apr. \\n1998, Accessed: Sep. 30, 2023. [Online]. Available: https://www.microsoft.com/en -\\nus/research/publication/sequential -minimal-\\noptimization -a-fast-algorithm -for-training -support -\\nvector -machines/  \\n[11] L. Breiman, “Random Forests,” Mach. Learn. , vol. 45, \\nno. 1, pp. 5– 32, Oct. 2001, doi: \\n10.1023/A:1010933404324.  \\n[12] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, \\n“Gradient -based learning applied to document \\nrecognition,” Proc. IEEE , vol. 86, no. 11, pp. 2278–\\n2324, Nov. 1998, doi: 10.1109/5.726791.  \\n[13] J. J. Hopfield and D. W. Tank, “‘Neural’ computation \\nof decisions in optimization problems,” Biol. Cybern. , \\nvol. 52, no. 3, pp. 141 –152, Jul. 1985, doi: \\n10.1007/BF00339943.  \\n[14] S. Hochreiter and J. Schmidhuber, “Long Short -Term \\nMemory,” Neural Comput. , vol. 9, no. 8, pp. 1735–\\n1780, Nov. 1997, doi: 10.1162/neco.1997.9.8.1735.  [15] M. Schuster and K. K. Paliwal, “Bidirectional recurrent \\nneural networks,” IEEE Trans. Signal Process. , vol. 45, \\nno. 11, pp. 2673– 2681, Nov. 1997, doi: \\n10.1109/78.650093.  \\n[16] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” \\nNature , vol. 521, no. 7553, Art. no. 7553, May 2015, \\ndoi: 10.1038/nature14539.  \\n[17] O. Russakovsky et al. , “ImageNet Large Scale Visual \\nRecognition Challenge,” Int. J. Comput. Vis. , vol. 115, \\nno. 3, pp. 211 –252, Dec. 2015, doi: 10.1007/s11263-\\n015-0816- y. \\n[18] S. Cong and Y. Zhou, “A review of convolutional neural \\nnetwork architectures and their optimizations,” Artif. \\nIntell. Rev. , vol. 56, no. 3, pp. 1905– 1969, Mar. 2023, \\ndoi: 10.1007/s10462- 022-10213- 5. \\n[19] A. Krizhevsky, I. Sutskever, and G. E. Hinton, \\n“ImageNet Classification with Deep Convolutional Neural Networks,” in Advances in Neural Information \\nProcessing Systems , Curran Associates, Inc., 2012. \\nAccessed: Sep. 30, 2023. [Online]. Available: \\nhttps://proceedings.neurips.cc/paper/2012/hash/c39986\\n2d3b9d6b76c8436e924a68c45b- Abstract.html  \\n[20] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual \\nLearning for Image Recognition,” presented at the \\nProceedings of the IEEE Conference on Computer \\nVision and Pattern Recognition, 2016, pp. 770 –778. \\nAccessed: Sep. 30, 2023. [Online]. Available: \\nhttps ://openaccess.thecvf.com/content_cvpr_2016/html\\n/He_Deep_Residual_Learning_CVPR_2016_paper.ht\\nml \\n[21] G. Huang, Z. Liu, L. van der Maaten, and K. Q. \\nWeinberger, “Densely Connected Convolutional \\nNetworks,” presented at the Proceedings of the IEEE \\nConference on Computer Vision and Pattern \\nRecognition, 2017, pp. 4700– 4708. Accessed: Sep. 30, \\n2023. [Onlin e]. Available: \\nhttps://openaccess.thecvf.com/content_cvpr_2017/html\\n/Huang_Densely_Connected_Convolutional_CVPR_2\\n017_paper.html  \\n[22] A. G. Howard et al. , “MobileNets: Efficient \\nConvolutional Neural Networks for Mobile Vision \\nApplications,” arXiv.org. Accessed: Sep. 30, 2023. \\n[Online]. Available: \\nhttps://arxiv.org/abs/1704.04861v1  \\n[23] M. Tan and Q. Le, “EfficientNet: Rethinking Model \\nScaling for Convolutional Neural Networks,” in \\nProceedings of the 36th International Conference on \\nMachine Learning, PMLR, May 2019, pp. 6105– 6114. \\nAccessed: Sep. 30, 2023. [Online]. Available: https://proceedings.mlr.press/v97/tan19a.html  \\n[24] A. Vaswani et al. , “Attention is All you Need,” in \\nAdvances in Neural Information Processing Systems , \\nCurran Associates, Inc., 2017. Accessed: Aug. 15, 2023. \\n[Online]. Available: \\nhttps://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa -\\nAbstract.html ', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='  [25] I. J. Goodfellow et al. , “Generative Adversarial \\nNetworks.” arXiv, Jun. 10, 2014. doi: \\n10.48550/arXiv.1406.2661.  \\n[26] C. Zheng, G. Wu, F. Bao, Y. Cao, C. Li, and J. Zhu, “Revisiting Discriminative vs. Generative Classifiers: Theory and Implications.” arXiv, May 29, 2023. doi: \\n10.48550/arXiv.2302.02334.  \\n[27] E. Brophy, Z. Wang, Q. She, and T. Ward, “Generative \\nAdversarial Networks in Time Series: A Systematic \\nLiterature Review,” ACM Comput. Surv. , vol. 55, no. \\n10, p. 199:1- 199:31, Feb. 2023, doi: 10.1145/3559540.  \\n[28] G. Zhou et al. , “Emerging Synergies in Causality and \\nDeep Generative Models: A Survey.” arXiv, Sep. 14, 2023. doi: 10.48550/arXiv.2301.12351.  \\n[29] N. R. Mannuru et al. , “Artificial intelligence in \\ndeveloping countries: The impact of generative artificial \\nintelligence (AI) technologies for development,” Inf. Dev., p. 02666669231200628, Sep. 2023, doi: \\n10.1177/02666669231200628.  \\n[30] “Introducing ChatGPT.” Accessed: Sep. 30, 2023. \\n[Online]. Available: https://openai.com/blog/chatgpt  \\n[31] C. Leiter et al. , “ChatGPT: A Meta- Analysis after 2.5 \\nMonths.” arXiv, Feb. 20, 2023. doi: \\n10.48550/arXiv.2302.13795.  \\n[32] D. Bank, N. Koenigstein, and R. Giryes, \\n“Autoencoders.” arXiv, Apr. 03, 2021. doi: \\n10.48550/arXiv.2003.05991.  \\n[33] U. Michelucci, “An Introduction to Autoencoders.” \\narXiv, Jan. 11, 2022. doi: 10.48550/arXiv.2201.03898.  \\n[34] J. Zhai, S. Zhang, J. Chen, and Q. He, “Autoencoder and Its Various Variants,” in 2018 IEEE International \\nConference on Systems, Man, and Cybernetics (SMC) , \\nOct. 2018, pp. 415– 419. doi: \\n10.1109/SMC.2018.00080.  \\n[35] D. P. Kingma, S. Mohamed, D. Jimenez Rezende, and \\nM. Welling, “Semi -supervised Learning with Deep \\nGenerative Models,” in Advances in Neural Information \\nProcessing Systems , Curran Associates, Inc., 2014. \\nAccessed: Aug. 07, 2023. [Online]. Available: https://proceedings.neurips.cc/paper/2014/hash/d52377\\n3c6b194f37b938d340d5d02232- Abstract.html  \\n[36] D. P. Kingma and M. Welling, “An Introduction to \\nVariational Autoencoders,” Found. Trends® Mach. \\nLearn. , vol. 12, no. 4, pp. 307– 392, 2019, doi: \\n10.1561/2200000056.  \\n[37] H. Akrami, A. A. Joshi, J. Li, S. Aydore, and R. M. \\nLeahy, “Brain Lesion Detection Using A Robust \\nVariational Autoencoder and Transfer Learning,” in \\n2020 IEEE 17th International Symposium on \\nBiomedical Imaging (ISBI) , Apr. 2020, pp. 786– 790. \\ndoi: 10.1109/ISBI45749.2020.9098405.  \\n[38] X. Shen, B. Liu, Y. Zhou, J. Zhao, and M. Liu, “Remote \\nsensing image captioning via Variational Autoencoder \\nand Reinforcement Learning,” Knowl. -Based Syst. , vol. \\n203, p. 105920, Sep. 2020, doi: 10.1016/j.knosys.2020.105920.  [39] G. Zhao and Y. Peng, “Semisupervised SAR image \\nchange detection based on a siamese variational \\nautoencoder,” Inf. Process. Manag. , vol. 59, no. 1, p. \\n102726, Jan. 2022, doi: 10.1016/j.ipm.2021.102726.  \\n[40] H. W. L. Mak, R. Han, and H. H. F. Yin, “Application of Variational AutoEncoder (VAE) Model and Image \\nProcessing Approaches in Game Design,” Sensors , vol. \\n23, no. 7, Art. no. 7, Jan. 2023, doi: 10.3390/s23073457.  \\n[41] M. A. Yílmaz, O. Kelesş, H. Güven, A. M. Tekalp, J. \\nMalik, and S. Kíranyaz, “Self -Organized Variational \\nAutoencoders (Self -Vae) For Learned Image \\nCompression,” in 2021 IEEE International Conference \\non Image Processing (ICIP) , Sep. 2021, pp. 3732– 3736. \\ndoi: 10.1109/ICIP42928.2021.9506041.  \\n[42] Z.-S. Liu, W.- C. Siu, and L. -W. Wang, “Variational \\nAutoEncoder for Reference based Image Super -\\nResolution,” in 2021 IEEE/CVF Conference on \\nComputer Vision and Pattern Recognition Workshops \\n(CVPRW), Nashville, TN, USA: IEEE, Jun. 2021, pp. \\n516– 525. doi: 10.1109/CVPRW53098.2021.00063.  \\n[43] G. Carbajal, J. Richter, and T. Gerkmann, “Guided \\nVariational Autoencoder for Speech Enhancement with \\na Supervised Classifier,” in ICASSP 2021 - 2021 IEEE \\nInternational Conference on Acoustics, Speech and Signal Processing (ICASSP) , Jun. 2021, pp. 681– 685. \\ndoi: 10.1109/ICASSP39728.2021.9414363.  \\n[44] T. Srikotr and K. Mano, “Sub- band Vector Quantized \\nVariational AutoEncoder for Spectral Envelope \\nQuantization,” in TENCON 2019 - 2019 IEEE Region \\n10 Conference (TENCON) , Oct. 2019, pp. 296– 300. \\ndoi: 10.1109/TENCON.2019.8929436.  \\n[45] Z. Wang, “Using Gaussian Process in Clockwork \\nVariational Autoencoder for Video Prediction,” in 2022 International Conference on Information Technology \\nResearch and Innovation (ICITRI) , Nov. 2022, pp. 6–\\n11. doi: 10.1109/ICITRI56423.2022.9970241.  \\n[46] M. S. Kim, J. P. Yun, S. Lee, and P. Park, “Unsupervised Anomaly detection of LM Guide Using \\nVariational Autoencoder,” in 2019 11th International \\nSymposium on Advanced Topics in Electrical \\nEngineering (ATEE), Mar. 2019, pp. 1– 5. doi: \\n10.1109/ATEE.2019.8724998.  \\n[47] C. K. Meher, R. Nayak, and U. C. Pati, “Dual Stream \\nVariational Autoencoder for Video Anomaly Detection \\nin Single Scene Videos,” in 2022 2nd Odisha International Conference on Electrical Power \\nEngineering, Communication and Computing \\nTechnology (ODICON) , Nov. 2022, pp. 1– 6. doi: \\n10.1109/ODICON54453.2022.10010086.  \\n[48] H. Yanagihashi and T. Sudo, “Noise -robust Early \\nDetection of Cooling Fan Deterioration with a \\nVariational Autoencoder -based Method,” in 2022 9th \\nInternational Conference on Condition Monitoring and Diagnosis (CMD) , Nov. 2022, pp. 183– 188. doi: \\n10.23919/CMD54214.2022.9991542.  \\n[49] H. Purohit, T. Endo, M. Yamamoto, and Y. Kawaguchi, \\n“Hierarchical Conditional Variational Autoencoder ', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='  Based Acoustic Anomaly Detection,” in 2022 30th \\nEuropean Signal Processing Conference (EUSIPCO) , \\nAug. 2022, pp. 274 –278. doi: \\n10.23919/EUSIPCO55093.2022.9909785.  \\n[50] B. Shen, L. Yao, and Z. Ge, “Nonlinear probabilistic \\nlatent variable regression models for soft sensor \\napplication: From shallow to deep structure,” Control \\nEng. Pract. , vol. 94, p. 104198, Jan. 2020, doi: \\n10.1016/j.conengprac.2019.104198.  \\n[51] B. Shen and Z. Ge, “Supervised Nonlinear Dynamic \\nSystem for Soft Sensor Application Aided by Variational Auto -Encoder,” IEEE Trans. Instrum. \\nMeas. , vol. 69, no. 9, pp. 6132– 6142, Sep. 2020, doi: \\n10.1109/TIM.2020.2968162.  \\n[52] W. Xie, J. Wang, C. Xing, S. Guo, M. Guo, and L. Zhu, “Variational Autoencoder Bidirectional Long and \\nShort -Term Memory Neural Network Soft -Sensor \\nModel Based on Batch Training Strategy,” IEEE Trans. \\nInd. Inform. , vol. 17, no. 8, pp. 5325 –5334, Aug. 2021, \\ndoi: 10.1109/TII.2020.3025204.  \\n[53] R. Xie, N. M. Jan, K. Hao, L. Chen, and B. Huang, \\n“Supervised Variational Autoencoders for Soft Sensor \\nModeling With Missing Data,” IEEE Trans. Ind. \\nInform. , vol. 16, no. 4, pp. 2820– 2828, Apr. 2020, doi: \\n10.1109/TII.2019.2951622.  \\n[54] F. Guo, R. Xie, and B. Huang, “A deep learning just -in-\\ntime modeling approach for soft sensor based on \\nvariational autoencoder,” Chemom. Intell. Lab. Syst. , \\nvol. 197, p. 103922, Feb. 2020, doi: \\n10.1016/j.chemolab.2019.103922.  \\n[55] L. Li, J. Yan, H. Wang, and Y. Jin, “Anomaly Detection \\nof Time Series With Smoothness -Inducing Sequential \\nVariational Auto -Encoder,” IEEE Trans. Neural Netw. \\nLearn. Syst. , vol. 32, no. 3, pp. 1177 –1191, Mar. 2021, \\ndoi: 10.1109/TNNLS.2020.2980749.  \\n[56] N. T. N. Anh, T. Q. Khanh, N. Q. Dat, E. Amouroux, and V. K. Solanki, “Fraud detection via deep neural variational autoencoder oblique random forest,” in 2020 \\nIEEE -HYDCON , Sep. 2020, pp. 1– 6. doi: \\n10.1109/HYDCON48903.2020.9242753.  \\n[57] C. Zhang et al. , “A Complete Survey on Generative AI \\n(AIGC): Is ChatGPT from GPT -4 to GPT -5 All You \\nNeed?” arXiv, Mar. 21, 2023. doi: \\n10.48550/arXiv.2303.11717.  \\n[58] K. Han et al. , “A Survey on Vision Transformer,” IEEE \\nTrans. Pattern Anal. Mach. Intell. , vol. 45, no. 1, pp. \\n87–110, Jan. 2023, doi: \\n10.1109/TPAMI.2022.3152247.  \\n[59] S. Khan, M. Naseer, M. Hayat, S. W. Zamir, F. S. Khan, and M. Shah, “Transformers in Vision: A Survey,” ACM Comput. Surv. , vol. 54, no. 10s, p. 200:1- 200:41, \\nSep. 2022, doi: 10.1145/3505244.  \\n[60] T. Lin, Y. Wang, X. Liu, and X. Qiu, “A survey of transformers,” AI Open , vol. 3, pp. 111– 132, Jan. 2022, \\ndoi: 10.1016/j.aiopen.2022.10.001.  [61] M. Zong and B. Krishnamachari, “a survey on GPT -3.” \\narXiv, Dec. 01, 2022. Accessed: Aug. 15, 2023. [Online]. Available: http://arxiv.org/abs/2212.00857  \\n[62] B. Ghojogh and A. Ghodsi, “Attention Mechanism, Transformers, BERT, and GPT: Tutorial and Survey,” Open Science Framework, preprint, Dec. 2020. doi: \\n10.31219/osf.io/m6gcn.  \\n[63] C. Zhang et al. , “A Complete Survey on Generative AI \\n(AIGC): Is ChatGPT from GPT -4 to GPT -5 All You \\nNeed?” arXiv, Mar. 21, 2023. doi: \\n10.48550/arXiv.2303.11717.  \\n[64] “Generative AI: a game- changer society needs to be \\nready for,” World Economic Forum. Accessed: Aug. \\n16, 2023. [Online]. Available: \\nhttps://www.weforum.org/agenda/2023/01/davos23 -\\ngenerative- ai-a-game- changer -industries -and-society -\\ncode -developers/  \\n[65] A. Radford, K. Narasimhan, T. Salimans, and I. \\nSutskever, “Improving Language Understanding by \\nGenerative Pre- Training”.  \\n[66] I. Solaiman et al. , “Release Strategies and the Social \\nImpacts of Language Models”.  \\n[67] T. Brown et al. , “Language Models are Few -Shot \\nLearners,” Adv. Neural Inf. Process. Syst. , vol. 33, pp. \\n1877 –1901, 2020.  \\n[68] X. Zheng, C. Zhang, and P. C. Woodland, “Adapting \\nGPT, GPT -2 and BERT Language Models for Speech \\nRecognition,” in 2021 IEEE Automatic Speech \\nRecognition and Understanding Workshop (ASRU) , \\nDec. 2021, pp. 162– 168. doi: \\n10.1109/ASRU51503.2021.9688232.  \\n[69] A. Shrivastava, R. Pupale, and P. Singh, “Enhancing \\nAggression Detection using GPT -2 based Data \\nBalancing Technique,” in 2021 5th International \\nConference on Intelligent Computing and Control \\nSystems (ICICCS) , May 2021, pp. 1345 –1350. doi: \\n10.1109/ICICCS51141.2021.9432283.  \\n[70] M. Tamimi, M. Salehi, and S. Najari, “Deceptive review \\ndetection using GAN enhanced by GPT structure and \\nscore of reviews,” in 2023 28th International Computer \\nConference, Computer Society of Iran (CSICC) , Jan. \\n2023, pp. 1– 7. doi: \\n10.1109/CSICC58665.2023.10105368.  \\n[71] S. Saravanan and K. Sudha, “GPT -3 Powered System \\nfor Content Generation and Transformation,” in 2022 \\nFifth International Conference on Computational Intelligence and Communication Technologies \\n(CCICT) , Jul. 2022, pp. 514– 519. doi: \\n10.1109/CCiCT56684.2022.00096.  \\n[72] K. H. Manodnya and A. Giri, “GPT -K: A GPT -based \\nmodel for generation of text in Kannada,” in 2022 IEEE \\n4th International Conference on Cybernetics, Cognition \\nand Machine Learning Applications (ICCCMLA) , Oct. \\n2022, pp. 534 –539. doi: \\n10.1109/ICCCMLA56841.2022.9989289.  \\n[73] P. Isaranontakul and W. Kreesuradej, “A Study of \\nUsing GPT -3 to Generate a Thai Sentiment Analysis of ', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='  COVID- 19 Tweets Dataset,” in 2023 20th International \\nJoint Conference on Computer Science and Software \\nEngineering (JCSSE) , Jun. 2023, pp. 106– 111. doi: \\n10.1109/JCSSE58229.2023.10201994.  \\n[74] N. Aydın and O. A. Erdem, “A Research On The New Generation Artificial Intelligence Technology \\nGenerative Pretraining Transformer 3,” in 2022 3rd \\nInternational Informatics and Software Engineering \\nConference (IISEC) , Dec. 2022, pp. 1– 6. doi: \\n10.1109/IISEC56263.2022.9998298.  \\n[75] M. Lajkó, V. Csuvik, and L. Vidács, “Towards JavaScript program repair with Generative Pre- trained \\nTransformer (GPT -2),” in 2022 IEEE/ACM \\nInternational Workshop on Automated Program Repair (APR), May 2022, pp. 61– 68. doi: \\n10.1145/3524459.3527350.  \\n[76] Y. Su, “Computer -generated Humour Based on GPT -\\n2,” in 2022 IEEE 2nd International Conference on Data \\nScience and Computer Application (ICDSCA) , Oct. \\n2022, pp. 890 –893. doi: \\n10.1109/ICDSCA56264.2022.9987901.  \\n[77] N. Darapaneni, R. Prajeesh, P. Dutta, V. K. Pillai, A. \\nKarak, and A. R. Paduri, “Abstractive Text \\nSummarization Using BERT and GPT -2 Models,” in \\n2023 International Conference on Signal Processing, \\nComputation, Electronics, Power and \\nTelecommunication (IConSCEPT) , May 2023, pp. 1– 6. \\ndoi: 10.1109/IConSCEPT57958.2023.10170093.  \\n[78] Y. Liang and Z. Han, “Intelligent Love Letter Generator \\nBased on GPT -2 Model,” in 2022 3rd International \\nConference on Electronic Communication and \\nArtificial Intelligence (IWECAI) , Jan. 2022, pp. 562 –\\n567. doi: 10.1109/IWECAI55315.2022.00115.  \\n[79] D. H. Nguyen, H. L. Pham, and L. Le Thi Trang, “Security of the Cryptosystem GPT Based on Rank \\nCodes and Term -rank Codes,” in 2021 International \\nConference Engineering and Telecommunication \\n(En&T), Nov. 2021, pp. 1 –5. doi: \\n10.1109/EnT50460.2021.9681778.  \\n[80] M. Nam, S. Park, and D. S. Kim, “Intrusion Detection \\nMethod Using Bi -Directional GPT for in -Vehicle \\nController Area Networks,” IEEE Access , vol. 9, pp. \\n124931– 124944, 2021, doi: \\n10.1109/ACCESS.2021.3110524.  \\n[81] D. Demırcı, N. şahın, M. şirlancis, and C. Acarturk, \\n“Static Malware Detection Using Stacked BiLSTM and \\nGPT -2,” IEEE Access , vol. 10, pp. 58488 –58502, 2022, \\ndoi: 10.1109/ACCESS.2022.3179384.  \\n[82] H. Khan, M. Alam, S. Al -Kuwari, and Y. Faheem, \\n“OFFENSIVE AI: UNIFICATION OF EMAIL \\nGENERATION THROUGH GPT -2 MODEL WITH A \\nGAME -THEORETIC APPROACH FOR SPEAR -\\nPHISHING ATTACKS,” in Competitive Advantage in the Digital Economy (CADE 2021) , Jun. 2021, pp. 178–\\n184. doi: 10.1049/icp.2021.2422.  \\n[83] H. Liu, Y. Cai, Z. Lin, Z. Ou, Y. Huang, and J. Feng, “Variational Latent -State GPT for Semi -Supervised Task -Oriented Dialog Systems,” IEEEACM Trans. \\nAudio Speech Lang. Process. , vol. 31, pp. 970– 984, \\n2023, doi: 10.1109/TASLP.2023.3240661.  \\n[84] S. W. Jeong, C. G. Kim, and T. K. Whangbo, “Question Answering System for Healthcare Information based on BERT and GPT,” in 2023 Joint International \\nConference on Digital Arts, Media and Technology with \\nECTI Northern Section Conference on Electrical, \\nElectronics, Computer and Telecommunications \\nEngineering (ECTI DAMT & NCON) , Mar. 2023, pp. \\n348–\\n352. doi: \\n10.1109/ECTIDAMTNCON57770.2023.10139365.  \\n[85] Y. Zhang, Z. Li, and J. Zhang, “Towards the Use of Pretrained Language Model GPT -2 for Testing the \\nHypothesis of Communicative Efficiency in the Lexicon,” in 2021 International Conference on Asian \\nLanguage Processing (IALP) , Dec. 2021, pp. 62– 66. \\ndoi: 10.1109/IALP54817.2021.9675217.  \\n[86] R. Kinoshita and S. Shiramatsu, “Agent for Recommending Information Relevant to Web- based \\nDiscussion by Generating Query Terms using GPT -3,” \\nin 2022 IEEE International Conference on Agents \\n(ICA), Nov. 2022, pp. 24 –29. doi: \\n10.1109/ICA55837.2022.00011.  \\n[87] C. Treude, “Navigating Complexity in Software Engineering: A Prototype for Comparing GPT -n \\nSolutions,” in 2023 IEEE/ACM 5th International \\nWorkshop on Bots in Software Engineering (BotSE) , \\nMay 2023, pp. 1– 5. doi: \\n10.1109/BotSE59190.2023.00008.  \\n[88] J. J. Bird, M. Pritchard, A. Fratini, A. Ekárt, and D. R. \\nFaria, “Synthetic Biological Signals Machine -\\nGenerated by GPT -2 Improve the Classification of EEG \\nand EMG Through Data Augmentation,” IEEE Robot. \\nAutom. Lett. , vol. 6, no. 2, pp. 3498 –3504, Apr. 2021, \\ndoi: 10.1109/LRA.2021.3056355.  \\n[89] P. Maddigan and T. Susnjak, “Chat2VIS: Generating \\nData Visualizations via Natural Language Using \\nChatGPT, Codex and GPT -3 Large Language Models,” \\nIEEE Access , vol. 11, pp. 45181 –45193, 2023, doi: \\n10.1109/ACCESS.2023.3274199.  \\n[90] OpenAI, “GPT -4 Technical Report.” arXiv, Mar. 27, \\n2023. doi: 10.48550/arXiv.2303.08774.  \\n[91] H. Nori, N. King, S. M. McKinney, D. Carignan, and E. \\nHorvitz, “Capabilities of GPT -4 on Medical Challenge \\nProblems.” arXiv, Apr. 12, 2023. doi: \\n10.48550/arXiv.2303.13375.  \\n[92] D. M. Katz, M. J. Bommarito, S. Gao, and P. \\nArredondo, “GPT -4 Passes the Bar Exam.” Rochester, \\nNY, Mar. 15, 2023. doi: 10.2139/ssrn.4389233.  \\n[93] D. Hendrycks et al. , “Measuring Massive Multitask \\nLanguage Understanding,” arXiv.org. Accessed: Aug. \\n22, 2023. [Online]. Available: \\nhttps://arxiv.org/abs/2009.03300v3  \\n[94] A. Creswell, T. White, V. Dumoulin, K. Arulkumaran, \\nB. Sengupta, and A. A. Bharath, “Generative Adversarial Networks: An Overview,” IEEE Signal ', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='  Process. Mag. , vol. 35, no. 1, pp. 53– 65, Jan. 2018, doi: \\n10.1109/MSP.2017.2765202.  \\n[95] A. Aggarwal, M. Mittal, and G. Battineni, “Generative \\nadversarial network: An overview of theory and \\napplications,” Int. J. Inf. Manag. Data Insights , vol. 1, \\nno. 1, p. 100004, Apr. 2021, doi: \\n10.1016/j.jjimei.2020.100004.  \\n[96] Z. Zhang, M. Li, and J. Yu, “On the convergence and \\nmode collapse of GAN,” in SIGGRAPH Asia 2018 \\nTechnical Briefs , in SA ’18. New York, NY, USA: \\nAssociation for Computing Machinery, Dec. 2018, pp. \\n1–4. doi: 10.1145/3283254.3283282.  \\n[97] Bhagyashree, V. Kushwaha, and G. C. Nandi, “Study of \\nPrevention of Mode Collapse in Generative Adversarial \\nNetwork (GAN),” in 2020 IEEE 4th Conference on Information & Communication Technology (CICT) , \\nDec. 2020, pp. 1– 6. doi: \\n10.1109/CICT51604.2020.9312049.  \\n[98] H. Thanh- Tung and T. Tran, “Catastrophic forgetting \\nand mode collapse in GANs,” in 2020 International \\nJoint Conference on Neural Networks (IJCNN) , Jul. \\n2020, pp. 1– 10. doi: \\n10.1109/IJCNN48605.2020.9207181.  \\n[99] W. Li, L. Fan, Z. Wang, C. Ma, and X. Cui, “Tackling mode collapse in multi -generator GANs with \\northogonal vectors,” Pattern Recognit. , vol. 110, p. \\n107646, Feb. 2021, doi: 10.1016/j.patcog.2020.107646.  \\n[100]  D. Saxena and J. Cao, “Generative Adversarial \\nNetworks (GANs): Challenges, Solutions, and Future \\nDirections”.  \\n[101]  H. Chen, “Challenges and Corresponding Solutions \\nof Generative Adversarial Networks (GANs): A Survey \\nStudy,” J. Phys. Conf. Ser. , vol. 1827, no. 1, p. 012066, \\nMar. 2021, doi: 10.1088/1742 -6596/1827/1/012066.  \\n[102]  M. Mirza and S. Osindero, “Conditional Generative \\nAdversarial Nets,” arXiv.org. Accessed: Aug. 26, 2023. \\n[Online]. Available: https://arxiv.org/abs/1411.1784v1  \\n[103]  G. G. Chrysos, J. Kossaifi, and S. Zafeiriou, \\n“Robust Conditional Generative Adversarial Networks.” arXiv, Mar. 13, 2019. doi: \\n10.48550/arXiv.1805.08657.  \\n[104]  A. Radford, L. Metz, and S. Chintala, \\n“Unsupervised Representation Learning with Deep \\nConvolutional Generative Adversarial Networks.” arXiv, Jan. 07, 2016. Accessed: Aug. 26, 2023. \\n[Online]. Available: http://arxiv.org/abs/1511.06434  \\n[105]  M. Arjovsky, S. Chintala, and L. Bottou, \\n“Wasserstein GAN.” arXiv, Dec. 06, 2017. Accessed: Aug. 27, 2023. [Online]. Available: \\nhttp://arxiv.org/abs/1701.07875 \\n[106]  T. C. Koopmans, “Optimum Utilization of the \\nTransportation System,” Econometrica , vol. 17, pp. \\n136– 146, 1949, doi: 10.2307/1907301.  \\n[107]  E. Massart, “Improving weight clipping in \\nWasserstein GANs,” in 2022 26th International Conference on Pattern Recognition (ICPR) , Montreal, QC, Canada: IEEE, Aug. 2022, pp. 2286– 2292. doi: \\n10.1109/ICPR56361.2022.9956056.  \\n[108]  J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, \\n“Unpaired Image -To-Image Translation Using Cycle -\\nConsistent Adversarial Networks,” presented at the Proceedings of the IEEE International Conference on \\nComputer Vision, 2017, pp. 2223– 2232. Accessed: \\nAug. 27, 2023. [Online]. Available: \\nhttps://openaccess.thecvf.com/content_iccv_2017/html\\n/Zhu_Unpaired_Image -To-\\nImage_Translation_ICCV_2017_paper.html  \\n[109]  Y. Choi, M. Choi, M. Kim, J.- W. Ha, S. Kim, and \\nJ. Choo, “StarGAN: Unified Generative Adversarial Networks for Multi -Domain Image -to-Image \\nTranslation,” presented at the Proceedings of the IEEE Conference on Computer Vision and Pattern \\nRecognition, 2018, pp. 8789 –8797. Accessed: Aug. 27, \\n2023. [Online]. Available: \\nhttps://openaccess.thecvf.com/content_cvpr_2018/html/Choi_StarGAN_Unified_Generative_CVPR_2018_pa\\nper.html  \\n[110]  T. Karras, T. Aila, S. Laine, and J. Lehtinen, \\n“Progressive Growing of GANs for Improved Quality, \\nStability, and Variation.” arXiv, Feb. 26, 2018. doi: \\n10.48550/arXiv.1710.10196.  \\n[111]  A. Brock, J. Donahue, and K. Simonyan, “Large \\nScale GAN Training for High Fidelity Natural Image Synthesis.” arXiv, Feb. 25, 2019. doi: 10.48550/arXiv.1809.11096.  \\n[112]  T. Karras, S. Laine, and T. Aila, “A Style- Based \\nGenerator Architecture for Generative Adversarial \\nNetworks,” presented at the Proceedings of the \\nIEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 4401 –4410. Accessed: Aug. 29, \\n2023. [Online]. Available: \\nhttps://openaccess.thecvf.com/content_CVPR_2019/html/Karras_A_Style -\\nBased_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.html  \\n[113]  T. Karras, S. Laine, M. Aittala, J. Hellsten, J. \\nLehtinen, and T. Aila, “Analyzing and Improving the Image Quality of StyleGAN,” presented at the \\nProceedings of the IEEE/CVF Conference on Computer \\nVision and Pattern Recognition, 2020, pp. 8110– 8119. \\nAccessed: Aug. 29, 2023. [Online]. Available: \\nhttps://openaccess.thecvf.com/content_CVPR_2020/ht\\nml/Karras_Analyzing_and_Improving_the_Image_Qu\\nality_of_StyleGAN_CVPR_2020_paper.html  \\n[114]  X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. \\nSutskever, and P. Abbeel, “InfoGAN: Interpretable Representation Learning by Information Maximizing \\nGenerative Adversarial Nets,” in Advances in Neural \\nInformation Processing Systems , Curran Associates, \\nInc., 2016. Accessed: Aug. 29, 2023. [Online]. \\nAvailable: \\nhttps://proceedings.neurips.cc/paper_files/paper/2016/', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='  hash/7c9d0b1f96aebd7b5eca8c3edaa19ebb-\\nAbstract.html \\n[115]  T. Salimans et al. , “Improved Techniques for \\nTraining GANs,” in Advances in Neural Information \\nProcessing Systems , Curran Associates, Inc., 2016. \\nAccessed: Aug. 29, 2023. [Online]. Available: \\nhttps://proceedings.neurips.cc/paper_files/paper/2016/\\nhash/8a3363abe792db2d8761d6403605aeb7 -\\nAbstract.html \\n[116]  J. Donahue, P. Krähenbühl, and T. Darrell, \\n“Adversarial Feature Learning.” arXiv, Apr. 03, 2017. \\ndoi: 10.48550/arXiv.1605.09782.  \\n[117]  A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. \\nChen, “Hierarchical Text -Conditional Image \\nGeneration with CLIP Latents,” arXiv.org. Accessed: Oct. 06, 2023. [Online]. Available: \\nhttps://arxiv.org/abs/2204.06125v1  \\n[118]  J. Ho et al. , “IMAGEN VIDEO: HIGH \\nDEFINITION VIDEO GENERATION WITH \\nDIFFUSION MODELS”.  \\n[119]  U. Singer et al. , “Make- A-Video: Text -to-Video \\nGeneration without Text -Video Data.” arXiv, Sep. 29, \\n2022. doi: 10.48550/arXiv.2209.14792.  \\n[120]  Y. Li et al. , “Competition -level code generation \\nwith AlphaCode,” Science, vol. 378, no. 6624, pp. \\n1092 –1097, Dec. 2022, doi: 10.1126/science.abq1158.  \\n[121]  “StarCoder: A State -of-the-Art LLM for Code.” \\nAccessed: Oct. 06, 2023. [Online]. Available: https://huggingface.co/blog/starcoder  \\n[122]  M. Chen et al. , “Evaluating Large Language \\nModels Trained on Code.” arXiv, Jul. 14, 2021. doi: 10.48550/arXiv.2107.03374.  \\n[123]  “A systematic review of artificial intelligence -\\nbased music generation: Scope, applications, and future trends - ScienceDirect.” Accessed: Oct. 07, 2023. \\n[Online]. Available: https://www.sciencedirect.com/science/article/pii/S0957417422013537  \\n[124]  “MuseNet.” Accessed: Oct. 07, 2023. [Online]. \\nAvailable: https://openai.com/research/musenet  \\n[125]  P. Dhariwal, H. Jun, C. Payne, J. W. Kim, A. \\nRadford, and I. Sutskever, “Jukebox: A Generative \\nModel for Music.” arXiv, Apr. 30, 2020. doi: \\n10.48550/arXiv.2005.00341.  \\n[126]  “How To Give Your Living Room a Luxurious \\nMakeover,” House Beautiful. Accessed: Sep. 26, 2023. \\n[Online]. Available: \\nhttps://www.housebeautiful.com/room -\\ndecorating/living -family -rooms/g715/designer -living -\\nrooms/  \\n[127]  “File:Bowie -state-university -science- building.jpg - \\nWikipedia.” Accessed: Sep. 26, 2023. [Online]. \\nAvailable: \\nhttps://commons.wikimedia.org/wiki/File:Bowie -state-\\nuniversity -science- building.jpg  \\n[128]  N. Kaur and P. Singh, “Conventional and \\ncontemporary approaches used in text to speech synthesis: a review,” Artif. Intell. Rev. , vol. 56, no. 7, \\npp. 5837– 5880, Jul. 2023, doi: 10.1007/s10462- 022-\\n10315- 0. \\n[129]  A. Wali et al. , “Generative adversarial networks for \\nspeech processing: A review,” Comput. Speech Lang. , \\nvol. 72, p. 101308, Mar. 2022, doi: \\n10.1016/j.csl.2021.101308.  \\n[130]  J. A. Rodriguez, D. Vazquez, I. Laradji, M. \\nPedersoli, and P. Rodriguez, “FigGen: Text to Scientific \\nFigure Generation.” arXiv, Jun. 21, 2023. Accessed: \\nOct. 07, 2023. [Online]. Available: http://arxiv.org/abs/2306.00800 \\n[131]  “Minerva: Solving Quantitative Reasoning \\nProblems with Language Models.” Accessed: Oct. 07, \\n2023. [Online]. Available: \\nhttps://blog.research.google/2022/06/minerva -solving-\\nquantitative -reasoning.html  \\n[132]  R. Taylor et al. , “Galactica: A Large Language \\nModel for Science.” arXiv, Nov. 16, 2022. doi: \\n10.48550/arXiv.2211.09085.  \\n[133]  C. Plut and P. Pasquier, “Generative music in video \\ngames: State of the art, challenges, and prospects,” Entertain. Comput. , vol. 33, p. 100337, Mar. 2020, doi: \\n10.1016/j.entcom.2019.100337.  \\n[134]  S. Wang et al. , “ReelFramer: Co -creating News \\nReels on Social Media with Generative AI.” arXiv, Apr. \\n19, 2023. Accessed: Oct. 11, 2023. [Online]. Available: http://arxiv.org/abs/2304.09653 \\n[135]  T. H. D. and R. Bean, “The Impact of Generative \\nAI on Hollywood and Entertainment,” MIT Sloan Management Review. Accessed: Oct. 11, 2023. \\n[Online]. Available: \\nhttps://sloanreview.mit.edu/article/the -impact -of-\\ngenerative- ai-on-hollywood- and-entertainm ent/ \\n[136]  “Runway AI: Tech Behind Everything Everywhere \\nAll At Once.” Accessed: Oct. 11, 2023. [Online]. Available: https://topten.ai/ai- tech-behind- everything-\\neverywhere -all-at-once/  \\n[137]  L. Rai, C. Deng, and F. Liu, “Developing Massive \\nOpen Online Course Style Assessments using \\nGenerative AI Tools,” in 2023 IEEE 6th International \\nConference on Electronic Information and \\nCommunication Technology (ICEICT) , Jul. 2023, pp. \\n1292 –1294. doi: \\n10.1109/ICEICT57916.2023.10244824.  \\n[138]  J. Qadir, “Engineering Education in the Era of \\nChatGPT: Promise and Pitfalls of Generative AI for Education,” in 2023 IEEE Global Engineering \\nEducation Conference (EDUCON) , May 2023, pp. 1– 9. \\ndoi: 10.1109/EDUCON54358.2023.10125121.  \\n[139]  W. M. Lim, A. Gunasekara, J. L. Pallant, J. I. \\nPallant, and E. Pechenkina, “Generative AI and the \\nfuture of education: Ragnarök or reformation? A \\nparadoxical perspective from management educators,” \\nInt. J. Manag. Educ. , vol. 21, no. 2, p. 100790, Jul. \\n2023, doi: 10.1016/j.ijme.2023.100790.  ', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='  [140]  Y.-X. Li and N. -C. Tai, “Teaching at the Right \\nMoment: A Generative AI -Enabled Bedtime Storybook \\nGeneration System Communicating Timely Issues,” in \\n2023 International Conference on Consumer \\nElectronics - Taiwan (ICCE -Taiwan) , Jul. 2023, pp. \\n157– 158. doi: 10.1109/ICCE -\\nTaiwan58799.2023.10226626.  \\n[141]  E. A. Alasadi and C. R. Baiz, “Generative AI in \\nEducation and Research: Opportunities, Concerns, and \\nSolutions,” J. Chem. Educ. , vol. 100, no. 8, pp. 2965–\\n2971, Aug. 2023, doi: 10.1021/acs.jchemed.3c00323.  \\n[142]  H. Yu, Z. Liu, and Y. Guo, “Application Status, \\nProblems and Future Prospects of Generative AI in Education,” in 2023 5th International Conference on \\nComputer Science and Technologies in Education (CSTE), Apr. 2023, pp. 1– 7. doi: \\n10.1109/CSTE59648.2023.00065.  \\n[143]  M. Kuzlu, Z. Xiao, S. Sarp, F. O. Catak, N. Gurler, \\nand O. Guler, “The Rise of Generative Artificial \\nIntelligence in Healthcare,” in 2023 12th \\nMediterranean Conference on Embedded Computing (MECO), Jun. 2023, pp. 1 –4. doi: \\n10.1109/MECO58584.2023.10155107.  \\n[144]  A. Jadon and S. Kumar, “Leveraging Generative AI \\nModels for Synthetic Data Generation in Healthcare: Balancing Research and Privacy,” in 2023 International \\nConference on Smart Applications, Communications \\nand Networking (SmartNets) , Jul. 2023, pp. 1– 4. doi: \\n10.1109/SmartNets58706.2023.10215825.  \\n[145]  Z. Shen, F. Ding, A. Jolfaei, K. Yadav, S. Vashisht, \\nand K. Yu, “DeformableGAN: Generating Medical Images With Improved Integrity for Healthcare Cyber \\nPhysical Systems,” IEEE Trans. Netw. Sci. Eng. , vol. \\n10, no. 5, pp. 2584– 2596, Sep. 2023, doi: \\n10.1109/TNSE.2022.3190765.  \\n[146]  “AWS Announces AWS HealthScribe, a New \\nGenerative AI -Powered Service that Automatically \\nCreates Clinical Documentation,” Press Center. Accessed: Oct. 11, 2023. [Online]. Available: \\nhttps://press.aboutamazon.com/2023/7/aws -announces -\\naws-healthscribe -a-new-generative -ai-powered -\\nservice- that-automatically -creates -clinical-\\ndocumentation  \\n[147]  B. Tang, J. Ewalt, and H.- L. Ng, “Generative AI \\nModels for Drug Discovery,” in Biophysical and \\nComputational Tools in Drug Discovery , A. K. Saxena, \\nEd., in Topics in Medicinal Chemistry. , Cham: \\nSpringer International Publishing, 2021, pp. 221– 243. \\ndoi: 10.1007/7355_2021_124.  \\n[148]  W. P. Walters and M. Murcko, “Assessing the \\nimpact of generative AI on medicinal chemistry,” Nat. \\nBiotechnol. , vol. 38, no. 2, Art. no. 2, Feb. 2020, doi: \\n10.1038/s41587- 020-0418- 2. \\n[149]  X. Zeng et al. , “Deep generative molecular design \\nreshapes drug discovery,” Cell Rep. Med. , vol. 3, no. 12, \\np. 100794, Dec. 2022, doi: \\n10.1016/j.xcrm.2022.100794.  [150]  A. Madani et al. , “Large language models generate \\nfunctional protein sequences across diverse families,” Nat. Biotechnol. , vol. 41, no. 8, Art. no. 8, Aug. 2023, \\ndoi: 10.1038/s41587- 022-01618- 2. \\n[151]  E. Sevgen et al. , “ProT -VAE: Protein Transformer \\nVariational AutoEncoder for Functional Protein \\nDesign.” bioRxiv, p. 2023.01.23.525232, Jan. 24, 2023. \\ndoi: 10.1101/2023.01.23.525232.  \\n[152]  “Cognizant and Google Cloud Expand Alliance to \\nBring AI to Enterprise Clients,” News | Cognizant \\nTechnology Solutions. Accessed: Oct. 11, 2023. [Online]. Available: https://news.cognizant.com/2023 -\\n05-09-Cognizant -and-Google -Cloud- Expand- Alliance -\\nto-Bring-AI-to-Enterprise -Clients  \\n[153]  “Generative AI to Become a $1.3 Trillion Market \\nby 2032, Research Finds | Press | Bloomberg LP,” Bloomberg L.P.  Accessed: Oct. 12, 2023. [Online]. \\nAvailable: \\nhttps://www.bloomberg.com/company/press/generativ\\ne-ai-to-become- a-1-3-trillion -market -by-2032-\\nresearch -finds/  \\n[154]  T. H. Baek, “Digital Advertising in the Age of \\nGenerative AI,” J. Curr. Issues Res. Advert. , vol. 44, no. \\n3, pp. 249– 251, Jul. 2023, doi: \\n10.1080/10641734.2023.2243496.  \\n[155]  J. Huh, M. R. Nelson, and C. A. Russell, “ChatGPT, \\nAI Advertising, and Advertising Research and \\nEducation,” J. Advert. , vol. 52, no. 4, pp. 477– 482, Aug. \\n2023, doi: 10.1080/00913367.2023.2227013.  \\n[156]  J. Ford, V. Jain, K. Wadhwani, and D. G. Gupta, \\n“AI advertising: An overview and guidelines,” J. Bus. \\nRes., vol. 166, p. 114124, Nov. 2023, doi: \\n10.1016/j.jbusres.2023.114124.  \\n[157]  A. Beheshti et al. , “ProcessGPT: Transforming \\nBusiness Process Management with Generative \\nArtificial Intelligence,” in 2023 IEEE International \\nConference on Web Services (ICWS) , Jul. 2023, pp. \\n731– 739. doi: 10.1109/ICWS60048.2023.00099.  \\n[158]  “Amazon launches generative AI to help sellers \\nwrite product descriptions,” US About Amazon. \\nAccessed: Oct. 12, 2023. [Online]. Available: \\nhttps://www.aboutamazon.com/news/small-\\nbusiness/amazon -sellers -generative- ai-tool \\n[159]  “ChatGPT In Healthcare: What Science Says,” The \\nMedical Futurist. Accessed: Aug. 24, 2023. [Online]. Available: https://medicalfuturist.com/chatgpt -in-\\nhealthcare- what -the-science- says/  \\n[160]  “Generative AI and the future of work in America | \\nMcKinsey.” Accessed: Oct. 10, 2023. [Online]. Available: https://www.mckinsey.com/mgi/our -\\nresearch/generative- ai-and-the-future -of-work -in-\\namerica#/  \\n[161]  A. Zarifhonarvar, “Economics of ChatGPT: A \\nLabor Market View on the Occupational Impact of \\nArtificial Intelligence.” Rochester, NY, Feb. 07, 2023. \\ndoi: 10.2139/ssrn.4350925.  ', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='  [162]  “Future of Work Report: AI at Work.” Accessed: \\nOct. 14, 2023. [Online]. Available: \\nhttps://economicgraph.linkedin.com/research/future -\\nof-work -report -ai \\n[163]  “Jobs of Tomorrow: Large Language Models and \\nJobs,” World Economic Forum. Accessed: Oct. 14, \\n2023. [Online]. Available: \\nhttps://www.weforum.org/whitepapers/jobs -of-\\ntomorrow -large -language -models -and-jobs/  \\n[164]  “Automation or augmentation? This is how AI will \\nbe integrated into the jobs of tomorrow,” World \\nEconomic Forum. Accessed: Oct. 14, 2023. [Online]. \\nAvailable: \\nhttps://www.weforum.org/agenda/2023/09/ai -\\nautomation -augmentation -workplace -jobs-of-\\ntomorrow/  \\n[165]  “We always hear that AI will take our jobs. But \\nwhat jobs will it create?,” World Economic Forum. \\nAccessed: Oct. 14, 2023. [Online]. Available: \\nhttps://www.weforum.org/agenda/2023/09/jobs -ai-\\nwill- create/  \\n[166]  K. Michael, R. Abbas, and G. Roussos, “AI in \\nCybersecurity: The Paradox,” IEEE Trans. Technol. \\nSoc., vol. 4, no. 2, pp. 104 –109, Jun. 2023, doi: \\n10.1109/TTS.2023.3280109.  \\n[167]  S. Oh and T. Shon, “Cybersecurity Issues in \\nGenerative AI,” in 2023 International Conference on \\nPlatform Technology and Service (PlatCon) , Aug. \\n2023, pp. 97 –100. doi: \\n10.1109/PlatCon60102.2023.10255179.  \\n[168]  M. Gupta, C. Akiri, K. Aryal, E. Parker, and L. \\nPraharaj, “From ChatGPT to ThreatGPT: Impact of \\nGenerative AI in Cybersecurity and Privacy,” IEEE \\nAccess , vol. 11, pp. 80218– 80245, 2023, doi: \\n10.1109/ACCESS.2023.3300381.  \\n[169]  “AI-Based Cybercrime Tools WormGPT and \\nFraudGPT Could Be The Tip of the Iceberg | SlashNext,” SlashNext |. Accessed: Aug. 24, 2023. \\n[Online]. Available: https://slashnext.com/blog/ai-\\nbased -cybercrime- tools -wormgpt -and-fraudgpt -could -\\nbe-the-tip-of-the-iceberg/  \\n[170]  I.-C. Mihai, “The Transformative Impact of \\nArtificial Intelligence on Cybersecurity,” Int. J. Inf. Secur. Cybercrime, vol. 12, p. 9, 2023.  \\n[171]  P. V. Falade, “Decoding the Threat Landscape\\u202f: \\nChatGPT, FraudGPT, and WormGPT in Social \\nEngineering Attacks,” Int. J. Sci. Res. Comput. Sci. Eng. \\nInf. Technol. , pp. 185 –198, Oct. 2023, doi: \\n10.32628/CSEIT2390533.  \\n[172]  M. Mozes, X. He, B. Kleinberg, and L. D. Griffin, \\n“Use of LLMs for Illicit Purposes: Threats, Prevention \\nMeasures, and Vulnerabilities.” arXiv, Aug. 24, 2023. \\ndoi: 10.48550/arXiv.2308.12833.  \\n[173]  “Pause Giant AI Experiments: An Open Letter,” \\nFuture of Life Institute. Accessed: Aug. 24, 2023. \\n[Online]. Available: https://futureoflife.org/open -\\nletter/pause -giant -ai-experiments/ [174]  J. Coscarelli, “An A.I. Hit of Fake ‘Drake’ and ‘The \\nWeeknd’ Rattles the Music World,” The New York Times , Apr. 19, 2023. Accessed: Oct. 11, 2023. \\n[Online]. Available: \\nhttps://www.nytimes.com/2023/04/19/arts/music/ai-drake -the-weeknd -fake.html  \\n[175]  B. Lane, “An AI -generated Rihanna cover of \\nBeyoncé’s ‘Cuff It’ is going viral, and it could open up a new legal nightmare for the music industry,” Insider. \\nAccessed: Oct. 14, 2023. [Online]. Available: \\nhttps://www.insider.com/rihanna -ai-cuff-it-cover -\\nlegal -nightmare -music -industry -2023- 4 \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n ', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 24})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pdf data in the Machine Learning Notes folder\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be9060c-c966-4ad1-8860-37cfed77d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator object of the recursive character for chunks of data\n",
    "test_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36db2b99-414f-4060-ba15-8d8d6481baf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Advancements in Generative AI: A \\nComprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and \\nTransformers. \\nStaphord Bengesi1, Hoda El -Sayed1, Md Kamruzzaman Sarker1, Yao  Houkpati1, John \\nIrungu3   and Timothy Oladunni2 \\n1 Dept. of Computer Science, Bowie State University, Bowie, MD 20715 USA  \\n2 Dept. of Computer Science, Morgan State University, Baltimore, MD 21251 USA  \\n3 Dept.  of Computer Science, University of the District of Columbia , Washington, DC 20008  USA', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}),\n",
       " Document(page_content='Corresponding author: sbengesi@bowiestate.edu  \\n \\nABSTRACT  The launch of ChatGPT has garnered global attention, marking a significant milestone in the \\nfield of Generative Artificial Intelligence. While Generative AI has been in effect for the past decade, the \\nintroduction of ChatGPT has ignited a new wave of research and innovation in the AI domain. This surge in interest has led to the development and release of numerous cutting -edge tools, such as Bard, Stable Diffusion,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}),\n",
       " Document(page_content='DALL -E, Make-A- Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable \\ncapabilities, encompassing tasks ranging from text generation and music composition, image creation, video \\nproduction, code generation, and even scientific work. They are built upon various state -of-the-art models, \\nincluding Stable Diffusion, transformer models like GPT- 3 (recent GPT -4), variational autoencoders, and', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}),\n",
       " Document(page_content='generative adversarial networks. This advancement in Generative AI presents a wealth of exciting opportunities and, simultaneously, unprecedented challenges. Throughout this paper, we have explored these state-of-the-art models, the diverse array of tasks they can accomplish, the challenges they pose, and the \\npromisi ng future of Generative Artificial Intelligence.  \\nINDEX TERMS  Generative AI, GPT , Bard, ChatGPT, Diffusion  Model, Transformer, GAN , Autoencoder, \\nArtificial Intelligence .', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}),\n",
       " Document(page_content='I. INTRODUCTION   \\nThe release of ChatGPT on November 30, 2022 [30][31], \\ntriggered an exponential surge in the groundbreaking and \\nwidespread popularity of G enerative A rtificial Intelligence \\n(GAI)  to the general public.  This remarkable achievement \\ncould be traced to t he 1956 summer project at Dartmouth \\nCollege spearheaded by McCarthy ; mark ing the inception of  \\nthe Artificial Intelligence  [1]. The endeavor aimed to', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}),\n",
       " Document(page_content='develop machines with the ability to perform tasks typically demanding human intelligence  [2]  [3] [4] [5] [6]. These \\ntasks include  computer vision, natural language processing, \\nrobotics,  and many others .  Since then, significant \\nadvancements have been achieved in imbuing  machines with \\nthe capability of talking, walking, thinking, and acting like humans . Notably, a series of algorithms, including the \\nRegression model, perceptron algorithm  [7], Decision', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}),\n",
       " Document(page_content='tree[8], K-N earest Neighbor  [9], Naive Bayes Classifier, \\nBack Propagation, support vector machine (SVM)[10] , and Random Forest  [11] have emerged . These  algorithms  in the \\ncontemporary  are commonly referred to  as \\nclassical /traditional machine learning algorithms and  most of \\nthem were developed before  the year 2000.  Furthermore, \\nthere is an  advancement  in deep learning algorithms,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}),\n",
       " Document(page_content='including the development of Convolutional Neural Networks (CNNs) in the 1980s  [12], Recurrent Neural \\nNetworks (RNNs) in 198 5[13], Long Short -Term Memory \\n(LSTM) in 1997  [14], and Bidirectional Long Short -Term \\nMemory (BiLSTM) [15] in the same year. However, until \\nrecent times , widespread attention has been limited primarily \\nbecause of computing resources and dataset availability limitations  [16].', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}),\n",
       " Document(page_content='To tackle the constraints imposed by limited datasets, researchers from Stanford University, Princeton University, and Columbia University jointly launched the ImageNet Large Scale Visual Recognition Challenge in 2010 [17]. This \\ncompetition played a pivotal role in driving advancements in neural network architectures, with a particular focus on', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}),\n",
       " Document(page_content='Convolutional Neural Networks (CNNs). Since then, CNN \\nhas been established as algorithm  for image classification  \\nand computer vision[18] . The breakthrough achievement of \\nAlexNet in 2012 [19] mark ed a significant milestone in the \\npractical application of deep learning in computer vision \\ntasks. The success of the ImageNet Competition ignited a \\nsurge in interest and investment in deep learning research. \\nThis newfound enthusiasm resulted in the continuous', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='evolution of  improved architectural innovations, including \\nmodels such as ResNet [20], DenseNet [21], MobileNet [22], \\nand EfficientNet [23]. These models set the gold standard for \\nvarious cutting- edge technologies, such as transfer learning, \\ncontinual learning, attention mechanisms  [24], self -\\nsupervised learning, and generative AI.   \\nBefore 2014, all existing deep learning models were \\nprimarily descriptive, focusing on summarizing or', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='representing existing data patterns and relationships. These \\nmodels aimed to explain the data patterns and make \\npredictions based on the information prese nt. However, \\nGoodfellow  et al.  [25] in 2014  introduced the Generative \\nAdversarial Network (GAN) ushering in a new era of \\nGenerative Artificial Intelligence (GAI)  realization . Unlike \\ntheir descriptive counterparts, generative models, such as \\nGANs, are designed to learn the underlying probability', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='distribution of the data  [26] . Their primary goal is to \\ngenerate new data samples that closely resemble the patterns \\nobserved in the training data  [27][28].  \\nThe breakthrough of GAN marked a significant \\ndeparture from traditional deep learning methods, opening  \\nexciting possibilities for Generative artificial intelligence . \\nGAI has since garnered widespread attention due to its \\ntransformative impact across various domains of life. It offers elegant solutions to complex problems  [29]', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='enabling \\nthe creation of synthetic data, artistic content, and realistic \\nsimulations. This paradigm shift in AI technology has \\nprofoundly influenced the  new perception , implementation, \\nand utilization on  artificial intelligence, sparking innovation \\nand new application opportunities across industries.   \\nThe emergence of GAI has sparked numerous questions, \\nprompting a need for a comprehensive exploration. In that \\nvein, this paper aims   at provid ing an in -depth exploration to', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='the state-of-the-art in GAI , including  models,  task \\ncategorization, applications, areas of influence, challenges, \\nand prospects . To achieve this, our work  is structured as \\nfollows: Section II introduces contemporary generative \\nmodels. Section III elaborates on the various tasks within \\nGenerative AI. Section IV examines the diverse applications \\nof Generative AI. Section V delves into the outlook for \\ngenerative AI. Lastly, Section VI offers a conclusion.  \\n \\n \\nII. GENE RATIVE MODELS', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='There has been a shift in the focus of researchers from discriminative learning to generative learning in the \\ncontemporary era. Multiple generative models have emerged \\n \\n1 Source: https://towardsdatascience.com/applied -deep -learning -part-3-\\nautoencoders -1c083af4d798  with the capability of generating new data points like the \\ntraining data inputs based on learning their distribution . This \\nsection will discuss current state -of-the-art theoretical and', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='mathematical foundations of generative models.  \\n \\nA. AUTOENCODER  \\nAutoencoder is  an unsupervised machine learning neural \\nnetwork model that encodes the input data  using an encoder  \\ninto a lower -dimensional representation (encoding) and then  \\nuses a decoder to  decode it back to its original form \\n(decoding) while reducing the reconstruction error  [32]. This \\nmodel was primarily designed for Dimensionality \\nReduction, Feature Extraction, Image Denoising, Image', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='Compression, Image Search, Anomaly Detection and \\nMissing Value Imputation  [32]. \\n  \\n           FIGURE 1. Autoencoder architecture1 \\n \\nBoth encoder and decoder  of the model  are neural networks \\nwritten as a function of input and a generic function of code layer respectively  [33]. Based on figure 1,  autoencoder is \\nmade up of four components namely:  \\n• Encoder:  This component reduces and compresses \\nthe input data into lower dimensions.  As a result of', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='its output, it creates a new layer called code.  \\n• Code/Bottleneck:  a layer that contains a \\ncompressed and the lowest possible dimensions of input data representation.  \\nConsider  equation 1 below.  \\nℎ\\n𝑖𝑖=𝑓𝑓(𝑋𝑋𝑖𝑖)                                   (1) \\nWhereby 𝒉𝒉𝒊𝒊 is code layer after function f  with user \\ndefined parameter s is applied to the input  𝑿𝑿𝒊𝒊  \\n \\n• Decoder: Reconstruc ts the code layer from lower \\ndimension representation to input.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='• Reconstruction  Loss: Defines the final output of \\nthe decoder, measuring how closely the output resembles the original input.     \\n   \\n                          𝑋𝑋\\n𝚤𝚤�=𝑔𝑔(ℎ𝑖𝑖)                       (2)', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 1}),\n",
       " Document(page_content='Where 𝑿𝑿𝒊𝒊� is the output of encoder after second \\ngeneric function to the code layer.  \\n \\nThe training of the autoencoder involves minimizing the \\ndissimilarity between the input and the output  [33], as shown \\nin Equation 3.  \\n \\n                     𝐴𝐴\\n𝐴𝐴𝑔𝑔𝐴𝐴𝐴𝐴\\n𝐴𝐴𝑓𝑓,𝑔𝑔<∆�𝑿𝑿 𝒊𝒊,𝑿𝑿𝒊𝒊��                  (3)  \\n T\\nhe encoder and the decoder are composed of fully \\nconnected feedforward neural networks where the input, code, and output layer s consist each of a single neural', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 2}),\n",
       " Document(page_content='network layer defined by the user. Like other standard neural networks, autoencoders apply activation functions such as sigmoid and Relu.  Various variants of autoencoder exist, \\nsuch as contractive, Denoising, and sparse autoencoder  [34]. \\nGenerally, the plain autoencoders prior mentioned are not generative since they do not generate new data but replicate \\nthe input. However, the variational autoencoder is the variant \\nthat is generative  [32]. \\n \\n1) VARIATIONAL AUTOENCODER', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 2}),\n",
       " Document(page_content=\"Variational autoencoder (VAE) evolved as a result of the introduction of variational inference  (A statistical technique \\nfor approximating complex distributions) to Autoencoder (AE) by Kingma  et al.  [35]. It's a generative model that \\nutilizes Variational Bayes Inference to describe data generation using a probabilistic distribution  [36]. \\n     Unlike traditional AEs, VAEs have an extra sampling layer in addition to an encoder and decoder layer  as depicted \\nin figure  2.\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 2}),\n",
       " Document(page_content='in figure  2.\\n Training the VAEs model involves encoding the \\ninput as a distribution over the latent space and generating the latent vector from the distribution sampling. Afterward, \\nthe latent vector is decoded, the reconstruction error is \\ncomputed, and the reconstruction error is backpropagated through the network.  During the training process, \\nregularization is introduced explicitly to prevent overfitting.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 2}),\n",
       " Document(page_content='FIGURE 2 . Variational encoder architecture  \\n \\n  \\n \\n \\n    FIGURE 3. Probability Model   \\n \\nProbabilistically,  VAE is composed of a latent \\nrepresentation z as depicted by  Figure 3, drawn from the \\nprior distribution p(z)  and the data x drawn from the \\nconditional likelihood distribution p(x|z) which is  referred to \\nas probabilistic decoder  and can be expressed as:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 2}),\n",
       " Document(page_content='p(x,z)=p(x∣z)p(z)                                              (4) \\n \\nThe inference of the model is examined by computing the \\nposterior of the latent vector using the Bayes theorem shown \\nin equation 5.  \\n          𝑝𝑝(𝑧𝑧 ∣ 𝑥𝑥 ) =𝑝𝑝(𝑥𝑥∣𝑧𝑧)𝑝𝑝(𝑧𝑧)\\n𝑝𝑝(𝑥𝑥)                               (5)  \\n With any distribution variant such as Gaussian, variational \\ninference can approximate th e posterior,  and its reliability in \\napproximation can be assessed through Kullback- Leibler', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 2}),\n",
       " Document(page_content='divergence  which measures the information lost during \\napproximation.  This model has significantly influenced \\ngenerative AI, as demonstrated in Table 1, which highlights \\na few outstanding state -of-the-art examples using VAE \\nacross various domains.  \\n \\n \\nTABLE   1 \\nVAE  STATE -OF-THE-ART \\ncategory  Subcategory \\nDomains  Dataset  Reference  \\nImage Processing  Image \\nClassification  MRI datasets , SAR \\nimages , ImageNet \\ndataset, NWPU -\\nRESISC45  [37] [38] [39] [40]', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 2}),\n",
       " Document(page_content='Image Compression  Kodak dataset  [41] \\nImage Resolution  \\n DIV2K and Flickr2K \\nimage dataset  [42] \\nAudio Processing  \\n Noisy voice \\nrecorded datasets  NIL [43] [44]', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 2}),\n",
       " Document(page_content='Video Processing  Prediction  MineRL  and \\nMMNIST  [45] \\nVideo  Infrastructure \\nMonitoring  UCSD Ped2 , Fan \\ndeterioration simulated \\ndataset  [46] [47] [48]  \\nAudio  Infrastructure \\nMonitoring  MIMII  [49] \\nSensor  Nonlinear analysis  Simulated Dataset, \\nButane content  [50] [51] \\nModeling  DCS  [52] [53]  [54] \\nActivity monitoring  Finance 284,807 credit card \\ntransactions  [55] [56] \\n \\n \\nB. TRANSFORMER  \\nThe ground- breaking work of Vaswani et al . \"Attention Is All', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 3}),\n",
       " Document(page_content='You Need\" by the Google Brain team introduced a \\ntransformer  model which can analyze large -scale dataset  \\n[24]. Transform was initially developed for natural language  \\nprocessing (NLP) but was subsequently adapted to other \\nareas of machine learning, such as computer vision [57] [58] \\n[59]. This model aimed  to solve RNNs, and CNNs \\nshortcomings such as long- range dependencies, gradient \\nvanishing, gradient explosion, the need for larger training', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 3}),\n",
       " Document(page_content='steps to reach a local/global minima, and the fact that parallel \\ncomputation was not allowed [24]. Thus, t he proposed \\nsolution  presented a novel  way of handling neural network \\ntasks like translation, content generation, and sentiment analysis  [60]  \\n \\n          \\nFIGURE 4. Transformer Architecture  [24] \\n Transformer Architecture \\nVaswani et al , introduced three main concepts in their study  \\nas depicted in figure 4 , including self -attention, which allows', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 3}),\n",
       " Document(page_content='a model  to evaluate input sequences according to their \\nimportance, thus reducing long- range dependencies, multi -\\nhead  attention which allows the model to learn multiple \\nmeans of the input sequence, and word embedding, which transforms inputs into vectors.   \\n \\nEncoder and Decoder', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 3}),\n",
       " Document(page_content='It is worth mentioning that the transformer architecture \\n(Figure 4) inherits the encoder -decoder structure[61] that \\nutilizes stacked self -attention and point -wise layers, fully \\nconnected layers for both the encoder and decoder  [62]. The \\nencoder consists of a stack of N = 6 identical layers, each with \\ntwo sublayers, including a multi -head self -attention \\nmechanism and a fully connected feedforward network. A \\ndecoder is like an encoder, but with an additional sublayer', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 4}),\n",
       " Document(page_content=\"which masks the mult i-head attention. Encoders and decoders \\nboth apply residual connections to the sublayers, followed by normalization of the layers.  \\n  \\nSelf-Attention  \\nAttention describes the mechanism for a better understanding of the word's context by paying attention to the vital part of the sentence or any input. It involves mapping a vector of \\nquery and a set of key -value pairs to an output vector. \\nAccording to [24], self -attention refers to Scaled Dot -Product\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 4}),\n",
       " Document(page_content='Attention  consisting of queries and key dimensions 𝑑𝑑\\n𝑘𝑘, and \\ndimension 𝑑𝑑𝑣𝑣 values computed according to the following \\nformula:  \\n \\n𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴 (𝑄𝑄,𝐾𝐾,𝑉𝑉 ) = 𝑠𝑠𝐴𝐴𝑓𝑓𝐴𝐴𝐴𝐴 𝑠𝑠𝑥𝑥(𝑄𝑄𝐾𝐾𝑇𝑇\\n√𝑑𝑑𝑘𝑘)𝑉𝑉              (6) \\nFigure 5 depicts  the structure attention whereby the SoftMax \\nactivation function is used to compute the weights on values.   \\n \\nFIGURE 5. Self-attention architecture  [24] \\n Mult i-head attention \\nA multi- head attention mechanism proposes that self -', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 4}),\n",
       " Document(page_content='attention can be run multiple times in parallel mode combining knowledge of the same a ttention pooling via \\ndifferent representation subspaces of queries, keys, and \\nvalues.  Afterward, the independent attention outputs are \\nconcatenated and linearly transformed into the expected \\ndimension, as portrayed by equation 7 and figure 6.  \\n  \\n \\n      \\nFIGURE 6. Self-attention architecture [24] \\n \\n𝑀𝑀𝑀𝑀𝑀𝑀 𝐴𝐴𝐴𝐴𝑀𝑀𝐴𝐴𝑠𝑠𝑑𝑑 (𝑄𝑄,𝐾𝐾,𝑉𝑉 )=', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 4}),\n",
       " Document(page_content=\"𝐶𝐶𝐴𝐴𝐴𝐴𝐶𝐶𝑠𝑠𝐴𝐴(ℎ𝐴𝐴𝑠𝑠𝑑𝑑 1,...ℎ𝐴𝐴𝑠𝑠𝑑𝑑 ℎ)𝑊𝑊𝑜𝑜                                         (7)      \\n \\nwhere ℎ𝐴𝐴𝑠𝑠𝑑𝑑 𝑖𝑖 = Attention ( 𝑄𝑄𝑊𝑊𝑖𝑖𝑄𝑄,𝐾𝐾𝑊𝑊𝑖𝑖𝑘𝑘,𝑉𝑉𝑊𝑊𝑖𝑖𝑣𝑣) \\n \\nSince the Transformer's  invention, several variants have been \\ndeveloped to solve different machine- learning  tasks in \\ncomputer vision and natural language processing. It's \\nimperative to note that the state -of-the-art models are built on \\nthe foundation transformer architecture  [63]. In the following\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 4}),\n",
       " Document(page_content=\"subsection, we will discuss the contemporary generative \\nmodels.  \\n \\n \\n1) GENERATIVE PRE-TRAINED TRANSFORMER (GPT) \\nA Generative Pretrained Transformer (GPT) describes the \\ntransformer -based large language model (LLM) that utilizes  \\ndeep learning techniques to generate a human- like text  [64]. \\nThe model  was introduced by OpenAI in 2018 [65], \\nfollowing Google's 2017 invention of a transformer.  It is \\nmade of a stack of transformer decoders.  They proposed a\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 4}),\n",
       " Document(page_content='model consisting of two stages: learning a high- capacity \\nlanguage model from a large corpus of text and fine -tuning it \\nwith labeled data during the discriminative task, as depicted \\nin figure 7.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 4}),\n",
       " Document(page_content='FIGURE 7. Self-attention architecture [65] \\n \\n GPT or GPT -1 was trained on the BooksCorpus dataset, \\nwhich consists of over 7,000 unique unpublished books in many genres, such as Adventure, Fantasy, and Romance, all with long stretches of contiguous text, allowing the \\ngenerative model to lear n on long- range information  [61][62] \\n[65]. The model training specification included the following:  \\n• 12-layer decoder -only transformer.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content='• Masked self -attention heads (768- dimensional states \\nand 12 attention heads).  \\n• Position -wise feed -forward networks.  \\n• Adam optimization.  \\n• Learning rate:  2.5e-4. \\n• 3072 -dimensional inner states.   \\nThe assessment tasks for the model were drawn from four \\nprimary categories within Natural Language Processing \\n(NLP): these encompass natural language inference, question \\nanswering and common- sense reasoning, semantic similarity,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content='and classification.  Following the initial release, OpenAI has \\nproduced a series of variant models known as GPT -n series \\nwhere  every successor model is more substantial and efficient \\nthan the predecessor.  GPT -4 is the most recent variant release \\nin March 2023.  \\n \\n2) GPT-2 \\nAfter the great success of GPT -1, , OpenAI released a second \\nversion (GPT -2) in 2019 with 1.5 billion learnable \\nparameters, ten times more in pre- training corpus and', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content='parameters than its predecessor trained on WebText, a collection of millions of webpages.  [66]. As a result, this \\nmodel is capable of handling complex problems and \\ngenerating coherent and contextually relevant texts across a \\nwide range of topics and styles.  \\n \\n3) GPT-3 \\nThis version was released in 2020 and had 2048- token \\ncontexts, 175 billion learnable parameters, which is more \\nthan 100 times its predecessor, and required 800GB of', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content='storage [67]. CommonCrawl was used to train the model, \\nwhich was tested on all domains of NLP, and it had promising \\nfew-short and zero -shot performance.  This version was \\nfurther improved to GPT 3.5, which was used to develop \\nChatGPT.  Considerable research work has been conducted, \\nincorporating GPT -1 to GPT -3.5 across various task  such as \\nSpeech Recognition [68] [69] [70], Text Generation  [71] [72]', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content='[73] [74] [75] [76] [77] [78], Cryptography [79] [80] [81] [82], Computer Vision [88] [89], and Question Answering  \\n[83] [84] [85] [86] [87]. \\n \\n4) GPT-4 \\nIn March 2023, the most recent GPT model was released  by \\nOpenAI [90]. It’s a multimodal transformer  model , A large -\\nscale language model  which  accept s image and text inputs \\nand produce text outputs. In a number of professional and \\nacademic benchmarks, including passing a bar and medical', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content='exam at high rates, GPT -4 exhibits high performance \\ncomparable to that of humans [91] [92]. The model was \\ntrained using publicly available internet data and data licensed from third parties and then fine -tuned using \\nReinforcement Learning from Human Feedback (RLHF).  It \\nwas compared with state- of-the-art models using Measuring \\nMassive Multitask Language Understanding (MMLU)  [93] \\nthat covers 57 tasks in elementary mathematics, US history,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content='computer science, law, and more and outperformed them all.  \\n \\nC. GENERATIVE ADVERSARIAL NETWORK (GAN)  \\n1) GAN OVERVIEW  \\nA generative adversarial network (GAN) is an unsupervised generative model that consists of two neural networks: a \\ngenerator and a discriminator . A generator attempts to \\nfabricate new data (fake) that is indistinguishable from real \\ndata, while a discriminator tries to distinguish between real and fabricated data  [94]. Figure 8 illustrate the  schematic', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content='architecture of GAN (Also known as a vanilla GAN ). The \\ngenerator network takes noise as input and generates fake \\ndata. The discriminator network takes both real and fake data \\nas input and classifies them as real or fake using a sigmoid activation function and binary cross -entropy loss  [95]. Since \\nthe generator does not have direct access to authentic images \\n,it only learns through interactions  with the discriminator; the \\ndiscriminator has access to synthetic and authentic images.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content='Upon completion of classification, backpropagation takes \\nplace to optimize the training process  [94]. This process \\nrepeats itself until the difference between real and fake data \\nsamples is negligible.  \\n \\n \\n                FIGURE 8. Schematic G AN architecture        \\nAccording to Goodfellow et al . [25],  the generator (G) and \\ndiscriminator (D) are trained together in a minimax game', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 5}),\n",
       " Document(page_content=\"(zero -sum game). In this game  as demonstrated by equation \\n8, G is trying to maximize the probability that D misclassifies \\nits output as real data, while D is trying to minimize the \\nprobability that it misclassifies G's output.  \\n \\n𝒎𝒎𝒊𝒊𝒎𝒎𝑮𝑮𝒎𝒎𝒎𝒎𝒎𝒎𝑫𝑫𝑽𝑽(𝑫𝑫,𝑮𝑮)  =𝑬𝑬𝒎𝒎~𝒑𝒑𝒅𝒅𝒎𝒎𝒅𝒅𝒎𝒎(𝒎𝒎)[𝐥𝐥𝐥𝐥𝐥𝐥𝑫𝑫(𝒎𝒎)]        \\n+ 𝑬𝑬𝒛𝒛~𝒑𝒑𝒛𝒛(𝒛𝒛)[𝐥𝐥𝐥𝐥𝐥𝐥 (𝟏𝟏−𝑫𝑫(𝑮𝑮(𝒛𝒛)))]              (8)    \\n \\nWher e E is the Expected Value, 𝒑𝒑𝒅𝒅𝒎𝒎𝒅𝒅𝒎𝒎(𝒎𝒎) is Real  data \\ndistribution  and 𝒑𝒑𝒛𝒛(𝒛𝒛) implies Noise data distribution .\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='2) GAN CHA LLENGES  \\nDespite their robustness, traditional GANs suffer from \\nlimitations such as : \\n      Mode collapse : In this phenomenon, the generator can \\nonly produce a single type of output or a limited number of outputs  [96]. This is because the generator becomes stuck in \\na particular mode or pattern, failing to generate diverse \\noutputs that cover the entire data range  [97]. There are two', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='main causes of mode collapse in GANs. The first is catastrophic forgetting  [98], which occurs when learning in a \\ncurrent task destroys knowledge learned in a previous task. \\nThe second cause is discriminator overfitting, which results \\nin the generator loss vanishing [99]. \\n      Non -convergence and Instability : The loss function in \\nequation 8 can cause the generator to suffer from gradient \\nvanishing [100] . This can happen when the discriminator', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='learns too quickly and can easily distinguish between real and \\nfake samples. On the other hand, the generator may have a \\nlower learning rate and be unable to keep up. This can lead to \\nthe training process stalling, as the generator cannot learn \\nfrom the feedback provided by the discriminator. GANs are also known to be sensitive to the choice of hyperparameters, \\nsuch as the learning rate and the batch size. This means that \\nit can be challenging to train GANs consistently, as even', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content=\"small changes to the hyperparameters can significantly \\nimpact the results [101] . \\n    Gradient vanishing can be addressed using a different loss function, such as the Wasserstein loss. The Wasserstein loss \\nis less sensitive to the discriminator's learning rate, and it can \\nprevent the generator's gradients from disappearing. Another solution would be to use a generator with a smaller learning \\nrate. This will prevent generator weights from becoming too\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='large, whi ch can also contribute to gradient vanishing. In \\naddition, a good initialization technique must be used for the \\ngenerator. In this manner, the generator will start well, and \\nthe training process will likely be successful.  \\n \\n3) \\nGAN VARIANTS  \\nIn response to the aforementioned GAN challenges, various \\nvariants have been developed to address the weaknesses and \\noptimize the model. Here are some of the most famous \\nvariants of GAN since its emergence in 2014:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='Condi tional Generative Adversarial Network ( cGAN)  \\ncGAN was introduced  by Mirza et al.  [102]  in 2014,  this \\nvariant enhances the classical GAN by incorporating extra auxiliary information into the Generator and Discriminator \\nnetworks, such as class labels or style attributes. This \\nintegration is achieved by introducing an additional layer that \\nincludes the conditional information input to the generator, \\ninstructing it on what to produce  [103] . For instance, in an', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='image generation scenario, this condition might consist of a \\nclass label that precisely defines the type of image to be \\ngenerated.  \\n \\n   The Deep Convolutional GAN (DCGAN)  framework \\nemploys a deep learning model for discriminator and \\ngenerator components, specifically a Convolutional Neural \\nNetwork (CNN). In the architectural design defined by \\nRadford et al. [104] , traditional fully connected layers', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='situated on top of convolutional features have been omitted. Additionally, including Batch Normalization plays a pivotal \\nrole in enhancing training stability. This technique \\nnormalizes the input to each neural unit, ens uring a mean of \\nzero and unit variance, thus facilitating more consistent and efficient learning. Moreover, DCGAN substitutes \\nconventional pooling layers with strided convolutions in the \\ndiscriminator and fractional -strided convolutions in the', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content=\"generator ne twork. The Rectified Linear Unit (ReLU) serves \\nas the activation function for the generator, while the Leaky \\nReLU is employed in the discriminator.  These activation \\nfunctions play a crucial role in enabling the networks to capture intricate patterns and features.   \\n \\n    Wasserstein GAN  (WGAN) is a GAN variant that \\nemploys the Wasserstein distance (also referred to as the \\nEarth Mover's distance) as its loss function, distinguishing\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='itself from traditional GANs that typically use the Jensen -\\nShannon or Kullback- Leibler divergences. The Wasserstein \\ndistance (WD) measures the similarity between the \\ndistributions of real and generated samples [105] . It is \\ngrounded in the solution to a classical optimization problem \\nknown as the transportation problem  [106] . In this context, \\nsuppose there exists several  suppliers, each endowed with a', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='certain quantity of goods, tasked with delivering to several consumers, each having a specified capacity limit. Each supplier -consumer pair incurs a cost for transporting a single \\nunit of goods. The transportation problem ai ms to identify the \\nmost cost -efficient allocation of goods from suppliers to \\nconsumers.  \\n \\n𝑊𝑊�𝑃𝑃\\n𝑟𝑟,𝑃𝑃𝑔𝑔�= 𝐴𝐴𝐴𝐴𝑓𝑓\\n𝛾𝛾∈𝜋𝜋(𝑃𝑃𝑟𝑟,𝑃𝑃𝑔𝑔)𝐸𝐸(𝑥𝑥.𝑦𝑦)~𝛾𝛾[ || 𝑥𝑥−𝑦𝑦|| ]                     (9)    \\n \\n    WD is expressed  by equation 9, 𝑷𝑷𝒓𝒓 𝑠𝑠𝐴𝐴𝑑𝑑  𝑷𝑷𝒈𝒈 denotes  the', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='probability distribution of real ad generated sample \\nrespectively.  The Lipschitz constraint was utilized to impose \\nweight clipping on the discriminator [107] . This measure \\nenhances training stability, mitigating challenges like mode \\ncollapse and saturation loss.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 6}),\n",
       " Document(page_content='Cycle GAN is an approach that automates training image -\\nto-image translation models without requiring paired \\nexamples, leveraging GAN architecture [108] . It utilizes \\nunassociated image collections from distinct source and \\ntarget domains (e.g. Domain X and Domain Y). The model structure comprises two generators: Generator -X crafts \\nimages for Domain X, and Generator -Y generates images for \\nDomain Y. Each gen erator associated with a its', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content='corresponding discriminator for binary classification.  \\n      This variant incorporates three loss functions: firstly, the \\ncycle consistency losses ensure that translations between domains maintain a coherent loop, returning to their original \\npoint; secondly, the adversarial loss pits the Generator against \\nits corresponding Discr iminator, with the Generator striving \\nto generate domain -specific images while the Discriminator', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content='distinguishes between translated and real samples; and thirdly, the Identity Loss incentivizes the Generator to \\nfaithfully preserve color co mposition between input and \\noutput, enhancing translation fidelity.  \\n \\n    StarGAN :  a method that harnesses the power of the GAN \\narchitecture for versatile multi- domain image -to-image \\ntranslation. As outlined by Choi  et al [109] , this innovative \\ngenerative adversarial network masterfully learns mappings', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content='among numerous domains, employing just a single generator \\nand discriminator, and efficiently trains on images spanning \\nall domains. This model utilizes an Adversarial Loss to make  \\ngenerated images virtually indistinguishable from real ones, \\na Domain Classification Loss to guarantee precise \\nclassification by the discriminator and a Reconstruction Loss \\nthat minimizes adversarial and classification losses.  \\n \\nIn the preceding subsection, we have delved into several', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content='variants of Generative Adversarial Networks (GANs). However, it is worth noting that the landscape of GANs \\nencompasses a myriad of additional variants that have \\nsignificantly advanced beyond the foundational GAN framework. These notable advancements include the \\nProgressive GAN (PGAN) of 2017  [110] , BigGAN of 2018  \\n[111] , StyleGAN  [112]  and StyleGAN 2  [113]  of  2019, along \\nwith earlier innovations such as InfoGAN  [114] , Stacked', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content='GAN [115] , Bidirectional GAN (BiGAN) [116]  from 2016.  \\n \\nD. DIFFUSION MODEL  Diffusion model  is a generative  model  characterized by a \\ntwo-step process. Initially, they introduce Gaussian noise into \\nthe training data, a step referred to as the forward diffusion process. Subsequently, they perform the reverse diffusion \\nprocess, often called denoising, to reconstruct the original data. Over time, the model progressively acquires the ability \\nto eliminate the added noise.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content='III. GENERATIVE AI TASK  \\nGenerative AI encompasses a wide array of tasks, including Speech Generation (Text -to-Speech), Image Generation \\n(Text -to-Image), Text Generation (Text -to-Text), Code \\nGeneration (Text -to-Code), Music Generation (Text -to-\\nMusic), Video Generation (Text -to-Video), and Scientific \\nContent Generation (Text -to-Science). These tasks are \\nsupported by various cutting -edge tools, as illustrated in', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content='Table 2. Notably, Google boasts the most generative tools, with Meta AI and OpenAI following closely. Most of these \\ntools w ere unveiled in 2023, although a few were introduced \\nearlier.  \\nA. TEXT  GENERATION  \\nThis task  involves taking text as input and generating \\ncorresponding text -based responses. It is often associated \\nwith question -and-answer conversational systems, \\ncommonly called chatbots. Many renowned generative AI \\ntools fall within this category, with ChatGPT be ing a', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content=\"groundbreaking example in the field of Generative AI. Other notable tools in this category include Google's Bard, \\nOpenAI's ChatGPT Plus, Wordtune Spice, and Cohere's \\nGenerate.  We conducted a comprehensive performance \\nassessment of two promin ent and renowned text -to-text tools, \\nBard and ChatGPT. Both were presented with identical queries: ‘Provide a brief description of what Bard is in one \\nparagraph ’, ‘Provide a brief description of what ChatGPT is\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content='in one paragraph’,  and a Swahili question, ‘ Habari za saa \\nhizi’. The results as illustrated by figure  9, unmistakably \\nindicate that ChatGPT outperformed Bard in delivering more \\nprecise answers to the questions.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 7}),\n",
       " Document(page_content=\"(a)  \\n(b) \\n(c)  \\n(d) \\n \\n                                                          FIGURE 9. (a) chatGPT chatbot, b -d are bard output.  \\n   \\nB. IMAGE  GENERATION  \\nIt’s a task which encompasses  the process of utilizing textual \\nprompts  or visual to generate corresponding images, \\nspanning various visual domains, including graphics, \\nphotographs, and artwork. As an illustration of text -to-image \\nconcept , we conducted experiments using 'Firefly' from\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 8}),\n",
       " Document(page_content=\"Adobe and 'Stable Diffusion' by Stability as our subjects. By \\nprompting these models with ‘ College Student \\nProgramming’ , we obtained their respective outputs, as \\nshowcased in Figure 10, t he results clearly indicate that while \\n'Firefly' excelled in delivering more precise outputs in alignment with the input, S table Diffusion exhibited superior \\nimage resolution compared to its counterpart.  Another \\nscenario image generation revolves around the\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 8}),\n",
       " Document(page_content='transformation of an image from one form to another, guided \\nby textual descriptions provided as input. Within this domain, numerous tools have demonstrated promising capabilities in \\neffecting such transformations. Notably, we have explored \\nthe performance of RoomGPT and Runaway, as exemplified \\nin Figure 11 and Figure 12, respectively.  \\nC. VIDEO GENERA TION  \\nThis task involves generating new videos based on textual or \\nvisual inputs, whereby visual encompasses a diverse range of', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 8}),\n",
       " Document(page_content='content that includes both images and videos. In this domain, \\nthere are notable tools designed to accommodate exclusively \\ntext-based descriptions as inputs. A prime example is ‘ Parti ’ \\nby Google,  and DALL  E-2 [117]  by openAI  are proficient \\ntools focused on creating videos solely from textual prompts. \\nNonetheless, the field of video generation is in a state of \\ncontinuous evolution. Tools such as ‘ Gen-2’ by RunwayML, \\n‘Imagen Video ’ by Google [118] , and ‘ Make -A-Video ’ by', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 8}),\n",
       " Document(page_content='Meta[119]   have emerged as pioneers. These advanced \\nplatforms possess the remarkable capability unlimited to', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 8}),\n",
       " Document(page_content='textual descriptions but also seamlessly integrate images and \\nvideos as input, transcending conventional boundaries. Their \\nexcellence lies in their adeptness at transforming these inputs \\ninto entirely novel video compositions, thus unveiling the exciting potential of generative AI in the creative realm of video production.  \\n  \\n \\n \\n(a) \\n \\n(b) \\n \\n                             FIGURE 10. (a) Adobe firefly, (b) stable diffusion image generated using text “ college Student', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 9}),\n",
       " Document(page_content='Programming”.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 9}),\n",
       " Document(page_content='D. CODE GENERATION  \\nCode generation tools are specialized software utilities \\ncapable of automatically producing code blocks for various \\nprogramming languages based on textual descriptions \\nprovided as input [120] . These tools leverage sophisticated \\nmodels trained on extensive publicly available code \\nrepositories, boasting billions of parameters. Their primary \\nobjective is to assist human developers by comprehending \\nplain English and translating it into functional code. Notable', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 10}),\n",
       " Document(page_content=\"examples of such tools include StarCoder  [121] , Codex\\n [122] , CoPilot,  Codey, and Code Interpreter. \\nAdditionally, it's worth noting that several text- to-text tools, \\nincluding ChatGPT  and Bard as depicted by F igure  13 , also \\npossess the capacity to generate code.   \\n E. MUSI C GENERATION  \\nIt's a fascinating generative task involving entirely new music's \\ncomposition. This innovative process takes input in various forms, including textual descriptions, sequences of musical\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 10}),\n",
       " Document(page_content='notes, and even audio samples [123] . The objective is to \\nharness these inputs and transform them into fresh musical \\ncompositions that encapsulate rhythm, melody, harmonious \\nchords, and diverse musical instruments. Prominent tools like \\nMuseNet  [124]  and Jukebox[125]  stand out as prime examples \\nin the music  generation. These innovative platforms harness', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 10}),\n",
       " Document(page_content='the power of generative AI to craft musical compositions spanning various genres and styles. They excel in infusing creativity into the art of music, opening  new avenues for artists \\nand enthusiasts to explore and enjoy.  \\n \\n \\n         \\nFIGURE 11 . (a) Original Living Room [126]  and (b) Generated new living room using roomGPT  \\n \\n \\n           a  \\n                    b  \\nFIGURE 12. (a) Original BSU Natural Science Building [127]  and  (b) Generated new living room  using runway with prompt', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 10}),\n",
       " Document(page_content='a                                            b', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 10}),\n",
       " Document(page_content='a  \\nb \\n \\nFIGURE 1 3. Code generation using ( a) ChatGPT and (b) Bard\\n \\nF. SPEECH GENERATION  \\nThe generation of human- like speech or voice relies on \\ntextual or audio input. Textual input can encompass written \\ntext, such as sentences, paragraphs, or entire documents, and \\nit can span multiple languages, including punctuation, \\nspecial symbols, and for matting instructions. Speech \\ngeneration models, such as SpeechGAN, undertake a', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 11}),\n",
       " Document(page_content='sequence of steps that involve speech synthesis, enhancement, and conversion. The enhancement process \\nincludes noise handling, tone modulation, emotion \\nconveyance, and other nua nced features [128] [129] . \\nNumerous tools have been developed in this domain to \\nfacilitate speech generation, some of which include Whisper, \\nSpeechelo, Synthesys, Voice Over, and WaveNet. These tools are proficient in generating voices or speech that closely mimic natural language , effectively blurring the line', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 11}),\n",
       " Document(page_content='between human and artificial speech synthesis.  \\nG. SCIENTIFIC CONTENT GENERATION  \\nScientific content generation is a multifaceted process \\nencompassing the creation of informative and scholarly content across various domains of science, including \\nmathematics, physics, chemistry, and biology. This endeavor seeks to harness the power of generative AI to produce \\ncontent that is accurate and insightful, aiding in \\ndisseminating scientific knowledge. O ne notable study in', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 11}),\n",
       " Document(page_content=\"this field, conducted by Rodriguez  et el. [130] , delved into the \\ninnovative way of generating scientific figures based on textual input. This groundbreaking research leveraged \\ndiffusion models to seamlessly translate textual descriptions \\ninto visually informative scientific figures, thereby \\nstreamlinin g the process of scientific communication and \\nvisualization. Furthermore, Google's ongoing research project, Minerva[131] , represents a significant stride in\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 11}),\n",
       " Document(page_content='solving quantitative reasoning problems. This initiative \\nharnesses the capabilities of Large Language Models \\n(LLMs) to tackle complex quantitative challenges, thereby \\nenhancing our understanding of mathematics and its \\npractical applications within the scientific landscape. In \\nparallel, Galactica [132] , a cutting -edge tool developed by \\nMeta AI, plays a pivotal role in scientific writing. This \\nplatform equips scientists and researchers with powerful', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 11}),\n",
       " Document(page_content='tools to streamline articulating their scientific discoveries, theories, and insights.  \\n \\n \\nTABLE  2 \\nGENERETIVE  AI TOOLS  \\n  Tool   Developer  Task   Year  Additional Description  \\n1 VoiceBox  Meta AI  Text-to-Speech  2023  Generate voice clips  \\n2 Genny  Lovo  Text-to-Speech , \\nText-to-Image  2020  Can generate voice over and art image  \\n3 Metamate  Meta AI  Text-to-Code  2023  Software debugging', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 11}),\n",
       " Document(page_content='4 Scribe AI  Scribe  Computer Vision  2023  Creates Documentation, how -to guides, \\nSOPs and training manuals  \\n5 Read  Read.ai  Speech -to-Text 2021  Virtual meeting Automated summary, \\ntranscripts, playback, and highlights on  \\naction items, key questions, and real -\\ntime engagement  \\n6 appleGPT  Apple  Text-to-Text 2023  chatbot summarize text and answer \\nquestions  \\n7 Einstein \\nGPT  SalesForce  Text-to-Text 2023  Chatbot built in top for chatGPT  which', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 12}),\n",
       " Document(page_content='generate text, translate languages, write different kinds of creative content, and \\nanswer questions  \\n8 flashGPT  Neuroflash  Text-to-Text 2020  A generative Chatbot which use flash   \\n9 AlphaCode  DeepMind  Text-to-Code  2022  Generate code,creative content, and \\nrespond to questions in an informative \\nway \\n10 Cloude 2  Anthropic  Text-to-Text 2023  Content Generation, AI Assistant  \\n11 Jasper  Jasper  Text-to-Text 2021  Generate Creative Contents', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 12}),\n",
       " Document(page_content='12 PaLM 2  Google  Text-to-Text 2023  Generate code, creative content, \\nTranslation and Q&A  \\n13 Shepherd  Meta AI  Text-to-Text 2023  Improve the accuracy of AI generated \\nresponse  \\n14 Murf  Murf.Ai  Text-to-Speech  2020  Generate voice -over for  Creative \\ncontents and Presentation  \\n15 Codex  OpenAI  Text-to-Code  2021  Code Generator  \\n16 Codey  Google  Text-to-Code  2023  Generate Code based on user input  \\n17 DALL -E 2 OpenAI  Text-to-Image  2023  Generate image from text description', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 12}),\n",
       " Document(page_content='18 DeepDream  Google  Text-to-Image  2015  Generate psychedelic images  \\n19 Midjourney  Midjourney, Inc  Text-to-Image  2022  Generate realistic and creative image \\nfrom text prompt  \\n20 Firefly  Adobe  Text-to-Image  2023  Generative image from text prompt  \\n21 RoomGPT  RoomGPT.io  Text-to-Image  2023  Design home and room  \\n22  StyleGAN  Nvidia  Text-to-Image  2019  Generate realistic and creative image \\nfrom text prompt  \\n23 Stable', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 12}),\n",
       " Document(page_content='23 Stable \\ndiffusion  Stability AI  Text-to-Image  2022  Generate photo -realistic images given \\nany text input  \\n24 NovelAI  Anlatan  Text-to-Image  2021  Generate image from text input and \\nstrorywriting  \\n25 CM3leon  Meta AI  Text-to-Image  2023  generate  text and images  \\n26 Imagen  Google  Text-to-Image  2023  Generate realistic image  \\n27 Photosonic  Writesonic  Text-to-Image  2020  Generate image from text input', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 12}),\n",
       " Document(page_content='28 AI Art  Nightcafe  Text-to-Image  2019  Generate image from text input  \\n29 Canva AI  Canva  Text-to-Image  2023  Generate image from text input  \\n30 Dreamstudi\\no Stability AI  Text-to-Image  2022  Generate photo -realistic images given \\nany text input  \\n31 StarryAI  StarryAI Inc  Text-to-Image  2021  Generate image from text input  \\n32 ChatSonic  Writesonic  Text-to-Image, \\nText-to-Text,  2022  Conversational chatbot which can \\ngenerate human text response and \\nimage', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 12}),\n",
       " Document(page_content='image  \\n33 Soundful  soundful  Text-to-Music  2021  Create customized music based on \\nindividual needs', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 12}),\n",
       " Document(page_content='34 Boomy  Boomy  Text-to-Music  2019  Develop music without prior \\nknowledge.  \\n35 Soundraw  Soundraw Inc  Text-to-Music  2021  Generate Music  \\n36 AudioCraft  Meta AI  Text-to-Music  2023  Music Generator  \\n37 MusicGen  Meta AI  Text-to-Music  2023  Music Generator  \\n38 Galactica  Meta AI  Text-to-Science  2022  tool for scientific writing  \\n39 Minerva  Google  Text-to-Science  2022  Solve Quantitative reasoning problem', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 13}),\n",
       " Document(page_content=\"40 WaveNet  DeepMind  Text-to-Speech  2016  Generate realistic speech from text or \\nother audio inputs  \\n41 Voice Over  Speechify  Text-to-Speech  N/A Creates natural Voiceovers for any \\nContent  \\n42 TexTalky  Textalky  Text-to-Speech  2021  Creates realistic voice from text  \\n43 speechelo  speechelo  Text-to-Speech    Creates realistic voice from text  \\n44 Overdub  Descript's  Text-to-Speech  2021  Creates realistic voice from text\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 13}),\n",
       " Document(page_content='45 Synthesys  Synthesys  Text-to-Speech  2020  Create voiceover from text  \\n46 Kits kits Text-to-Speech  N/A Voice generator  \\n47 WellSaid  WellSaid Lab  Text-to-Speech   N/A Voice generator  \\n48 Altered \\nStudio  Altered  Text-to-Speech  2023  Voice generator  \\n49 Whisper  OpenAI  Text-to-Speech  2022  Speech  recorgnition and translation  \\n50 Jukebox  OpenAI  Text-to-Speech  2020  Music Generator  \\n51 LaMDA 2  Google  Text-to-Speech  2022  Customer Service Chatbots, Q&A,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 13}),\n",
       " Document(page_content='Translation, Research  \\n52 PEER  Meta AI  Text-to-Speech  2022  Writing tool  \\n53 chatGPT  OpenAI  Text-to-Text 2022  Conversational chatbot that generates \\nhuman -like text responses  \\n54 Bard  Google  Text-to-Text 2023  Conversational chatbot that generates \\nhuman -like text responses  \\n55 Generate  Cohere  Text-to-Text 2022  Content Generation  \\n56 chatGPT \\nplus (GPT -\\n4) OpenAI  Text-to-Text 2023  Advanced ChatGPT, Conversational \\nchatbot that generates human- like text \\nresponses', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 13}),\n",
       " Document(page_content='responses  \\n57 Wordtune \\nSpice  AI21 Labs  Text-to-Text 2023  Writing Generator  \\n58 Gen-2 RunwayML  Text-to-Video  2023  Design video from text input  \\n59 Synthesia  Synthesia  Text-to-Video  2018  Generate video from text input  \\n60 Make -A-\\nVideo  Meta AI  Text-to-Video  2022  Generate video from text input  \\n61 Imagen \\nVideo  Google  Text-to-Video  2022  1280x768 HD videos at 24 frames per \\nsecond from text  limited  to inanimate \\nobjects', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 13}),\n",
       " Document(page_content='objects  \\n62 Phenaki  Google  Text-to-Video  2023  Generate video from text input of \\nanimate objects  \\n63 Descript  Descript  Text-to-Video  2020  Generate video from text input  \\n64 GitHub \\nCopilot  Microsoft/GitHub/OpenA\\nI Text-to-Code  2021  Code Generator and Suggestion  \\n65 Sensei   Adobe  Text-to-Image  2017  Generate automative workflow and \\npersonalize cunstomer experience  \\n66 parti Google  Text-to-Image  2023    \\n67 StarCoder  Hugginface +', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 13}),\n",
       " Document(page_content='ServiceNow  Text-to-Code  2023  state-of-the-art large language model \\n(LLM) for code', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 13}),\n",
       " Document(page_content='68 Amper  Amper  Text-to-Music  2023  Generate Music of various genres  \\n69 MuseNet  OpenAI  Text-to-Music  2019  Generate Music of various genres  \\n70 MusicLM  Google  Text-to-Music  2023  Generate Music of various genres  \\n71 quillbot  Course Hero  Text-to-Text   Can paraphrase, rewrite  the text  \\n72 Rephrase.ai  Rephrase.ai  Text-to-Video    Can Generate video using avatar by text \\nprompt  \\n73 Studio bot  Google  Text-to-Code  2023  Code Companion for android developer', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content=\"IV.        INDUSTIRIAL APPLICATION OF \\nGENERATIVE  AI \\nGenerative AI technology's relevance in the present and future is indispensable. Currently, Generative AI is exerting \\nan exponential impact across a broad spectrum of industries, \\nand this section will delve into a detailed exploration of the \\nsectors that are mostly impacted . \\nA. MEDIA AND ENTERTAINMENT  \\nIn the entertainment industry, Generative AI models are \\nbeginning to have a significant impact despite being in their\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content='early stages. Their influence spans various entertainment \\ndomains, encompassing scriptwriting and storyboarding for novels, plays, and fil ms, audio production [133]  involving \\ncomposition, arrangement, and mixing, game design and \\ncharacter creation, the creation of captivating virtual worlds, \\nmarketing campaigns, and the generation of both moving and \\nstatic images. Notably, a wide range of accessible tools, as \\ndemonst rated in Table 3, make it easier to generate content', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content='such as reels, jokes, and images [134] . Many of these tools \\nare cost -effective or even free, providing an alternative to \\ntraditional content creation methods. As an illustration of their potential, in 2022, RunwayAI  played a role in creating \\nthe Academy Award -winning film “Everything Everywhere \\nAll at Once ” which  received recognition with seven  Oscars  \\naward [135]  [136] . \\nB. EDUCATION AND RESEARCH', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content='Generative AI is rapidly reshaping the educational landscape, offering innovative solutions that elevate the \\nlearning experience for both students and educators. One \\nsignificant impact of Generative AI in education is the \\nemergence of personalized content generation tools. \\nExemplified by technologies like GPT -3, GPT -4 and Bard , \\nthese tools empower educators to craft tailored learning \\nmaterials, including interactive lessons, quizzes, and study', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content=\"guides, precisely catering to the unique needs of individual \\nstudents  and instructors [137] . Furthermore, AI -driven \\nchatbots and virtual tutors provide students with real -time \\nsupport, offering explanations, addressing queries, and \\ndelivering personalized feedback [138] . This transformative \\ntechnology holds the potential to reinvent how students \\naccess and engage with educational content, promoting \\naccessibility and adaptability according to each learner's\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content='specific preferences [139]  [140] .      Generative AI has also opened new avenues of research \\nand academic exploration. The rapid development of \\nGenerative AI tools has piqued the interest of researchers and \\nacademics across the globe, leading to an array of research \\nopportunities  [141] . Tech giants and research institutions are', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content='investing significant resources to explore and invent new tools and technologies in this field. This is evident in the surge of publications related to Generative AI, both in peer -\\nreviewed databases like IEEE and  non-reviewed platforms \\nlike arXiv, where Generative AI topics have gained prominence. The fusion of education and Generative AI has not only transformed the learning experience but has also \\nsparked a thriving academic domain that promises continued \\ngrowth and innovation [142] .', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content='C. HEALTHCARE  \\nGenerative AI is making substantial inroads in healthcare, particularly in medical imaging [143] . It plays a crucial role \\nin overcoming challenges related to limited datasets by \\nenabling the synthesis of new data [144]  [145] , ultimately \\nenhancing the quality and diversity of medical images. This \\ninnovation is set to revolutionize disease detection and \\ndiagnosis, providing healthcare professionals with more \\naccurate and detailed information. In addition, Generative AI', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content=\"is trans forming the administrative aspects of patient care. By \\nstreamlining administrative processes and offering virtual \\nhealth assistants, it simplifies healthcare management and provides personalized health advice, medication reminders, \\nand emotional support [146] .Moreover, Generative AI is \\nrevolutionizing treatment planning. Leveraging patient -\\nspecific data, it can generate customized treatment plans tailored to an individual's genetic makeup, lifestyle, and\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content='medical history. This approach represents a significant leap \\ntoward precision medicine, ensuring patients receive the \\nmost effective and personalized treatment.  \\n      Furthermore, Generative AI is playing a pivotal role in \\nthe realm of drug development and discovery[147]  [148]  \\n[149] . Through the generation of molecular structures [150]  \\nand predictive modeling, it expedites the identification of novel therapeutic compounds. These advancements can', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content='address previously untreatable diseases, instilling hope in \\ncountless patients across the globe. Notably, the \\ncollaboration between NVIDIA and Evozyne in \\nimplementing Generative AI, specifically ProT -VAE, \\nsignifies the remarkable synergy between AI and the healthcare sector. By employing the Protein Transformer \\nVariational AutoEncoder, they have laid the groundwork for', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 14}),\n",
       " Document(page_content='creating synthetic proteins [151] , opening up new avenues for \\ntherapeutic solutions in the fight against challenging \\nincurable diseases.  Yet another noteworthy example is the \\ncollaborative research venture between Google and Cognizant [152] . Their joint effort aims to construct a Large \\nLanguage Model (LLM) tailored for healthcare applications, \\nspecifically focusing on enhancing Healthcare \\nadministrative tasks. This endeavor harnesses the', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='capabilities of Google Cloud and its framework to crea te \\ncutting -edge generative AI solutions for the healthcare \\nsector.  \\nD. BUSINESS  \\nGenerative AI has firmly established its presence in the business landscape. Many of the applications listed in Table 3 operate on a subscription -based model, reflecting the \\ngrowing commercial nature of these tools. Bloomberg \\nIntelligence predicts that Gen erative AI (GAI) will generate \\n$137 billion in 2023 and is expected to surge to $1.3 trillion', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content=\"by 2030[153] . This profound impact extends across various \\nindustries, from manufacturing and wholesale to retail businesses, banking, agriculture, and many more. Generative \\nAI's reach spans from creating new products and automating \\nfinancial data analysis to generatin g personalized advertising \\ncampaigns [154] [155]  [156] , offering tailored product \\nrecommendations to customers, and producing product \\ndescriptions and news articles [157] . It is increasingly evident\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='that Generative AI is reshaping the business landscape and holds immense economic potential in the future.  \\n      For example, Amazon is actively harnessing Generative \\nAI capabilities to empower sellers in crafting engaging, compelling, and effective product listings through brief \\ndescriptions of their products. Amazon leverages Generative \\nAI to generate high- quality content, which sellers can further \\nrefine or directly submit to enrich the Amazon catalog[158] .', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='V. THE FUTURE OF GENERATIVE AI  \\nGenerative AI undoubtedly holds a significant and promising future, offering a plethora of tangible and transformative \\npossibilities across various domains. However, it is equally \\naccompanied by a considerable degree of uncertainty and a \\nrange of concerns that deserve in -depth exploration. This \\nsection aims to explore the multifaceted aspects of Generative AI, addressing its potential as well as the \\nchallenges and uncertainties that lie ahead.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='A. PIONEER OF FIR FTH INDUSTRIAL \\nREVOLUTION  (5IR)  \\nGenerative AI represents the promising frontier of the fifth \\nindustrial revolution (5IR), a force poised to revolutionize \\nthe fourth industrial revolution and create transformative \\nchanges across various sectors. This transformation is made possible by the  profound interconnection of internet \\ninfrastructure, extensive datasets, and distributed computing resources that transcend geographical', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content=\"boundaries. Several industries, including Healthcare, \\nSecurity, Cyber Infrastructure, Entertainment, and Education, ar e on the verge of significant disruption due to \\nGenerative AI's capabilities. However, it's crucial to \\nrecognize that this disruptive potential may also bring about \\ninfrastructure reforms across multiple sectors, potentially \\nleading to high levels of autom ation and optimization in \\nvarious career fields.  \\nOn Healthcare Industry , as we have witnessed,\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='Generative AI is already playing a pivotal role in drug discovery, with a particular emphasis on exploring protein molecules. The potential for this technology in the field of \\ndrug development is vast, and substantial investments from \\nmajor technology companies underscore the anticipated \\nadvancements in the near future. However, the impact of \\nGenerative AI extends far beyond drug development, as it \\nis expected to transform the patient experience within the', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content=\"healt hcare sector fundamentally. By harnessing patients' \\nmedical history data, it can autonomously diagnose medical \\nconditions by analyzing metadata like age, sex, and \\nunderlying medical conditions. Moreover, it can sift \\nthrough extensive patient data to identi fy patterns, make \\npredictions, and suggest appropriate medications. This \\ntransformation is set to prioritize patient- centered clinical \\nexperiences and drive cost -effectiveness, ultimately leading\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='to significant enhancements in healthcare protocols [159] . \\nEnhance d Entertainment , In the foreseeable future, \\nwe stand at the threshold of a transformative era where generative AI will likely dominate the realm of content \\ncreation in entertainment and media. From crafting intricate \\nscripts and narratives to meticulously arranging scenes and \\nbringing characters to life, the influence of generative AI is \\nset to permeate every facet of content gen eration in these', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='industries. Furthermore, the potential impact is so profound \\nthat it might even challenge the boundaries of life and art. \\nDeceased artists could potentially continue to release new albums and creative works, effectively transcending the \\nlimitations of mortality. Not only will this innovation usher \\nin a new age of artistic exploration, but it also promises \\nsignificant cost savings, revolutionizing the economics of movie and music production. Automating scene creation', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='and content generation w ill reduce expenses and make the \\ncreation process more efficient.  \\nNew education era, the advent of AI chatbots like \\nChatGPT and Google Bard, along with other innovative \\ntools, serves as compelling evidence of the democratization of Generative AI in the education industry. This remarkable \\nprogress has rendered the current educational system an d \\nresources outdated, particularly in developed countries. It \\nanticipates a comprehensive overhaul of the education', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='system, including teaching resources, to adapt to the \\nexponential growth in the generative AI era, aiming to provide highly personalized and adaptive learning \\nexperiences.  \\nAdvanced Manufa cturing Industries,  before the \\nemergence of Generative AI, robotics had already showcased impressive capabilities. However, with the \\nintegration of generative AI, we can look forward to truly remarkable advancements. Just envision the consequences', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 15}),\n",
       " Document(page_content='of infusing generative AI into military technology, where \\nwe might see the development of generative nuclear \\nweaponry, the formulation of chemical recipes for \\nbeverages, detergents, and various industrial products, and \\nthe widespread adoption of self -drivi ng vehicles. The range \\nof possibilities is extensive, and it undoubtedly signifies the \\nonset of a new era —an industrial revolution that promises \\na thoroughly transformed landscape and innovative', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content=\"approaches across numerous sectors of industries.  \\nB. JOB MARKET SHIFTING  \\nThe influence of Generative AI on the labor market is two -\\nfold:  \\nFirstly, it ushers in new employment opportunitie s in \\nemerging domains such as AI Explainability and Generative AI engineering. McKinsey's analysis  [160]  suggests a \\ngradual rise in job openings within professions exposed to \\nGenerative AI, and this trend is expected to persist until \\nroughly 2030. A noteworthy revelation is that a substantial\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='84% of the U.S. workforce occupies positions with the \\npotential to  leverage Generative AI for automating a \\nsignificant portion of repetitive tasks, leading to a \\nconsiderable surge in overall productivity. Significantly, \\n47% of U.S. executives express confidence that integrating \\nGenerative AI will lead to heightened produ ctivity across \\ndiverse industries [161]  [162] . \\nConversely, Job deterioration ; optimizing and', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content=\"automating business processes are anticipated to replace many existing careers with creative and generative AI \\nfunctions. Generative AI's impact on the labor market is \\npoised to transform the employment landscape, gradually replacing many traditional roles with advanced technology. \\nAccording to the World Economic Forum's r eport [163] , \\ntasks with the highest potential for automation by Large \\nLanguage Models (LLMs) are routine and repetitive. These\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='tasks include those performed by Credit Authorizers, \\nCheckers, Clerks, Management Analysts, Telemarketers, \\nStatistical Assistants, and Telle rs[164]  [165] . Therefore, \\nindividuals must prioritize reskilling and adaptability to prepare for AI -driven jobs in the future effectively.  \\nC. PRIVACY AND SECURITY CONCERNS  \\nThe cybersecurity infrastructure domain is presently \\nundergoing a profound and rapid transformation, primarily driven by the integration of Generative AI. This substantial', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='shift is giving rise to a host of pressing concerns and \\nchallenges for the future : \\nSophisticated cyberwarfare, currently , we are \\nwitnessing a notable surge in malicious activities, and this trend is expected to continue its upward trajectory while \\nalso becoming more intricate and sophisticated[166] . For \\ninstance  the emergence of cutting -edge cyber threat tools \\nlike WormGPT and FraudGPT [167]  [168] , which have', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='rapidly established themselves as pioneering elements in cyber threats often referred to as “ exclusive bots ” [169]  by \\ntheir perpetrators, are engineered to be highly sophisticated and evasive. Moreover, the emergence of increasingly automated and sophisticated malware and ransomware, \\npowered by Generative A I[170] , presents a menacing \\npotential for subverting existing encryption methods [171] .', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='This is primarily due to the immense computational prowess inherent in Generative AI. As these malicious \\nentities persist and advance, they represent a formidable \\nchallenge to the cybersecurity landscape, testing the limits \\nof the resilience and robustne ss of contemporary \\ncybersecurity systems and protocols [172] . The \\nconsequences of these developments are far -reaching, with', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content=\"the prospect of malicious AI proving to be devastating to a nation's critical infrastructure, particularly in scenarios \\ninvolving state -sponsored or malevolent cyber \\nterrorism [173] . \\n \\nIncreased Impersonation  and misinformation , \\nescalation of AI advancements across various domains, \\nvisual, speech, audio, and text -based applications, has \\nsignificantly elevated concerns surrounding personal\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='privacy breaches and impersonation. A pertinent example is the music industry, where AI -drive n ghostwriters have \\nreleased a fake audio tracks emulating the voices of \\nrenowned artists like Drake and The Weeknd, both of \\nwhom are global music sensations [174] . Tracks like \"Heart \\non My Sleeve\" and \"Cuff It\" featuring AI -rendered versions \\nof Rihanna and Beyoncé\\'s voices [175] , have garnered \\nattention for their remarkably convincing mimicry.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='Consequently, the creative industry faces substantial threats, particularly sectors reliant on advanced artificial \\nintelligence. As reported, these technologies can potentially \\njeopardize careers within the entertainment industry.  \\n \\n \\nVI. CONCLUSION  \\nIn conclusion, Generative AI opens the door to a world filled \\nwith both unprecedented opportunities and inherent risks. \\nFurther in -depth research is necessary to comprehend its', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content=\"multifaceted impacts across various sectors better and develop effective mitiga tion strategies. Striking a balance \\nbetween the potential benefits and threats posed by \\nGenerative AI is essential to serve humanity's needs best. \\nThroughout this paper, we have delved into state -of-the-art \\nmodels, explored their mathematical foundations, scrutinized their architectural intricacies, and anticipated their evolution in the future. We have also examined\", metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='prominent tasks, benchmarked state -of-the-art tools against \\nGenerative AI, and assessed their real -world applications. \\nThe realms of impact, c hallenges, and future prospects of \\nGenerative AI have been thoroughly addressed.  \\n       The journey to harness the full potential of Generative \\nAI is ongoing, requiring swift and thoughtful actions from \\nregulatory authorities to ensure order and alignment with the \\nrapid advancements in AI technology sweeping the world.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='The role of Explainabil ity AI, Responsive AI, and Privacy -\\nPreserving AI becomes increasingly crucial in this context. \\nThe future is bright, but as we move forward, maintaining a \\ndelicate equilibrium between the opportunities and risks', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 16}),\n",
       " Document(page_content='presented by Generative AI is paramount to realizing its full \\nutility and ensuring it serves humanity effectively.  \\n \\n \\nREFERENCES  \\n[1] J. McCarthy, M. L. Minsky, N. Rochester, I. B. M. \\nCorporation, and C. E. Shannon, “A PROPOSAL FOR THE DARTMOUTH SUMMER RESEARCH \\nPROJECT ON ARTIFICIAL INTELLIGENCE”.  \\n[2] C. Zhang and Y. Lu, “Study on artificial intelligence: \\nThe state of the art and future prospects,” J. Ind. Inf. \\nIntegr. , vol. 23, p. 100224, Sep. 2021, doi:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='10.1016/j.jii.2021.100224.  \\n[3] N. J. Nilsson, The Quest for Artificial Intelligence . \\nCambridge University Press, 2009.  \\n[4] P. Hamet and J. Tremblay, “Artificial intelligence in medicine,” Metabolism , vol. 69, pp. S36– S40, Apr. \\n2017, doi: 10.1016/j.metabol.2017.01.011.  \\n[5] R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, Machine Learning: An Artificial Intelligence Approach. \\nSpringer Science & Business Media, 2013.  \\n[6] D. L. Du Yi, Artificial Intelligence with Uncertainty ,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='2nd ed. Boca Raton: CRC Press, 2016. doi: 10.1201/9781315366951.  \\n[7] F. Rosenblatt, “The perceptron: A probabilistic model \\nfor information storage and organization in the brain,” \\nPsychol. Rev. , vol. 65, no. 6, pp. 386– 408, 1958, doi: \\n10.1037/h0042519.  \\n[8] J. N. Morgan and J. A. Sonquist, “Problems in the Analysis of Survey Data, and a Proposal,” J. Am. Stat. \\nAssoc. , vol. 58, no. 302, pp. 415– 434, Jun. 1963, doi: \\n10.1080/01621459.1963.10500855.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='[9] E. Fix and J. L. Hodges, “Discriminatory Analysis. \\nNonparametric Discrimination: Consistency \\nProperties,” Int. Stat. Rev. Rev. Int. Stat. , vol. 57, no. 3, \\npp. 238– 247, 1989, doi: 10.2307/1403797.  \\n[10] J. Platt, “Sequential Minimal Optimization: A Fast \\nAlgorithm for Training Support Vector Machines,” Apr. \\n1998, Accessed: Sep. 30, 2023. [Online]. Available: https://www.microsoft.com/en -\\nus/research/publication/sequential -minimal-', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='optimization -a-fast-algorithm -for-training -support -\\nvector -machines/  \\n[11] L. Breiman, “Random Forests,” Mach. Learn. , vol. 45, \\nno. 1, pp. 5– 32, Oct. 2001, doi: \\n10.1023/A:1010933404324.  \\n[12] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, \\n“Gradient -based learning applied to document \\nrecognition,” Proc. IEEE , vol. 86, no. 11, pp. 2278–\\n2324, Nov. 1998, doi: 10.1109/5.726791.  \\n[13] J. J. Hopfield and D. W. Tank, “‘Neural’ computation', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='of decisions in optimization problems,” Biol. Cybern. , \\nvol. 52, no. 3, pp. 141 –152, Jul. 1985, doi: \\n10.1007/BF00339943.  \\n[14] S. Hochreiter and J. Schmidhuber, “Long Short -Term \\nMemory,” Neural Comput. , vol. 9, no. 8, pp. 1735–\\n1780, Nov. 1997, doi: 10.1162/neco.1997.9.8.1735.  [15] M. Schuster and K. K. Paliwal, “Bidirectional recurrent \\nneural networks,” IEEE Trans. Signal Process. , vol. 45, \\nno. 11, pp. 2673– 2681, Nov. 1997, doi: \\n10.1109/78.650093.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='[16] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” \\nNature , vol. 521, no. 7553, Art. no. 7553, May 2015, \\ndoi: 10.1038/nature14539.  \\n[17] O. Russakovsky et al. , “ImageNet Large Scale Visual \\nRecognition Challenge,” Int. J. Comput. Vis. , vol. 115, \\nno. 3, pp. 211 –252, Dec. 2015, doi: 10.1007/s11263-\\n015-0816- y. \\n[18] S. Cong and Y. Zhou, “A review of convolutional neural \\nnetwork architectures and their optimizations,” Artif.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='Intell. Rev. , vol. 56, no. 3, pp. 1905– 1969, Mar. 2023, \\ndoi: 10.1007/s10462- 022-10213- 5. \\n[19] A. Krizhevsky, I. Sutskever, and G. E. Hinton, \\n“ImageNet Classification with Deep Convolutional Neural Networks,” in Advances in Neural Information \\nProcessing Systems , Curran Associates, Inc., 2012. \\nAccessed: Sep. 30, 2023. [Online]. Available: \\nhttps://proceedings.neurips.cc/paper/2012/hash/c39986\\n2d3b9d6b76c8436e924a68c45b- Abstract.html', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='[20] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual \\nLearning for Image Recognition,” presented at the \\nProceedings of the IEEE Conference on Computer \\nVision and Pattern Recognition, 2016, pp. 770 –778. \\nAccessed: Sep. 30, 2023. [Online]. Available: \\nhttps ://openaccess.thecvf.com/content_cvpr_2016/html\\n/He_Deep_Residual_Learning_CVPR_2016_paper.ht\\nml \\n[21] G. Huang, Z. Liu, L. van der Maaten, and K. Q. \\nWeinberger, “Densely Connected Convolutional', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='Networks,” presented at the Proceedings of the IEEE \\nConference on Computer Vision and Pattern \\nRecognition, 2017, pp. 4700– 4708. Accessed: Sep. 30, \\n2023. [Onlin e]. Available: \\nhttps://openaccess.thecvf.com/content_cvpr_2017/html\\n/Huang_Densely_Connected_Convolutional_CVPR_2\\n017_paper.html  \\n[22] A. G. Howard et al. , “MobileNets: Efficient \\nConvolutional Neural Networks for Mobile Vision \\nApplications,” arXiv.org. Accessed: Sep. 30, 2023. \\n[Online]. Available:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='https://arxiv.org/abs/1704.04861v1  \\n[23] M. Tan and Q. Le, “EfficientNet: Rethinking Model \\nScaling for Convolutional Neural Networks,” in \\nProceedings of the 36th International Conference on \\nMachine Learning, PMLR, May 2019, pp. 6105– 6114. \\nAccessed: Sep. 30, 2023. [Online]. Available: https://proceedings.mlr.press/v97/tan19a.html  \\n[24] A. Vaswani et al. , “Attention is All you Need,” in \\nAdvances in Neural Information Processing Systems ,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='Curran Associates, Inc., 2017. Accessed: Aug. 15, 2023. \\n[Online]. Available: \\nhttps://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa -\\nAbstract.html', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 17}),\n",
       " Document(page_content='[25] I. J. Goodfellow et al. , “Generative Adversarial \\nNetworks.” arXiv, Jun. 10, 2014. doi: \\n10.48550/arXiv.1406.2661.  \\n[26] C. Zheng, G. Wu, F. Bao, Y. Cao, C. Li, and J. Zhu, “Revisiting Discriminative vs. Generative Classifiers: Theory and Implications.” arXiv, May 29, 2023. doi: \\n10.48550/arXiv.2302.02334.  \\n[27] E. Brophy, Z. Wang, Q. She, and T. Ward, “Generative \\nAdversarial Networks in Time Series: A Systematic \\nLiterature Review,” ACM Comput. Surv. , vol. 55, no.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='10, p. 199:1- 199:31, Feb. 2023, doi: 10.1145/3559540.  \\n[28] G. Zhou et al. , “Emerging Synergies in Causality and \\nDeep Generative Models: A Survey.” arXiv, Sep. 14, 2023. doi: 10.48550/arXiv.2301.12351.  \\n[29] N. R. Mannuru et al. , “Artificial intelligence in \\ndeveloping countries: The impact of generative artificial \\nintelligence (AI) technologies for development,” Inf. Dev., p. 02666669231200628, Sep. 2023, doi: \\n10.1177/02666669231200628.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='[30] “Introducing ChatGPT.” Accessed: Sep. 30, 2023. \\n[Online]. Available: https://openai.com/blog/chatgpt  \\n[31] C. Leiter et al. , “ChatGPT: A Meta- Analysis after 2.5 \\nMonths.” arXiv, Feb. 20, 2023. doi: \\n10.48550/arXiv.2302.13795.  \\n[32] D. Bank, N. Koenigstein, and R. Giryes, \\n“Autoencoders.” arXiv, Apr. 03, 2021. doi: \\n10.48550/arXiv.2003.05991.  \\n[33] U. Michelucci, “An Introduction to Autoencoders.” \\narXiv, Jan. 11, 2022. doi: 10.48550/arXiv.2201.03898.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='[34] J. Zhai, S. Zhang, J. Chen, and Q. He, “Autoencoder and Its Various Variants,” in 2018 IEEE International \\nConference on Systems, Man, and Cybernetics (SMC) , \\nOct. 2018, pp. 415– 419. doi: \\n10.1109/SMC.2018.00080.  \\n[35] D. P. Kingma, S. Mohamed, D. Jimenez Rezende, and \\nM. Welling, “Semi -supervised Learning with Deep \\nGenerative Models,” in Advances in Neural Information \\nProcessing Systems , Curran Associates, Inc., 2014.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='Accessed: Aug. 07, 2023. [Online]. Available: https://proceedings.neurips.cc/paper/2014/hash/d52377\\n3c6b194f37b938d340d5d02232- Abstract.html  \\n[36] D. P. Kingma and M. Welling, “An Introduction to \\nVariational Autoencoders,” Found. Trends® Mach. \\nLearn. , vol. 12, no. 4, pp. 307– 392, 2019, doi: \\n10.1561/2200000056.  \\n[37] H. Akrami, A. A. Joshi, J. Li, S. Aydore, and R. M. \\nLeahy, “Brain Lesion Detection Using A Robust \\nVariational Autoencoder and Transfer Learning,” in', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='2020 IEEE 17th International Symposium on \\nBiomedical Imaging (ISBI) , Apr. 2020, pp. 786– 790. \\ndoi: 10.1109/ISBI45749.2020.9098405.  \\n[38] X. Shen, B. Liu, Y. Zhou, J. Zhao, and M. Liu, “Remote \\nsensing image captioning via Variational Autoencoder \\nand Reinforcement Learning,” Knowl. -Based Syst. , vol. \\n203, p. 105920, Sep. 2020, doi: 10.1016/j.knosys.2020.105920.  [39] G. Zhao and Y. Peng, “Semisupervised SAR image \\nchange detection based on a siamese variational', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='autoencoder,” Inf. Process. Manag. , vol. 59, no. 1, p. \\n102726, Jan. 2022, doi: 10.1016/j.ipm.2021.102726.  \\n[40] H. W. L. Mak, R. Han, and H. H. F. Yin, “Application of Variational AutoEncoder (VAE) Model and Image \\nProcessing Approaches in Game Design,” Sensors , vol. \\n23, no. 7, Art. no. 7, Jan. 2023, doi: 10.3390/s23073457.  \\n[41] M. A. Yílmaz, O. Kelesş, H. Güven, A. M. Tekalp, J. \\nMalik, and S. Kíranyaz, “Self -Organized Variational \\nAutoencoders (Self -Vae) For Learned Image', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='Compression,” in 2021 IEEE International Conference \\non Image Processing (ICIP) , Sep. 2021, pp. 3732– 3736. \\ndoi: 10.1109/ICIP42928.2021.9506041.  \\n[42] Z.-S. Liu, W.- C. Siu, and L. -W. Wang, “Variational \\nAutoEncoder for Reference based Image Super -\\nResolution,” in 2021 IEEE/CVF Conference on \\nComputer Vision and Pattern Recognition Workshops \\n(CVPRW), Nashville, TN, USA: IEEE, Jun. 2021, pp. \\n516– 525. doi: 10.1109/CVPRW53098.2021.00063.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='[43] G. Carbajal, J. Richter, and T. Gerkmann, “Guided \\nVariational Autoencoder for Speech Enhancement with \\na Supervised Classifier,” in ICASSP 2021 - 2021 IEEE \\nInternational Conference on Acoustics, Speech and Signal Processing (ICASSP) , Jun. 2021, pp. 681– 685. \\ndoi: 10.1109/ICASSP39728.2021.9414363.  \\n[44] T. Srikotr and K. Mano, “Sub- band Vector Quantized \\nVariational AutoEncoder for Spectral Envelope \\nQuantization,” in TENCON 2019 - 2019 IEEE Region', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='10 Conference (TENCON) , Oct. 2019, pp. 296– 300. \\ndoi: 10.1109/TENCON.2019.8929436.  \\n[45] Z. Wang, “Using Gaussian Process in Clockwork \\nVariational Autoencoder for Video Prediction,” in 2022 International Conference on Information Technology \\nResearch and Innovation (ICITRI) , Nov. 2022, pp. 6–\\n11. doi: 10.1109/ICITRI56423.2022.9970241.  \\n[46] M. S. Kim, J. P. Yun, S. Lee, and P. Park, “Unsupervised Anomaly detection of LM Guide Using \\nVariational Autoencoder,” in 2019 11th International', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='Symposium on Advanced Topics in Electrical \\nEngineering (ATEE), Mar. 2019, pp. 1– 5. doi: \\n10.1109/ATEE.2019.8724998.  \\n[47] C. K. Meher, R. Nayak, and U. C. Pati, “Dual Stream \\nVariational Autoencoder for Video Anomaly Detection \\nin Single Scene Videos,” in 2022 2nd Odisha International Conference on Electrical Power \\nEngineering, Communication and Computing \\nTechnology (ODICON) , Nov. 2022, pp. 1– 6. doi: \\n10.1109/ODICON54453.2022.10010086.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='[48] H. Yanagihashi and T. Sudo, “Noise -robust Early \\nDetection of Cooling Fan Deterioration with a \\nVariational Autoencoder -based Method,” in 2022 9th \\nInternational Conference on Condition Monitoring and Diagnosis (CMD) , Nov. 2022, pp. 183– 188. doi: \\n10.23919/CMD54214.2022.9991542.  \\n[49] H. Purohit, T. Endo, M. Yamamoto, and Y. Kawaguchi, \\n“Hierarchical Conditional Variational Autoencoder', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 18}),\n",
       " Document(page_content='Based Acoustic Anomaly Detection,” in 2022 30th \\nEuropean Signal Processing Conference (EUSIPCO) , \\nAug. 2022, pp. 274 –278. doi: \\n10.23919/EUSIPCO55093.2022.9909785.  \\n[50] B. Shen, L. Yao, and Z. Ge, “Nonlinear probabilistic \\nlatent variable regression models for soft sensor \\napplication: From shallow to deep structure,” Control \\nEng. Pract. , vol. 94, p. 104198, Jan. 2020, doi: \\n10.1016/j.conengprac.2019.104198.  \\n[51] B. Shen and Z. Ge, “Supervised Nonlinear Dynamic', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='System for Soft Sensor Application Aided by Variational Auto -Encoder,” IEEE Trans. Instrum. \\nMeas. , vol. 69, no. 9, pp. 6132– 6142, Sep. 2020, doi: \\n10.1109/TIM.2020.2968162.  \\n[52] W. Xie, J. Wang, C. Xing, S. Guo, M. Guo, and L. Zhu, “Variational Autoencoder Bidirectional Long and \\nShort -Term Memory Neural Network Soft -Sensor \\nModel Based on Batch Training Strategy,” IEEE Trans. \\nInd. Inform. , vol. 17, no. 8, pp. 5325 –5334, Aug. 2021, \\ndoi: 10.1109/TII.2020.3025204.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='[53] R. Xie, N. M. Jan, K. Hao, L. Chen, and B. Huang, \\n“Supervised Variational Autoencoders for Soft Sensor \\nModeling With Missing Data,” IEEE Trans. Ind. \\nInform. , vol. 16, no. 4, pp. 2820– 2828, Apr. 2020, doi: \\n10.1109/TII.2019.2951622.  \\n[54] F. Guo, R. Xie, and B. Huang, “A deep learning just -in-\\ntime modeling approach for soft sensor based on \\nvariational autoencoder,” Chemom. Intell. Lab. Syst. , \\nvol. 197, p. 103922, Feb. 2020, doi: \\n10.1016/j.chemolab.2019.103922.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='[55] L. Li, J. Yan, H. Wang, and Y. Jin, “Anomaly Detection \\nof Time Series With Smoothness -Inducing Sequential \\nVariational Auto -Encoder,” IEEE Trans. Neural Netw. \\nLearn. Syst. , vol. 32, no. 3, pp. 1177 –1191, Mar. 2021, \\ndoi: 10.1109/TNNLS.2020.2980749.  \\n[56] N. T. N. Anh, T. Q. Khanh, N. Q. Dat, E. Amouroux, and V. K. Solanki, “Fraud detection via deep neural variational autoencoder oblique random forest,” in 2020 \\nIEEE -HYDCON , Sep. 2020, pp. 1– 6. doi:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='10.1109/HYDCON48903.2020.9242753.  \\n[57] C. Zhang et al. , “A Complete Survey on Generative AI \\n(AIGC): Is ChatGPT from GPT -4 to GPT -5 All You \\nNeed?” arXiv, Mar. 21, 2023. doi: \\n10.48550/arXiv.2303.11717.  \\n[58] K. Han et al. , “A Survey on Vision Transformer,” IEEE \\nTrans. Pattern Anal. Mach. Intell. , vol. 45, no. 1, pp. \\n87–110, Jan. 2023, doi: \\n10.1109/TPAMI.2022.3152247.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='[59] S. Khan, M. Naseer, M. Hayat, S. W. Zamir, F. S. Khan, and M. Shah, “Transformers in Vision: A Survey,” ACM Comput. Surv. , vol. 54, no. 10s, p. 200:1- 200:41, \\nSep. 2022, doi: 10.1145/3505244.  \\n[60] T. Lin, Y. Wang, X. Liu, and X. Qiu, “A survey of transformers,” AI Open , vol. 3, pp. 111– 132, Jan. 2022, \\ndoi: 10.1016/j.aiopen.2022.10.001.  [61] M. Zong and B. Krishnamachari, “a survey on GPT -3.”', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='arXiv, Dec. 01, 2022. Accessed: Aug. 15, 2023. [Online]. Available: http://arxiv.org/abs/2212.00857  \\n[62] B. Ghojogh and A. Ghodsi, “Attention Mechanism, Transformers, BERT, and GPT: Tutorial and Survey,” Open Science Framework, preprint, Dec. 2020. doi: \\n10.31219/osf.io/m6gcn.  \\n[63] C. Zhang et al. , “A Complete Survey on Generative AI \\n(AIGC): Is ChatGPT from GPT -4 to GPT -5 All You \\nNeed?” arXiv, Mar. 21, 2023. doi: \\n10.48550/arXiv.2303.11717.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='[64] “Generative AI: a game- changer society needs to be \\nready for,” World Economic Forum. Accessed: Aug. \\n16, 2023. [Online]. Available: \\nhttps://www.weforum.org/agenda/2023/01/davos23 -\\ngenerative- ai-a-game- changer -industries -and-society -\\ncode -developers/  \\n[65] A. Radford, K. Narasimhan, T. Salimans, and I. \\nSutskever, “Improving Language Understanding by \\nGenerative Pre- Training”.  \\n[66] I. Solaiman et al. , “Release Strategies and the Social \\nImpacts of Language Models”.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='[67] T. Brown et al. , “Language Models are Few -Shot \\nLearners,” Adv. Neural Inf. Process. Syst. , vol. 33, pp. \\n1877 –1901, 2020.  \\n[68] X. Zheng, C. Zhang, and P. C. Woodland, “Adapting \\nGPT, GPT -2 and BERT Language Models for Speech \\nRecognition,” in 2021 IEEE Automatic Speech \\nRecognition and Understanding Workshop (ASRU) , \\nDec. 2021, pp. 162– 168. doi: \\n10.1109/ASRU51503.2021.9688232.  \\n[69] A. Shrivastava, R. Pupale, and P. Singh, “Enhancing', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='Aggression Detection using GPT -2 based Data \\nBalancing Technique,” in 2021 5th International \\nConference on Intelligent Computing and Control \\nSystems (ICICCS) , May 2021, pp. 1345 –1350. doi: \\n10.1109/ICICCS51141.2021.9432283.  \\n[70] M. Tamimi, M. Salehi, and S. Najari, “Deceptive review \\ndetection using GAN enhanced by GPT structure and \\nscore of reviews,” in 2023 28th International Computer \\nConference, Computer Society of Iran (CSICC) , Jan. \\n2023, pp. 1– 7. doi:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='10.1109/CSICC58665.2023.10105368.  \\n[71] S. Saravanan and K. Sudha, “GPT -3 Powered System \\nfor Content Generation and Transformation,” in 2022 \\nFifth International Conference on Computational Intelligence and Communication Technologies \\n(CCICT) , Jul. 2022, pp. 514– 519. doi: \\n10.1109/CCiCT56684.2022.00096.  \\n[72] K. H. Manodnya and A. Giri, “GPT -K: A GPT -based \\nmodel for generation of text in Kannada,” in 2022 IEEE \\n4th International Conference on Cybernetics, Cognition', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='and Machine Learning Applications (ICCCMLA) , Oct. \\n2022, pp. 534 –539. doi: \\n10.1109/ICCCMLA56841.2022.9989289.  \\n[73] P. Isaranontakul and W. Kreesuradej, “A Study of \\nUsing GPT -3 to Generate a Thai Sentiment Analysis of', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 19}),\n",
       " Document(page_content='COVID- 19 Tweets Dataset,” in 2023 20th International \\nJoint Conference on Computer Science and Software \\nEngineering (JCSSE) , Jun. 2023, pp. 106– 111. doi: \\n10.1109/JCSSE58229.2023.10201994.  \\n[74] N. Aydın and O. A. Erdem, “A Research On The New Generation Artificial Intelligence Technology \\nGenerative Pretraining Transformer 3,” in 2022 3rd \\nInternational Informatics and Software Engineering \\nConference (IISEC) , Dec. 2022, pp. 1– 6. doi: \\n10.1109/IISEC56263.2022.9998298.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='[75] M. Lajkó, V. Csuvik, and L. Vidács, “Towards JavaScript program repair with Generative Pre- trained \\nTransformer (GPT -2),” in 2022 IEEE/ACM \\nInternational Workshop on Automated Program Repair (APR), May 2022, pp. 61– 68. doi: \\n10.1145/3524459.3527350.  \\n[76] Y. Su, “Computer -generated Humour Based on GPT -\\n2,” in 2022 IEEE 2nd International Conference on Data \\nScience and Computer Application (ICDSCA) , Oct. \\n2022, pp. 890 –893. doi: \\n10.1109/ICDSCA56264.2022.9987901.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='[77] N. Darapaneni, R. Prajeesh, P. Dutta, V. K. Pillai, A. \\nKarak, and A. R. Paduri, “Abstractive Text \\nSummarization Using BERT and GPT -2 Models,” in \\n2023 International Conference on Signal Processing, \\nComputation, Electronics, Power and \\nTelecommunication (IConSCEPT) , May 2023, pp. 1– 6. \\ndoi: 10.1109/IConSCEPT57958.2023.10170093.  \\n[78] Y. Liang and Z. Han, “Intelligent Love Letter Generator \\nBased on GPT -2 Model,” in 2022 3rd International \\nConference on Electronic Communication and', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='Artificial Intelligence (IWECAI) , Jan. 2022, pp. 562 –\\n567. doi: 10.1109/IWECAI55315.2022.00115.  \\n[79] D. H. Nguyen, H. L. Pham, and L. Le Thi Trang, “Security of the Cryptosystem GPT Based on Rank \\nCodes and Term -rank Codes,” in 2021 International \\nConference Engineering and Telecommunication \\n(En&T), Nov. 2021, pp. 1 –5. doi: \\n10.1109/EnT50460.2021.9681778.  \\n[80] M. Nam, S. Park, and D. S. Kim, “Intrusion Detection \\nMethod Using Bi -Directional GPT for in -Vehicle', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='Controller Area Networks,” IEEE Access , vol. 9, pp. \\n124931– 124944, 2021, doi: \\n10.1109/ACCESS.2021.3110524.  \\n[81] D. Demırcı, N. şahın, M. şirlancis, and C. Acarturk, \\n“Static Malware Detection Using Stacked BiLSTM and \\nGPT -2,” IEEE Access , vol. 10, pp. 58488 –58502, 2022, \\ndoi: 10.1109/ACCESS.2022.3179384.  \\n[82] H. Khan, M. Alam, S. Al -Kuwari, and Y. Faheem, \\n“OFFENSIVE AI: UNIFICATION OF EMAIL \\nGENERATION THROUGH GPT -2 MODEL WITH A \\nGAME -THEORETIC APPROACH FOR SPEAR -', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='PHISHING ATTACKS,” in Competitive Advantage in the Digital Economy (CADE 2021) , Jun. 2021, pp. 178–\\n184. doi: 10.1049/icp.2021.2422.  \\n[83] H. Liu, Y. Cai, Z. Lin, Z. Ou, Y. Huang, and J. Feng, “Variational Latent -State GPT for Semi -Supervised Task -Oriented Dialog Systems,” IEEEACM Trans. \\nAudio Speech Lang. Process. , vol. 31, pp. 970– 984, \\n2023, doi: 10.1109/TASLP.2023.3240661.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='[84] S. W. Jeong, C. G. Kim, and T. K. Whangbo, “Question Answering System for Healthcare Information based on BERT and GPT,” in 2023 Joint International \\nConference on Digital Arts, Media and Technology with \\nECTI Northern Section Conference on Electrical, \\nElectronics, Computer and Telecommunications \\nEngineering (ECTI DAMT & NCON) , Mar. 2023, pp. \\n348–\\n352. doi: \\n10.1109/ECTIDAMTNCON57770.2023.10139365.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='[85] Y. Zhang, Z. Li, and J. Zhang, “Towards the Use of Pretrained Language Model GPT -2 for Testing the \\nHypothesis of Communicative Efficiency in the Lexicon,” in 2021 International Conference on Asian \\nLanguage Processing (IALP) , Dec. 2021, pp. 62– 66. \\ndoi: 10.1109/IALP54817.2021.9675217.  \\n[86] R. Kinoshita and S. Shiramatsu, “Agent for Recommending Information Relevant to Web- based \\nDiscussion by Generating Query Terms using GPT -3,” \\nin 2022 IEEE International Conference on Agents', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='(ICA), Nov. 2022, pp. 24 –29. doi: \\n10.1109/ICA55837.2022.00011.  \\n[87] C. Treude, “Navigating Complexity in Software Engineering: A Prototype for Comparing GPT -n \\nSolutions,” in 2023 IEEE/ACM 5th International \\nWorkshop on Bots in Software Engineering (BotSE) , \\nMay 2023, pp. 1– 5. doi: \\n10.1109/BotSE59190.2023.00008.  \\n[88] J. J. Bird, M. Pritchard, A. Fratini, A. Ekárt, and D. R. \\nFaria, “Synthetic Biological Signals Machine -\\nGenerated by GPT -2 Improve the Classification of EEG', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='and EMG Through Data Augmentation,” IEEE Robot. \\nAutom. Lett. , vol. 6, no. 2, pp. 3498 –3504, Apr. 2021, \\ndoi: 10.1109/LRA.2021.3056355.  \\n[89] P. Maddigan and T. Susnjak, “Chat2VIS: Generating \\nData Visualizations via Natural Language Using \\nChatGPT, Codex and GPT -3 Large Language Models,” \\nIEEE Access , vol. 11, pp. 45181 –45193, 2023, doi: \\n10.1109/ACCESS.2023.3274199.  \\n[90] OpenAI, “GPT -4 Technical Report.” arXiv, Mar. 27, \\n2023. doi: 10.48550/arXiv.2303.08774.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='[91] H. Nori, N. King, S. M. McKinney, D. Carignan, and E. \\nHorvitz, “Capabilities of GPT -4 on Medical Challenge \\nProblems.” arXiv, Apr. 12, 2023. doi: \\n10.48550/arXiv.2303.13375.  \\n[92] D. M. Katz, M. J. Bommarito, S. Gao, and P. \\nArredondo, “GPT -4 Passes the Bar Exam.” Rochester, \\nNY, Mar. 15, 2023. doi: 10.2139/ssrn.4389233.  \\n[93] D. Hendrycks et al. , “Measuring Massive Multitask \\nLanguage Understanding,” arXiv.org. Accessed: Aug. \\n22, 2023. [Online]. Available:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='https://arxiv.org/abs/2009.03300v3  \\n[94] A. Creswell, T. White, V. Dumoulin, K. Arulkumaran, \\nB. Sengupta, and A. A. Bharath, “Generative Adversarial Networks: An Overview,” IEEE Signal', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 20}),\n",
       " Document(page_content='Process. Mag. , vol. 35, no. 1, pp. 53– 65, Jan. 2018, doi: \\n10.1109/MSP.2017.2765202.  \\n[95] A. Aggarwal, M. Mittal, and G. Battineni, “Generative \\nadversarial network: An overview of theory and \\napplications,” Int. J. Inf. Manag. Data Insights , vol. 1, \\nno. 1, p. 100004, Apr. 2021, doi: \\n10.1016/j.jjimei.2020.100004.  \\n[96] Z. Zhang, M. Li, and J. Yu, “On the convergence and \\nmode collapse of GAN,” in SIGGRAPH Asia 2018 \\nTechnical Briefs , in SA ’18. New York, NY, USA:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='Association for Computing Machinery, Dec. 2018, pp. \\n1–4. doi: 10.1145/3283254.3283282.  \\n[97] Bhagyashree, V. Kushwaha, and G. C. Nandi, “Study of \\nPrevention of Mode Collapse in Generative Adversarial \\nNetwork (GAN),” in 2020 IEEE 4th Conference on Information & Communication Technology (CICT) , \\nDec. 2020, pp. 1– 6. doi: \\n10.1109/CICT51604.2020.9312049.  \\n[98] H. Thanh- Tung and T. Tran, “Catastrophic forgetting \\nand mode collapse in GANs,” in 2020 International', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='Joint Conference on Neural Networks (IJCNN) , Jul. \\n2020, pp. 1– 10. doi: \\n10.1109/IJCNN48605.2020.9207181.  \\n[99] W. Li, L. Fan, Z. Wang, C. Ma, and X. Cui, “Tackling mode collapse in multi -generator GANs with \\northogonal vectors,” Pattern Recognit. , vol. 110, p. \\n107646, Feb. 2021, doi: 10.1016/j.patcog.2020.107646.  \\n[100]  D. Saxena and J. Cao, “Generative Adversarial \\nNetworks (GANs): Challenges, Solutions, and Future \\nDirections”.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='Directions”.  \\n[101]  H. Chen, “Challenges and Corresponding Solutions \\nof Generative Adversarial Networks (GANs): A Survey \\nStudy,” J. Phys. Conf. Ser. , vol. 1827, no. 1, p. 012066, \\nMar. 2021, doi: 10.1088/1742 -6596/1827/1/012066.  \\n[102]  M. Mirza and S. Osindero, “Conditional Generative \\nAdversarial Nets,” arXiv.org. Accessed: Aug. 26, 2023. \\n[Online]. Available: https://arxiv.org/abs/1411.1784v1  \\n[103]  G. G. Chrysos, J. Kossaifi, and S. Zafeiriou,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='“Robust Conditional Generative Adversarial Networks.” arXiv, Mar. 13, 2019. doi: \\n10.48550/arXiv.1805.08657.  \\n[104]  A. Radford, L. Metz, and S. Chintala, \\n“Unsupervised Representation Learning with Deep \\nConvolutional Generative Adversarial Networks.” arXiv, Jan. 07, 2016. Accessed: Aug. 26, 2023. \\n[Online]. Available: http://arxiv.org/abs/1511.06434  \\n[105]  M. Arjovsky, S. Chintala, and L. Bottou, \\n“Wasserstein GAN.” arXiv, Dec. 06, 2017. Accessed: Aug. 27, 2023. [Online]. Available:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='http://arxiv.org/abs/1701.07875 \\n[106]  T. C. Koopmans, “Optimum Utilization of the \\nTransportation System,” Econometrica , vol. 17, pp. \\n136– 146, 1949, doi: 10.2307/1907301.  \\n[107]  E. Massart, “Improving weight clipping in \\nWasserstein GANs,” in 2022 26th International Conference on Pattern Recognition (ICPR) , Montreal, QC, Canada: IEEE, Aug. 2022, pp. 2286– 2292. doi: \\n10.1109/ICPR56361.2022.9956056.  \\n[108]  J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='“Unpaired Image -To-Image Translation Using Cycle -\\nConsistent Adversarial Networks,” presented at the Proceedings of the IEEE International Conference on \\nComputer Vision, 2017, pp. 2223– 2232. Accessed: \\nAug. 27, 2023. [Online]. Available: \\nhttps://openaccess.thecvf.com/content_iccv_2017/html\\n/Zhu_Unpaired_Image -To-\\nImage_Translation_ICCV_2017_paper.html  \\n[109]  Y. Choi, M. Choi, M. Kim, J.- W. Ha, S. Kim, and', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='J. Choo, “StarGAN: Unified Generative Adversarial Networks for Multi -Domain Image -to-Image \\nTranslation,” presented at the Proceedings of the IEEE Conference on Computer Vision and Pattern \\nRecognition, 2018, pp. 8789 –8797. Accessed: Aug. 27, \\n2023. [Online]. Available: \\nhttps://openaccess.thecvf.com/content_cvpr_2018/html/Choi_StarGAN_Unified_Generative_CVPR_2018_pa\\nper.html  \\n[110]  T. Karras, T. Aila, S. Laine, and J. Lehtinen, \\n“Progressive Growing of GANs for Improved Quality,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='Stability, and Variation.” arXiv, Feb. 26, 2018. doi: \\n10.48550/arXiv.1710.10196.  \\n[111]  A. Brock, J. Donahue, and K. Simonyan, “Large \\nScale GAN Training for High Fidelity Natural Image Synthesis.” arXiv, Feb. 25, 2019. doi: 10.48550/arXiv.1809.11096.  \\n[112]  T. Karras, S. Laine, and T. Aila, “A Style- Based \\nGenerator Architecture for Generative Adversarial \\nNetworks,” presented at the Proceedings of the', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 4401 –4410. Accessed: Aug. 29, \\n2023. [Online]. Available: \\nhttps://openaccess.thecvf.com/content_CVPR_2019/html/Karras_A_Style -\\nBased_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.html  \\n[113]  T. Karras, S. Laine, M. Aittala, J. Hellsten, J. \\nLehtinen, and T. Aila, “Analyzing and Improving the Image Quality of StyleGAN,” presented at the \\nProceedings of the IEEE/CVF Conference on Computer', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='Vision and Pattern Recognition, 2020, pp. 8110– 8119. \\nAccessed: Aug. 29, 2023. [Online]. Available: \\nhttps://openaccess.thecvf.com/content_CVPR_2020/ht\\nml/Karras_Analyzing_and_Improving_the_Image_Qu\\nality_of_StyleGAN_CVPR_2020_paper.html  \\n[114]  X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. \\nSutskever, and P. Abbeel, “InfoGAN: Interpretable Representation Learning by Information Maximizing \\nGenerative Adversarial Nets,” in Advances in Neural', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='Information Processing Systems , Curran Associates, \\nInc., 2016. Accessed: Aug. 29, 2023. [Online]. \\nAvailable: \\nhttps://proceedings.neurips.cc/paper_files/paper/2016/', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 21}),\n",
       " Document(page_content='hash/7c9d0b1f96aebd7b5eca8c3edaa19ebb-\\nAbstract.html \\n[115]  T. Salimans et al. , “Improved Techniques for \\nTraining GANs,” in Advances in Neural Information \\nProcessing Systems , Curran Associates, Inc., 2016. \\nAccessed: Aug. 29, 2023. [Online]. Available: \\nhttps://proceedings.neurips.cc/paper_files/paper/2016/\\nhash/8a3363abe792db2d8761d6403605aeb7 -\\nAbstract.html \\n[116]  J. Donahue, P. Krähenbühl, and T. Darrell, \\n“Adversarial Feature Learning.” arXiv, Apr. 03, 2017.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='doi: 10.48550/arXiv.1605.09782.  \\n[117]  A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. \\nChen, “Hierarchical Text -Conditional Image \\nGeneration with CLIP Latents,” arXiv.org. Accessed: Oct. 06, 2023. [Online]. Available: \\nhttps://arxiv.org/abs/2204.06125v1  \\n[118]  J. Ho et al. , “IMAGEN VIDEO: HIGH \\nDEFINITION VIDEO GENERATION WITH \\nDIFFUSION MODELS”.  \\n[119]  U. Singer et al. , “Make- A-Video: Text -to-Video \\nGeneration without Text -Video Data.” arXiv, Sep. 29,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='2022. doi: 10.48550/arXiv.2209.14792.  \\n[120]  Y. Li et al. , “Competition -level code generation \\nwith AlphaCode,” Science, vol. 378, no. 6624, pp. \\n1092 –1097, Dec. 2022, doi: 10.1126/science.abq1158.  \\n[121]  “StarCoder: A State -of-the-Art LLM for Code.” \\nAccessed: Oct. 06, 2023. [Online]. Available: https://huggingface.co/blog/starcoder  \\n[122]  M. Chen et al. , “Evaluating Large Language \\nModels Trained on Code.” arXiv, Jul. 14, 2021. doi: 10.48550/arXiv.2107.03374.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='[123]  “A systematic review of artificial intelligence -\\nbased music generation: Scope, applications, and future trends - ScienceDirect.” Accessed: Oct. 07, 2023. \\n[Online]. Available: https://www.sciencedirect.com/science/article/pii/S0957417422013537  \\n[124]  “MuseNet.” Accessed: Oct. 07, 2023. [Online]. \\nAvailable: https://openai.com/research/musenet  \\n[125]  P. Dhariwal, H. Jun, C. Payne, J. W. Kim, A. \\nRadford, and I. Sutskever, “Jukebox: A Generative', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='Model for Music.” arXiv, Apr. 30, 2020. doi: \\n10.48550/arXiv.2005.00341.  \\n[126]  “How To Give Your Living Room a Luxurious \\nMakeover,” House Beautiful. Accessed: Sep. 26, 2023. \\n[Online]. Available: \\nhttps://www.housebeautiful.com/room -\\ndecorating/living -family -rooms/g715/designer -living -\\nrooms/  \\n[127]  “File:Bowie -state-university -science- building.jpg - \\nWikipedia.” Accessed: Sep. 26, 2023. [Online]. \\nAvailable: \\nhttps://commons.wikimedia.org/wiki/File:Bowie -state-', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='university -science- building.jpg  \\n[128]  N. Kaur and P. Singh, “Conventional and \\ncontemporary approaches used in text to speech synthesis: a review,” Artif. Intell. Rev. , vol. 56, no. 7, \\npp. 5837– 5880, Jul. 2023, doi: 10.1007/s10462- 022-\\n10315- 0. \\n[129]  A. Wali et al. , “Generative adversarial networks for \\nspeech processing: A review,” Comput. Speech Lang. , \\nvol. 72, p. 101308, Mar. 2022, doi: \\n10.1016/j.csl.2021.101308.  \\n[130]  J. A. Rodriguez, D. Vazquez, I. Laradji, M.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='Pedersoli, and P. Rodriguez, “FigGen: Text to Scientific \\nFigure Generation.” arXiv, Jun. 21, 2023. Accessed: \\nOct. 07, 2023. [Online]. Available: http://arxiv.org/abs/2306.00800 \\n[131]  “Minerva: Solving Quantitative Reasoning \\nProblems with Language Models.” Accessed: Oct. 07, \\n2023. [Online]. Available: \\nhttps://blog.research.google/2022/06/minerva -solving-\\nquantitative -reasoning.html  \\n[132]  R. Taylor et al. , “Galactica: A Large Language \\nModel for Science.” arXiv, Nov. 16, 2022. doi:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='10.48550/arXiv.2211.09085.  \\n[133]  C. Plut and P. Pasquier, “Generative music in video \\ngames: State of the art, challenges, and prospects,” Entertain. Comput. , vol. 33, p. 100337, Mar. 2020, doi: \\n10.1016/j.entcom.2019.100337.  \\n[134]  S. Wang et al. , “ReelFramer: Co -creating News \\nReels on Social Media with Generative AI.” arXiv, Apr. \\n19, 2023. Accessed: Oct. 11, 2023. [Online]. Available: http://arxiv.org/abs/2304.09653 \\n[135]  T. H. D. and R. Bean, “The Impact of Generative', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='AI on Hollywood and Entertainment,” MIT Sloan Management Review. Accessed: Oct. 11, 2023. \\n[Online]. Available: \\nhttps://sloanreview.mit.edu/article/the -impact -of-\\ngenerative- ai-on-hollywood- and-entertainm ent/ \\n[136]  “Runway AI: Tech Behind Everything Everywhere \\nAll At Once.” Accessed: Oct. 11, 2023. [Online]. Available: https://topten.ai/ai- tech-behind- everything-\\neverywhere -all-at-once/  \\n[137]  L. Rai, C. Deng, and F. Liu, “Developing Massive', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='Open Online Course Style Assessments using \\nGenerative AI Tools,” in 2023 IEEE 6th International \\nConference on Electronic Information and \\nCommunication Technology (ICEICT) , Jul. 2023, pp. \\n1292 –1294. doi: \\n10.1109/ICEICT57916.2023.10244824.  \\n[138]  J. Qadir, “Engineering Education in the Era of \\nChatGPT: Promise and Pitfalls of Generative AI for Education,” in 2023 IEEE Global Engineering \\nEducation Conference (EDUCON) , May 2023, pp. 1– 9. \\ndoi: 10.1109/EDUCON54358.2023.10125121.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='[139]  W. M. Lim, A. Gunasekara, J. L. Pallant, J. I. \\nPallant, and E. Pechenkina, “Generative AI and the \\nfuture of education: Ragnarök or reformation? A \\nparadoxical perspective from management educators,” \\nInt. J. Manag. Educ. , vol. 21, no. 2, p. 100790, Jul. \\n2023, doi: 10.1016/j.ijme.2023.100790.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 22}),\n",
       " Document(page_content='[140]  Y.-X. Li and N. -C. Tai, “Teaching at the Right \\nMoment: A Generative AI -Enabled Bedtime Storybook \\nGeneration System Communicating Timely Issues,” in \\n2023 International Conference on Consumer \\nElectronics - Taiwan (ICCE -Taiwan) , Jul. 2023, pp. \\n157– 158. doi: 10.1109/ICCE -\\nTaiwan58799.2023.10226626.  \\n[141]  E. A. Alasadi and C. R. Baiz, “Generative AI in \\nEducation and Research: Opportunities, Concerns, and \\nSolutions,” J. Chem. Educ. , vol. 100, no. 8, pp. 2965–', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='2971, Aug. 2023, doi: 10.1021/acs.jchemed.3c00323.  \\n[142]  H. Yu, Z. Liu, and Y. Guo, “Application Status, \\nProblems and Future Prospects of Generative AI in Education,” in 2023 5th International Conference on \\nComputer Science and Technologies in Education (CSTE), Apr. 2023, pp. 1– 7. doi: \\n10.1109/CSTE59648.2023.00065.  \\n[143]  M. Kuzlu, Z. Xiao, S. Sarp, F. O. Catak, N. Gurler, \\nand O. Guler, “The Rise of Generative Artificial \\nIntelligence in Healthcare,” in 2023 12th', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='Mediterranean Conference on Embedded Computing (MECO), Jun. 2023, pp. 1 –4. doi: \\n10.1109/MECO58584.2023.10155107.  \\n[144]  A. Jadon and S. Kumar, “Leveraging Generative AI \\nModels for Synthetic Data Generation in Healthcare: Balancing Research and Privacy,” in 2023 International \\nConference on Smart Applications, Communications \\nand Networking (SmartNets) , Jul. 2023, pp. 1– 4. doi: \\n10.1109/SmartNets58706.2023.10215825.  \\n[145]  Z. Shen, F. Ding, A. Jolfaei, K. Yadav, S. Vashisht,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='and K. Yu, “DeformableGAN: Generating Medical Images With Improved Integrity for Healthcare Cyber \\nPhysical Systems,” IEEE Trans. Netw. Sci. Eng. , vol. \\n10, no. 5, pp. 2584– 2596, Sep. 2023, doi: \\n10.1109/TNSE.2022.3190765.  \\n[146]  “AWS Announces AWS HealthScribe, a New \\nGenerative AI -Powered Service that Automatically \\nCreates Clinical Documentation,” Press Center. Accessed: Oct. 11, 2023. [Online]. Available: \\nhttps://press.aboutamazon.com/2023/7/aws -announces -', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='aws-healthscribe -a-new-generative -ai-powered -\\nservice- that-automatically -creates -clinical-\\ndocumentation  \\n[147]  B. Tang, J. Ewalt, and H.- L. Ng, “Generative AI \\nModels for Drug Discovery,” in Biophysical and \\nComputational Tools in Drug Discovery , A. K. Saxena, \\nEd., in Topics in Medicinal Chemistry. , Cham: \\nSpringer International Publishing, 2021, pp. 221– 243. \\ndoi: 10.1007/7355_2021_124.  \\n[148]  W. P. Walters and M. Murcko, “Assessing the', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='impact of generative AI on medicinal chemistry,” Nat. \\nBiotechnol. , vol. 38, no. 2, Art. no. 2, Feb. 2020, doi: \\n10.1038/s41587- 020-0418- 2. \\n[149]  X. Zeng et al. , “Deep generative molecular design \\nreshapes drug discovery,” Cell Rep. Med. , vol. 3, no. 12, \\np. 100794, Dec. 2022, doi: \\n10.1016/j.xcrm.2022.100794.  [150]  A. Madani et al. , “Large language models generate \\nfunctional protein sequences across diverse families,” Nat. Biotechnol. , vol. 41, no. 8, Art. no. 8, Aug. 2023,', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='doi: 10.1038/s41587- 022-01618- 2. \\n[151]  E. Sevgen et al. , “ProT -VAE: Protein Transformer \\nVariational AutoEncoder for Functional Protein \\nDesign.” bioRxiv, p. 2023.01.23.525232, Jan. 24, 2023. \\ndoi: 10.1101/2023.01.23.525232.  \\n[152]  “Cognizant and Google Cloud Expand Alliance to \\nBring AI to Enterprise Clients,” News | Cognizant \\nTechnology Solutions. Accessed: Oct. 11, 2023. [Online]. Available: https://news.cognizant.com/2023 -\\n05-09-Cognizant -and-Google -Cloud- Expand- Alliance -', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='to-Bring-AI-to-Enterprise -Clients  \\n[153]  “Generative AI to Become a $1.3 Trillion Market \\nby 2032, Research Finds | Press | Bloomberg LP,” Bloomberg L.P.  Accessed: Oct. 12, 2023. [Online]. \\nAvailable: \\nhttps://www.bloomberg.com/company/press/generativ\\ne-ai-to-become- a-1-3-trillion -market -by-2032-\\nresearch -finds/  \\n[154]  T. H. Baek, “Digital Advertising in the Age of \\nGenerative AI,” J. Curr. Issues Res. Advert. , vol. 44, no. \\n3, pp. 249– 251, Jul. 2023, doi:', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='10.1080/10641734.2023.2243496.  \\n[155]  J. Huh, M. R. Nelson, and C. A. Russell, “ChatGPT, \\nAI Advertising, and Advertising Research and \\nEducation,” J. Advert. , vol. 52, no. 4, pp. 477– 482, Aug. \\n2023, doi: 10.1080/00913367.2023.2227013.  \\n[156]  J. Ford, V. Jain, K. Wadhwani, and D. G. Gupta, \\n“AI advertising: An overview and guidelines,” J. Bus. \\nRes., vol. 166, p. 114124, Nov. 2023, doi: \\n10.1016/j.jbusres.2023.114124.  \\n[157]  A. Beheshti et al. , “ProcessGPT: Transforming', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='Business Process Management with Generative \\nArtificial Intelligence,” in 2023 IEEE International \\nConference on Web Services (ICWS) , Jul. 2023, pp. \\n731– 739. doi: 10.1109/ICWS60048.2023.00099.  \\n[158]  “Amazon launches generative AI to help sellers \\nwrite product descriptions,” US About Amazon. \\nAccessed: Oct. 12, 2023. [Online]. Available: \\nhttps://www.aboutamazon.com/news/small-\\nbusiness/amazon -sellers -generative- ai-tool \\n[159]  “ChatGPT In Healthcare: What Science Says,” The', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='Medical Futurist. Accessed: Aug. 24, 2023. [Online]. Available: https://medicalfuturist.com/chatgpt -in-\\nhealthcare- what -the-science- says/  \\n[160]  “Generative AI and the future of work in America | \\nMcKinsey.” Accessed: Oct. 10, 2023. [Online]. Available: https://www.mckinsey.com/mgi/our -\\nresearch/generative- ai-and-the-future -of-work -in-\\namerica#/  \\n[161]  A. Zarifhonarvar, “Economics of ChatGPT: A \\nLabor Market View on the Occupational Impact of', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='Artificial Intelligence.” Rochester, NY, Feb. 07, 2023. \\ndoi: 10.2139/ssrn.4350925.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 23}),\n",
       " Document(page_content='[162]  “Future of Work Report: AI at Work.” Accessed: \\nOct. 14, 2023. [Online]. Available: \\nhttps://economicgraph.linkedin.com/research/future -\\nof-work -report -ai \\n[163]  “Jobs of Tomorrow: Large Language Models and \\nJobs,” World Economic Forum. Accessed: Oct. 14, \\n2023. [Online]. Available: \\nhttps://www.weforum.org/whitepapers/jobs -of-\\ntomorrow -large -language -models -and-jobs/  \\n[164]  “Automation or augmentation? This is how AI will \\nbe integrated into the jobs of tomorrow,” World', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 24}),\n",
       " Document(page_content='Economic Forum. Accessed: Oct. 14, 2023. [Online]. \\nAvailable: \\nhttps://www.weforum.org/agenda/2023/09/ai -\\nautomation -augmentation -workplace -jobs-of-\\ntomorrow/  \\n[165]  “We always hear that AI will take our jobs. But \\nwhat jobs will it create?,” World Economic Forum. \\nAccessed: Oct. 14, 2023. [Online]. Available: \\nhttps://www.weforum.org/agenda/2023/09/jobs -ai-\\nwill- create/  \\n[166]  K. Michael, R. Abbas, and G. Roussos, “AI in \\nCybersecurity: The Paradox,” IEEE Trans. Technol.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 24}),\n",
       " Document(page_content='Soc., vol. 4, no. 2, pp. 104 –109, Jun. 2023, doi: \\n10.1109/TTS.2023.3280109.  \\n[167]  S. Oh and T. Shon, “Cybersecurity Issues in \\nGenerative AI,” in 2023 International Conference on \\nPlatform Technology and Service (PlatCon) , Aug. \\n2023, pp. 97 –100. doi: \\n10.1109/PlatCon60102.2023.10255179.  \\n[168]  M. Gupta, C. Akiri, K. Aryal, E. Parker, and L. \\nPraharaj, “From ChatGPT to ThreatGPT: Impact of \\nGenerative AI in Cybersecurity and Privacy,” IEEE', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 24}),\n",
       " Document(page_content='Access , vol. 11, pp. 80218– 80245, 2023, doi: \\n10.1109/ACCESS.2023.3300381.  \\n[169]  “AI-Based Cybercrime Tools WormGPT and \\nFraudGPT Could Be The Tip of the Iceberg | SlashNext,” SlashNext |. Accessed: Aug. 24, 2023. \\n[Online]. Available: https://slashnext.com/blog/ai-\\nbased -cybercrime- tools -wormgpt -and-fraudgpt -could -\\nbe-the-tip-of-the-iceberg/  \\n[170]  I.-C. Mihai, “The Transformative Impact of', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 24}),\n",
       " Document(page_content='Artificial Intelligence on Cybersecurity,” Int. J. Inf. Secur. Cybercrime, vol. 12, p. 9, 2023.  \\n[171]  P. V. Falade, “Decoding the Threat Landscape\\u202f: \\nChatGPT, FraudGPT, and WormGPT in Social \\nEngineering Attacks,” Int. J. Sci. Res. Comput. Sci. Eng. \\nInf. Technol. , pp. 185 –198, Oct. 2023, doi: \\n10.32628/CSEIT2390533.  \\n[172]  M. Mozes, X. He, B. Kleinberg, and L. D. Griffin, \\n“Use of LLMs for Illicit Purposes: Threats, Prevention \\nMeasures, and Vulnerabilities.” arXiv, Aug. 24, 2023.', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 24}),\n",
       " Document(page_content='doi: 10.48550/arXiv.2308.12833.  \\n[173]  “Pause Giant AI Experiments: An Open Letter,” \\nFuture of Life Institute. Accessed: Aug. 24, 2023. \\n[Online]. Available: https://futureoflife.org/open -\\nletter/pause -giant -ai-experiments/ [174]  J. Coscarelli, “An A.I. Hit of Fake ‘Drake’ and ‘The \\nWeeknd’ Rattles the Music World,” The New York Times , Apr. 19, 2023. Accessed: Oct. 11, 2023. \\n[Online]. Available: \\nhttps://www.nytimes.com/2023/04/19/arts/music/ai-drake -the-weeknd -fake.html', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 24}),\n",
       " Document(page_content='[175]  B. Lane, “An AI -generated Rihanna cover of \\nBeyoncé’s ‘Cuff It’ is going viral, and it could open up a new legal nightmare for the music industry,” Insider. \\nAccessed: Oct. 14, 2023. [Online]. Available: \\nhttps://www.insider.com/rihanna -ai-cuff-it-cover -\\nlegal -nightmare -music -industry -2023- 4', metadata={'source': 'Machine Learning Notes/AI paper.pdf', 'page': 24})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get chunks/pages of data\n",
    "test_chunk = test_splitter.split_documents(data)\n",
    "test_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3acf730b-2079-441e-8eec-6729d980dcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total chunks of data\n",
    "len(test_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "287bd0a0-993b-40b4-8b37-4452001bbde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advancements in Generative AI: A \n",
      "Comprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and \n",
      "Transformers. \n",
      "Staphord Bengesi1, Hoda El -Sayed1, Md Kamruzzaman Sarker1, Yao  Houkpati1, John \n",
      "Irungu3   and Timothy Oladunni2 \n",
      "1 Dept. of Computer Science, Bowie State University, Bowie, MD 20715 USA  \n",
      "2 Dept. of Computer Science, Morgan State University, Baltimore, MD 21251 USA  \n",
      "3 Dept.  of Computer Science, University of the District of Columbia , Washington, DC 20008  USA\n"
     ]
    }
   ],
   "source": [
    "# get the first chunk from first page 0\n",
    "print(test_chunk[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "230d7dfa-3ee8-41f0-9edf-7fbe41bd870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'Machine Learning Notes/AI paper.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(test_chunk[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "892051ce-ff9c-485a-9bd6-b8d8bdef4c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corresponding author: sbengesi@bowiestate.edu  \n",
      " \n",
      "ABSTRACT  The launch of ChatGPT has garnered global attention, marking a significant milestone in the \n",
      "field of Generative Artificial Intelligence. While Generative AI has been in effect for the past decade, the \n",
      "introduction of ChatGPT has ignited a new wave of research and innovation in the AI domain. This surge in interest has led to the development and release of numerous cutting -edge tools, such as Bard, Stable Diffusion,\n"
     ]
    }
   ],
   "source": [
    "# second chunk from first page 0\n",
    "print(test_chunk[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73a6f5bc-e824-4658-9f60-089d776c7b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DALL -E, Make-A- Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable \n",
      "capabilities, encompassing tasks ranging from text generation and music composition, image creation, video \n",
      "production, code generation, and even scientific work. They are built upon various state -of-the-art models, \n",
      "including Stable Diffusion, transformer models like GPT- 3 (recent GPT -4), variational autoencoders, and\n"
     ]
    }
   ],
   "source": [
    "# third chunk\n",
    "print(test_chunk[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5fc6b2a-818b-4641-a5ee-cbe9ba173710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175]  B. Lane, “An AI -generated Rihanna cover of \n",
      "Beyoncé’s ‘Cuff It’ is going viral, and it could open up a new legal nightmare for the music industry,” Insider. \n",
      "Accessed: Oct. 14, 2023. [Online]. Available: \n",
      "https://www.insider.com/rihanna -ai-cuff-it-cover -\n",
      "legal -nightmare -music -industry -2023- 4\n"
     ]
    }
   ],
   "source": [
    "# last chunk of data\n",
    "print(test_chunk[232].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc02aa68-fd16-4392-8501-afa31e95a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the openai api key with os\n",
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e84c998e-b30d-473d-bac8-76feb5d66ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimator object of OPENAI embeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a91dc1-c0cb-4868-8712-5393bda2a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call an embedding method with any query. This gave an error bcos of price and billing from OPENAI. You should get a vector embedding\n",
    "embeddings.embed_query('How are you?')\n",
    "len(embeddings.embed_query('How are you?'))    # this gives the total number of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13f25757-e421-4dd8-82b2-120adf97b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone vector database configurations(API_KEY and ENV name) from Pinecone website\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', '7e5d84fa-109f-4055-914a-2db9d3dc3b37')\n",
    "#PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5875828a-e799-441b-b4c9-ba70f1964b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinecone method with some parameters.\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4f121-bc17-4352-b637-cdd229115e3b",
   "metadata": {},
   "source": [
    "#### create index on Pinecone. use free tier cos it's usually charged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f549d8bd-f838-4fdd-bf33-e27bab3f3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = Pinecone.Index('testing')    --> imaginary index created in pinecone\n",
    "index_name='testing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab4f9f-6fa9-470c-a924-7321bd16fb33",
   "metadata": {},
   "source": [
    "##### create embeddings for each of the test chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248fb91-0aa9-45c5-8ed8-51531e448369",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in test_chunk], embeddings, index_name=index_name) # error cos of index not created in pinecone and billing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ed18157-fd54-4f03-a792-83e9bd37d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for question and answer. just practice code for retrieving answers from question\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI, chain_type='stuff', retriever=docsearch.as_retriever())\n",
    "query = 'any question asked from the pdf paper'\n",
    "# qa.run(query)\n",
    "# doc = docsearch.similarity_search(query)    --> get cosine similarity search of the query wrt to the docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46c047-12da-4c18-aa28-d8e6f954f70c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
