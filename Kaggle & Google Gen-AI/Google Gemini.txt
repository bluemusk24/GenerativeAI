# Google AI studio key (Gemini API Key) for both Gmail accounts
* AIzaSyCPFSmBBCnp9Fmks2mdLEnIVihducbc5fk  
* AIzaSyBetoX_myO3oN_iuJ4o9i0qMbHnTa-9gnc

# Summary of the Whitepaper/Podcast 1 on Large Language Model and Text Generation

1. LLMs are based off on the encoder-decoder Transformer architecture with attention is all that's necessary.

2. RNNs are the building blocks on which LLMs were introduced. RNNs are slow neural networks, which gave birth to LLMs, to learn longer texts/data in order to predict the next word or sentence.

3. The words/sentences are tokens broken down into chunks and converted to embeddings(numerical representation), to be fed into the LLM for easy understanding (contextual meaning) and predictions.

4. GPTs are decoder LLMs that predict the next word. 
* GPT-1 learn on its own unstructured text, but with limited memory, does not retain much to predict the next word. 
* GPT-2 was trained on 10000 more dataset than GPT-1 with more parameters. 
* GPT-3 has over 175Billion parameters. It also brought Few-Shot learning - understanding and performing tasks with a few example - without being trained on tons on large labeled data.
* GPT-4 handles images and text (multimodal learning) and have longer context windows to remember more data.

5. Lambda - language Model for dialogue application: Google first LLM used basically to dialogue before the advent of PalM, Gemini 1.5, Gemini Vision.

6. LLMs are trained on large tons of data (Supervised learning), but can be finetuned for a specific purpose. 
# Types of Finetuning: 
* Supervised finetuning SFT) - use LLM for a specific task, e.g. for a company document, report, news etc.
* Reinforcement Learning with Human Feedback (RLHF) - LLMs achieving a reward for a task done by another model. The reward model is finetuned on human preferences - thumbs up, thumbs down technique - to ensure LLM generates optimum outputs/responses. 
* Parameter Efficiency Finetuning (PEFT) - finetuning just a part of the parameters of an LLM to manage cost (token cost) without losing its efficiency. e.g. 7-Billion Parameters finetuned out of 175-Billion parameters of GPTs, Llama models or Google Geminis. 

7. LLMs can be optimized for inference - making and accessing predictions of next words/tokens, ensuring the outputs are meaningful. This can be achieved by adjusting the temperature (degree of randomness), top-K (outputting the most useful words), top-P (find out about this)

8. Quantized models are 'small LLMs' with almost (same) reasoning ability carved out of the main LLMs. e.g.. a student acquiring a knowledge of a teacher that impacted such knowledge. This technique is called Distillation of LLMs. Examples are: Data Distillation, Knowledge Distillation, Policy Distillation.

# Day-1 Livestream: Foundational Models and Prompt Engineering


# Day-2 Livestream: Embeddings and Vector Databases
